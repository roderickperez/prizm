Carefully read all the documentation:



Workflow description - How to create a Petrel UI from Python code

Inside Petrel, in the Prizm Workflow Runner plugin, the user interface (UI) elements are dynamically generated through workflow descriptions embedded within your Python script or Jupyter notebook. This is achieved by defining a special section in your code that is specifically interpreted by Petrel to create the UI.



Defining the Workflow Description Section

The workflow description section is clearly marked at the beginning of your script to indicate where the UI generation code begins and ends. This is done using specific comments:

The start of the description is marked with # Start: PWR Description.

The end is indicated by # End: PWR Description.

Between these markers, you define the UI elements and their behavior.



Using the Workflow Description Function

The Python library cegalprizm.pycoderunner has a class WorkflowDescription. You can use this class to define your Cegal Prizm workflow and determine what the Petrel user sees in the Petrel UI.

The WorkflowDescription must be defined in between 2 commented-out lines “# Start: PWR Description” and “# End: PWR Description”.

It must include the following parameters:

name : The name of the workflow as it will appear in Petrel.

category : The category under which your workflow will be listed in Petrel, aiding in organization and filtering.

description : A brief description of what your script or notebook does.

authors : Contact details of the workflow’s author.

version : The version number of your workflow.

The WorkflowDescription creates the input options in the Prizm Workflow Runner UI available to the Petrel user. When the Cegal Prizm workflow is executed from Petrel the WorkflowDescription returns a Python dictionary called ‘parameters’ with the parameter names and the Petrel GUID or user input values.

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnumpwr_description = WorkflowDescription(name="Name as shown in Petrel",

                                      category="Category used in filter",

                                      description="Describe here what your notebook or script does",

                                      authors="contact details of the workflow author",

                                      version="version_number")# End: PWR Description

The cell above will show as a Cegal Prizm workflow in Petrel without any user input options as shown in the image below. To allow Petrel users to select input you must add parameters to your WorkflowDescription.



Adding Input Objects

The Prizm Workflow Runner plugin offers a robust and flexible way to create user interfaces (UI) in Petrel by allowing a wide range of input types. This capability is showcased in the following code snippet. Users can utilize various input types, including Petrel domain objects, basic data types like integers, floats, strings, and booleans, as well as more complex types such as enums (dropdowns), files, and folders.

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnum, TemplateNamesEnumpwr_description = WorkflowDescription(name="Name as shown in Petrel",

                                      category="Category used in filter",

                                      description="Describe here what your notebook or script does",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add domain object parameterspwr_description.add_object_ref_parameter(name="",object_type=DomainObjectsEnum.,label="",description="",template_type=TemplateNamesEnum.template,measurement_type=MeasurementNamesEnum.measurement,select_multiple=True/False,linked_input_name="")# Add user defined input parameterspwr_description.add_boolean_parameter(name="",label="",description="",default_value=True/False)pwr_description.add_float_parameter(name="",label="",description="",display_symbol="",measurement_type=MeasurementNamesEnum.measurement,minimum_value="",maximum_value="",default_value="")pwr_description.add_integer_parameter(name="",label="",description="",minimum_value="",maximum_value="",default_value="")pwr_description.add_string_parameter(name="",label="",description="",default_value="")#Add user selection parameterspwr_description.add_enum_parameter(name="",label="",description="",options={1:"Option1",2:"Option2"},default_value=1)pwr_description.add_file_parameter(name="",label="",description="",file_extensions="",select_multiple=True/False)pwr_description.add_folder_parameter(name="",label="",description="")# End: PWR Description



All parameters are added to a Python dictionary called ‘parameters’ with the name of the parameter as the key. For object reference parameters the GUID of the object selected by the Petrel user is the value of the ‘parameters’ dictionary. You can then use the Python Tool Pro function get_petrelobjects_by_guids() to retrieve the Petrel object. For any other parameter type it is the value used by the Petrel user.

For users interested in learning more about these input types and how to effectively utilize them in their workflows, the rest of the user guides offers detailed explanations and examples.



====



Domain object parameters- How to let Petrel users select domain objects as input

DomainObjectsEnum deprecation (PWR 1.4)

Important:

As of Prizm Workflow Runner 1.4, the DomainObjectsEnum provided by the PWR API is deprecated.

It has been replaced by the new, unified DomainObjectsEnum from the Python Tool Pro (PTP) API.

All workflow scripts must be updated to use the PTP version.

The old PWR enum will be removed completely in PWR 2.0.

Note: Existing workflows will still run in PWR 1.4, but will show deprecation warnings.

Update your scripts now to avoid breaking changes when upgrading to PWR 2.0.

Migrate your scripts

To migrate your scripts, simply update the import to use the new PTP enum.

Replace:

from cegalprizm.pycoderunner import DomainObjectsEnum

With:

from cegalprizm.pythontool import DomainObjectsEnum

Both the enum names and their corresponding string identifiers have changed in PWR 1.4 to align with the new unified DomainObjectsEnum from Python Tool Pro.

Because of this, you should update them according to the enum and string mapping table provided below.

We strongly recommend using the new enum directly to ensure compatibility going forward, as the old PWR enum will be removed in PWR 2.0.

Enum migration mapping (PWR → PTP)

Old PWR Enum

Old PWR String

New PTP Enum

New PTP String

Well

well

Well

borehole

WellsFolder

wells_folder

WellFolder

borehole collection

WellContinuousLog

well_continuous_log

WellLog

well log

WellDiscreteLog

well_discrete_log

DiscreteWellLog

discrete well log

GlobalLogContinuous

global_continuous_log

GlobalWellLog

global well log

GlobalLogDiscrete

global_discrete_log

DiscreteGlobalWellLog

global discrete well log

WellMarkerCollection

well_marker_collection

MarkerCollection

marker collection

WellMarkerStratigraphy

well_marker_stratigraphy

MarkerStratigraphy

marker stratigraphy

WellMarkerContinuousProperty

well_marker_continuous_property

MarkerAttribute

marker attribute

WellMarkerDiscreteProperty

well_marker_discrete_property

MarkerAttribute

discrete marker attribute

WellCasing

well_casing

CasingString

casing string

WellPerforation

well_perforation

Perforation

perforation

WellPlugback

well_plugback

Plugback

plugback

WellSqueeze

well_squeeze

Squeeze

squeeze

WellCompletion

well_perforation; well_casing; well_plugback; well_squeeze

Completion

casing string; perforation; plugback; squeeze

InterpretationFolder

interpretation_folder

InterpretationFolder

interpretation collection

ObservedDataset

observed_dataset

ObservedDataSet

observed data set

ObservedDatasetForWell

observed_dataset_for_well

GlobalObservedDataSet

global observed data set

SurfaceContinuousProperty

surface_continuous_property

SurfaceAttribute

surface property

SurfaceDiscreteProperty

surface_discrete_property

SurfaceDiscreteAttribute

surface discrete property

HorizonInterpretation3DProperty

horizon_interpretation_3d_property

HorizonProperty3D

horizon property 3d

TemplateDiscrete

template_discrete

DiscreteTemplate

discrete template

This notebook shows how you can use the add_object_ref_parameter function to enable Petrel users to select Petrel domain objects as input for the Cegal Prizm workflow.

Any object supported by Investigator or Python Tool Pro can be used as input:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,MeasurementNamesEnum,TemplateNamesEnumfrom cegalprizm.pythontool import DomainObjectsEnumpwr_description = WorkflowDescription(name="Domain object support",

                                      category="Examples",

                                      description="Example notebook to show domain object support",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_object_ref_parameter(name="",object_type=DomainObjectsEnum.,label="",description="",template_type=TemplateNamesEnum.template,measurement_type=MeasurementNamesEnum.measurement,select_multiple=True/False,linked_input_name="")# End: PWR Description

The function add_object_ref_parameter has following flags:

Flag

Explanation

name

Key used in the Python dictionary “parameters”

label

Label shown to the Petrel user in the Prizm Workflow Runner UI

description

A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the Prizm Workflow Runner UI.

object_type

Domain object to be selected by Petrel user. Class DomainObjectsEnum can be used to easily find the correct syntax

template_type (optional)

Petrel template the domain object must have to be accepted

measurement_type (optional)

Petrel measurement the domain object must have to be accepted

select_multiple (optional)

Option to allow Petrel user to select multiple objects of the same type

linked_input_name (optional)

Link object selection to parameter of previous selected object

parameter_group (str, optional)

(New in PWR 1.4) Use this to specify the parameter group this parameter belongs to. Defaults to None.

Domain Object Enumerator

To define the object type it is recommended to use the class DomainObjectsEnum:

pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select log",description="Select the log needed for the workflow")

Alternatively you can use the string representation corresponding to the DomainObjectsEnum class:

pwr_description.add_object_ref_parameter(name="well_log",object_type='well log',label="Select log",description="Select the log needed for the workflow")

A full list of supported domain objects is shown in the cell below:

from cegalprizm.pythontool import  DomainObjectsEnum[i for i in DomainObjectsEnum]

[<DomainObjectsEnum.CasingString: 'casing string'>,

 <DomainObjectsEnum.CheckShot: 'checkshot'>,

 <DomainObjectsEnum.Completion: 'casing string;perforation;plugback;squeeze'>,

 <DomainObjectsEnum.DiscreteGlobalWellLog: 'global discrete well log'>,

 <DomainObjectsEnum.DiscreteTemplate: 'discrete template'>,

 <DomainObjectsEnum.DiscreteWellLog: 'discrete well log'>,

 <DomainObjectsEnum.FaultInterpretation: 'fault interpretation'>,

 <DomainObjectsEnum.Folder: 'folder'>,

 <DomainObjectsEnum.GlobalObservedDataSet: 'global observed data set'>,

 <DomainObjectsEnum.GlobalWellLog: 'global well log'>,

 <DomainObjectsEnum.GlobalWellLogFolder: 'global well log folder'>,

 <DomainObjectsEnum.Grid: 'grid'>,

 <DomainObjectsEnum.GridDiscreteProperty: 'grid discrete property'>,

 <DomainObjectsEnum.GridProperty: 'grid property'>,

 <DomainObjectsEnum.HorizonInterpretation: 'horizon interpretation'>,

 <DomainObjectsEnum.HorizonInterpretation3D: 'horizon interpretation 3d'>,

 <DomainObjectsEnum.HorizonProperty3D: 'horizon property 3d'>,

 <DomainObjectsEnum.InterpretationFolder: 'interpretation collection'>,

 <DomainObjectsEnum.MarkerAttribute: 'marker attribute;discrete marker attribute'>,

 <DomainObjectsEnum.MarkerCollection: 'marker collection'>,

 <DomainObjectsEnum.MarkerStratigraphy: 'marker stratigraphy'>,

 <DomainObjectsEnum.ObservedData: 'observed data'>,

 <DomainObjectsEnum.ObservedDataSet: 'observed data set'>,

 <DomainObjectsEnum.Perforation: 'perforation'>,

 <DomainObjectsEnum.Plugback: 'plugback'>,

 <DomainObjectsEnum.PointSet: 'pointset'>,

 <DomainObjectsEnum.PolylineAttribute: 'polyline attribute;discrete polyline attribute'>,

 <DomainObjectsEnum.PolylineSet: 'polylineset'>,

 <DomainObjectsEnum.PropertyFolder: 'property folder'>,

 <DomainObjectsEnum.SavedSearch: 'saved search'>,

 <DomainObjectsEnum.Segment: 'segment'>,

 <DomainObjectsEnum.SeismicCube: 'seismic cube'>,

 <DomainObjectsEnum.SeismicLine: 'seismic 2d'>,

 <DomainObjectsEnum.Squeeze: 'squeeze'>,

 <DomainObjectsEnum.Surface: 'surface'>,

 <DomainObjectsEnum.SurfaceAttribute: 'surface property'>,

 <DomainObjectsEnum.SurfaceDiscreteAttribute: 'surface discrete property'>,

 <DomainObjectsEnum.Template: 'template'>,

 <DomainObjectsEnum.Wavelet: 'wavelet'>,

 <DomainObjectsEnum.Well: 'borehole'>,

 <DomainObjectsEnum.WellAttribute: 'well attribute;discrete well attribute'>,

 <DomainObjectsEnum.WellFolder: 'borehole collection'>,

 <DomainObjectsEnum.WellLog: 'well log'>,

 <DomainObjectsEnum.WellSurvey: 'dxdytvd well survey;explicit well survey;mdinclazim well survey;xytvd well survey;xyz well survey'>,

 <DomainObjectsEnum.Zone: 'zone'>]

Let’s create a UI where we take as input a well and a continuous log:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,MeasurementNamesEnum,TemplateNamesEnumfrom cegalprizm.pythontool import  DomainObjectsEnumpwr_description = WorkflowDescription(name="Domain object support",

                                      category="Examples",

                                      description="Example notebook to show domain object support",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_object_ref_parameter(name="well",object_type=DomainObjectsEnum.Well,label="Select a well",description="User selected well object")pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select a well log",description="User selected well log object",linked_input_name="well")# End: PWR Description

The code from the previous cell created the following UI in Petrel:





It allows the user to user to select a well and a continuous well log. Notice how the user can select any continuous log, not just the ones associated with the selected well.

Use of flag linked_input_name

In the previous example the Petrel user could select a well and any continuous log. The linked_input_name flag allows you to link two input parameters. If you link a object_ref_parameter to a previously defined object_ref_parameter, Petrel users can only select the second input once they selected the first.

Let’s rewrite the previous example and only allow the Petrel users to select logs associated to the selected well:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription, MeasurementNamesEnumfrom cegalprizm.pythontool import  DomainObjectsEnumpwr_description = WorkflowDescription(name="Domain object support",

                                      category="Examples",

                                      description="Example notebook to show domain object support",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_object_ref_parameter(name="well",object_type=DomainObjectsEnum.Well,label="Select a well",description="User selected well object")pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select a well log",description="User selected well log object",linked_input_name="well")# End: PWR Description

The above PWR description will create a UI in Prizm Workflow Runner with a well selection and a well log selection. Notice the the log selector is disabled to begin with.



Only after the Petrel user selects well object can they select a well log that is linked to the well object.



Use of flag select_multiple

The .add_object_ref_parameter function includes an optional flag called select_multiple. By default, this flag is set to False, meaning that Petrel users can select only one object at a time for each parameter. However, when select_multiple is set to True, it allows users to select multiple objects for the same parameter.

Let’s modify the previous example and allow Petrel users to select multiple logs :

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,MeasurementNamesEnum,TemplateNamesEnumfrom cegalprizm.pythontool import  DomainObjectsEnumpwr_description = WorkflowDescription(name="Domain object support",

                                      category="Examples",

                                      description="Example notebook to show domain object support",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_object_ref_parameter(name="well",object_type=DomainObjectsEnum.Well,label="Select a well",description="User selected well object")pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select a well log",description="User selected well log object",linked_input_name="well",select_multiple=True)# End: PWR Description

Notice how the UI for the log selection changed, and now includes check boxes for each log , allowing the user to select multiple :



Use of flag template_type

You can also restrict the user input based on specific templates. This can be achieved by using the template_type flag. Similarly, to how you define the object_type flag, to define the template_type one , it is recommended to use the class TemplateNamesEnum:

pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select log",description="Select the log needed for the workflow",template_type=TemplateNamesEnum.GammaRay)

Alternatively you can use the string representation corresponding to the TemplateNamesEnum class:

pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select log",description="Select the log needed for the workflow",template_type='GammaRay')

A list of supported template objects is shown in the cell below. For the full list simply remove the [0:25] :

[i for i in TemplateNamesEnum][0:25]

[<TemplateNamesEnum.FracturePatchSet: 'FracturePatchSet'>,

 <TemplateNamesEnum.CompletionCasedLog: 'CompletionCasedLog'>,

 <TemplateNamesEnum.CompletionGeneral: 'CompletionGeneral'>,

 <TemplateNamesEnum.CompletionLinedLog: 'CompletionLinedLog'>,

 <TemplateNamesEnum.Perforation: 'Perforation'>,

 <TemplateNamesEnum.ProductionStatus: 'ProductionStatus'>,

 <TemplateNamesEnum.SlidingSleevePositions: 'SlidingSleevePositions'>,

 <TemplateNamesEnum.HistoryMatchQualitativeCoarse: 'HistoryMatchQualitativeCoarse'>,

 <TemplateNamesEnum.HistoryMatchQualitativeFine: 'HistoryMatchQualitativeFine'>,

 <TemplateNamesEnum.HoleClassification: 'HoleClassification'>,

 <TemplateNamesEnum.ActiveCellFlag: 'ActiveCellFlag'>,

 <TemplateNamesEnum.Bodies: 'Bodies'>,

 <TemplateNamesEnum.BooleanProperty: 'BooleanProperty'>,

 <TemplateNamesEnum.BoreholeIndex: 'BoreholeIndex'>,

 <TemplateNamesEnum.ConnectedVolume: 'ConnectedVolume'>,

 <TemplateNamesEnum.DictionaryGeneral: 'DictionaryGeneral'>,

 <TemplateNamesEnum.DipClassification: 'DipClassification'>,

 <TemplateNamesEnum.Facies: 'Facies'>,

 <TemplateNamesEnum.Faults: 'Faults'>,

 <TemplateNamesEnum.Fluids: 'Fluids'>,

 <TemplateNamesEnum.FluvialFacies: 'FluvialFacies'>,

 <TemplateNamesEnum.Horizons: 'Horizons'>,

 <TemplateNamesEnum.Lithologies: 'Lithologies'>,

 <TemplateNamesEnum.RegionId: 'RegionId'>,

 <TemplateNamesEnum.Segments: 'Segments'>]

Now, let’s modify the current example and only accept logs which have the Gamma Ray template:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,MeasurementNamesEnum,TemplateNamesEnumfrom cegalprizm.pythontool import  DomainObjectsEnumpwr_description = WorkflowDescription(name="Domain object support",

                                      category="Examples",

                                      description="Example notebook to show domain object support",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_object_ref_parameter(name="well",object_type=DomainObjectsEnum.Well,label="Select a well",description="User selected well object")pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select a well log",description="User selected well log object",linked_input_name="well",select_multiple=True,template_type=TemplateNamesEnum.GammaRay )# End: PWR Description

Notice how now, only the Gamma Ray log is available for selection:



Use of flag measurement_type

You can also restrict the user input based on the measurement type. In Petrel, the measurement is defined a category of units associated to a specific template. This can be achieved by using the measurement_type flag. Similarly, to how you define the object_type and template_type flags, to define the measurement_type one , it is recommended to use the class MeasurementNamesEnum:

pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select log",description="Select the log needed for the workflow",measurment_type=MeasurementNamesEnum.Porosity)

Alternatively you can use the string representation corresponding to the MeasurementNamesEnum class:

pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select log",description="Select the log needed for the workflow",measurment_type='Porosity')

A list of supported measurement types is shown in the cell below. For the full list simply remove the [0:25] :

[i for i in MeasurementNamesEnum][0:25]

[<MeasurementNamesEnum.StandardDepthIndex: 'Standard_Depth_Index'>,

 <MeasurementNamesEnum.ShortTime: 'Short_Time'>,

 <MeasurementNamesEnum.Length: 'Length'>,

 <MeasurementNamesEnum.Dimensionless: 'Dimensionless'>,

 <MeasurementNamesEnum.Frequency: 'Frequency'>,

 <MeasurementNamesEnum.Rotation: 'Rotation'>,

 <MeasurementNamesEnum.Area: 'Area'>,

 <MeasurementNamesEnum.Velocity: 'Velocity'>,

 <MeasurementNamesEnum.Ratio: 'Ratio'>,

 <MeasurementNamesEnum.AcousticImpedance: 'Acoustic_Impedance'>,

 <MeasurementNamesEnum.Temperature: 'Temperature'>,

 <MeasurementNamesEnum.PressureDensity: 'Pressure_Density'>,

 <MeasurementNamesEnum.Compressibility: 'Compressibility'>,

 <MeasurementNamesEnum.InverseArea: 'Inverse_Area'>,

 <MeasurementNamesEnum.ThermalConductivity: 'Thermal_Conductivity'>,

 <MeasurementNamesEnum.ThermalConductionTransmissibility: 'Thermal_Conduction_Transmissibility'>,

 <MeasurementNamesEnum.VolumetricHeatCapacity: 'Volumetric_Heat_Capacity'>,

 <MeasurementNamesEnum.VolumetricHeatCapacityPerTemperature: 'Volumetric_Heat_Capacity_Per_Temperature'>,

 <MeasurementNamesEnum.HeatTransferCoefficient: 'Heat_Transfer_Coefficient'>,

 <MeasurementNamesEnum.SpecificHeatCapacityPerTemperature: 'Specific_Heat_Capacity_Per_Temperature'>,

 <MeasurementNamesEnum.SpecificHeatCapacityPerTemperatureSquared: 'Specific_Heat_Capacity_Per_Temperature_Squared'>,

 <MeasurementNamesEnum.VaporizationHeat: 'Vaporization_Heat'>,

 <MeasurementNamesEnum.InverseTemperature: 'Inverse_Temperature'>,

 <MeasurementNamesEnum.InverseTemperatureSquared: 'Inverse_Temperature_Squared'>,

 <MeasurementNamesEnum.ThermalResistivity: 'Thermal_Resistivity'>]

Let’s modify the current example and only accept logs which have the Porosity measurement:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,MeasurementNamesEnum,TemplateNamesEnumfrom cegalprizm.pythontool import  DomainObjectsEnumpwr_description = WorkflowDescription(name="Domain object support",

                                      category="Examples",

                                      description="Example notebook to show domain object support",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_object_ref_parameter(name="well",object_type=DomainObjectsEnum.Well,label="Select a well",description="User selected well object")pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select a well log",description="User selected well log object",linked_input_name="well",select_multiple=True,measurement_type=MeasurementNamesEnum.Porosity)# End: PWR Description

Using the measurement filter, only the Porosity measurement can be used now :



Use of flag parameter_group flag (new in PWR 1.4)

PWR 1.4 introduces a new optional parameter called ``parameter_group``, which allows workflow authors to organize input parameters into logical sections inside the Prizm Workflow Runner UI.

Grouping parameters keeps the UI tidy when a workflow has many inputs.

You can assign any parameter to a group by setting the parameter_group argument when adding it to the workflow description.

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,MeasurementNamesEnum,TemplateNamesEnumfrom cegalprizm.pythontool import  DomainObjectsEnumpwr_description = WorkflowDescription(name="Domain object support",

                                      category="Examples",

                                      description="Example notebook to show domain object support",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_object_ref_parameter(name="well",object_type=DomainObjectsEnum.Well,label="Select a well",description="User selected well object",parameter_group="Well data")pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select a well log",description="User selected well log object",linked_input_name="well",select_multiple=True,measurement_type=MeasurementNamesEnum.Porosity , parameter_group="Well data")pwr_description.add_object_ref_parameter(name="surface",object_type=DomainObjectsEnum.Surface,label="Select a surface",description="User selected surface object",parameter_group="Other data types")pwr_description.add_object_ref_parameter(name="seismic",object_type=DomainObjectsEnum.SeismicCube,label="Select a cube",description="User selected cube object",parameter_group="Other data types")# End: PWR Description



Pass user selected input into Investigator or Python Tool Pro functionality

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_object_ref_parameter function is used as a key in the dictionary, and for object reference parameters the Petrel GUID of the selected object is used as the value.

This “parameters” dictionary can be then used to pass the object selected by the Petrel user to functionality used in Investigator or Python Tool Pro.

parameters[‘well’] will return the GUID of the selected well input.



Python Tool Pro

Let’s use Python Tool Pro to retrieve the well and log selected by the Petrel user:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,MeasurementNamesEnumfrom cegalprizm.pythontool import  DomainObjectsEnumpwr_description = WorkflowDescription(name="Domain object support",

                                      category="Examples",

                                      description="Example notebook to show domain object support",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_object_ref_parameter(name="well",object_type=DomainObjectsEnum.Well,label="Select a well",description="User selected well object")pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select a well log",description="User selected well log object",linked_input_name="well")# End: PWR Description

<cegalprizm.pycoderunner.workflow_description.WorkflowDescription at 0x218ef38b9d0>

If your Cegal Prizm workflow uses Python Tool Pro functionality you must first create a PetrelConnection:

from cegalprizm.pythontool import PetrelConnectionpetrel = PetrelConnection()

Then, you need to use the get_petrelobjects_by_guids() function to retrieve the user input objects:

my_well=petrel.get_petrelobjects_by_guids([parameters['well']])[0]my_log=petrel.get_petrelobjects_by_guids([parameters['well_log']])[0]

If we print the my_well and my_log variables defined above, it will output a Well and WellLog object (i.e : Well(petrel_name=””) and WellLog(petrel_name=””))

Let’s run the following script using the Prizm Workflow Runner inside Petrel. It allows the user to select a well and a log associated to that well. It will then print the parameter dictionary followed by each value of the dictionary ( the values associated to the well and well_log keys).

We’ll then use Python Tool Pro to retrieve the userselected object using the .get_petrelobjects_by_guids() funtion. Lastly, we’ll print the two objects retrieved by Python Tool Pro:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription, MeasurementNamesEnumfrom cegalprizm.pythontool import  DomainObjectsEnumpwr_description = WorkflowDescription(name="Domain object support",

                                      category="Examples",

                                      description="Example notebook to show domain object support",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_object_ref_parameter(name="well",object_type=DomainObjectsEnum.Well,label="Select a well",description="User selected well object")pwr_description.add_object_ref_parameter(name="well_log",object_type=DomainObjectsEnum.WellLog,label="Select a well log",description="User selected well log object",linked_input_name="well")# End: PWR Descriptionprint(f"Printing the parameters dictionary outputs: {parameters}")print(f"Printing the well parameter outputs: {parameters['well']}")print(f"Printing the log parameter outputs: {parameters['well_log']}")from cegalprizm.pythontool import PetrelConnectionpetrel = PetrelConnection()my_well=petrel.get_petrelobjects_by_guids([parameters['well']])[0]my_log=petrel.get_petrelobjects_by_guids([parameters['well_log']])[0]print(f"Printing the input well retrieved using Python tool Pro:  {my_well}")print(f"Printing the input log retrieved using Python tool Pro:  {my_log}")

After running the script we can see what the script printed , how the parameters dictionary looks like and how Python Tool Pro retrieved the user selected objects using the GUIDS from the parameters dictionary:



Investigator

Similarly, we can use Investigator to retrieve a user selected investigation:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnumpwr_description = WorkflowDescription(name="Domain object support",

                                      category="Examples",

                                      description="Example notebook to show domain object support",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_object_ref_parameter(name="investigation_id",object_type=DomainObjectsEnum.Investigation,label="Select an investigation",description="User selected investigation")# End: PWR Description

If your Cegal Prizm workflow uses Investigator functionality you must first create a InvestigatorConnection:

from cegalprizm.investigator import InvestigatorConnectioninv_conn = InvestigatorConnection(use_licensed_features=True)

Then, you need to use the load_investigation() function to retrieve the input investigation object:

inv = inv_conn.load_investigation(investigation_id=parameter['investigation_id'])

======

User defined input parameters- Boolean, Floats, Integer, Strings

This notebook shows how you can enable Petrel users to define input parameters as input for the Cegal Prizm workflow. User defined input of type boolean, floats, integer and strings are supported.

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription, MeasurementNamesEnumpwr_description = WorkflowDescription(name="Name as shown in Petrel",

                                      category="Category used in filter",

                                      description="Describe here what your notebook or script does",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_boolean_parameter(name="",label="",description="",default_value=True/False)pwr_description.add_float_parameter(name="",label="",description="",display_symbol="",measurement_type=MeasurementNamesEnum.measurement,minimum_value="",maximum_value="",default_value="")pwr_description.add_integer_parameter(name="",label="",description="",minimum_value="",maximum_value="",default_value="")pwr_description.add_string_parameter(name="",label="",description="",default_value="")# End: PWR Description

Boolean parameter

Boolean parameters enable Petrel users to toggle features or make straightforward choices - typically a ‘Yes’ or ‘No’, ‘True’ or ‘False’ decision - that can alter the workflow’s behavior.

To add an input boolean parameter use the .add_boolean_parameter() function:

pwr_description.add_boolean_parameter(name="bool_1",label="Boolean input",description="Check box for True",default_value=False)

The function add_boolean_parameter has following flags:

Flag

Explanation

name

Key used in the Python dictionary “parameters”

label

Label shown to the Petrel user in the Prizm Workflow Runner UI

description

A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the Prizm Workflow Runner UI.

default_value

The default value of the bool. Either True or False. Cegal Prizm workflow will be executed with default value if Petrel user doesn’t change it.

parameter_group (str, optional)

(New in PWR 1.4) Use this to specify the parameter group this parameter belongs to. Defaults to None.

Access the Boolean input parameter value

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_boolean_parameter() function is used as a key in the dictionary and the user selected option (True or False) is used as the value.

Let’s write a simple example that creates a Boolean input parameter and based on the user selection prints a statement:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescriptionpwr_description = WorkflowDescription(name="Boolean example",

                                      category="Examples",

                                      description="Example notebook to showcase the Boolean input parameters",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterpwr_description.add_boolean_parameter(name="boolean_1",label="Boolean input",description="Checkbox for True",default_value=False)# End: PWR Description# Retrieve the boolean parameter value from the parameters dictionaryboolean_value=parameters['boolean_1']if boolean_value:

    print(f'The checkbox is ticked - Boolean input value is {boolean_value}')else:

    print(f'The checkbox is not ticked - Boolean input value is {boolean_value}')

The script above will create a UI in the Prizm Workflow Runner with an input Boolean parameter. In the UI, the Boolean parameter is represented by a checkbox. As defined in the the PWR description the initial value of the Boolean parameter is False meaning the checkbox is not ticked. A True value is represented by a ticked checkbox.



Within the script we retrieved the boolean value from the parameters dictionary , check it’s value and print a statement based on the Boolean parameter value.

Float parameter

The float parameter in the Prizm Workflow Runner allows Petrel users to input precise, decimal values. It offers customizable settings such as defining minimum and maximum value limits, setting default values, and optionally specifying measurement units, ensuring both accuracy and flexibility in user inputs.

To add an input float parameter use the .add_float_parameter() function:

pwr_description.add_float_parameter(name="float_1",label="Float input",description="Insert a float value")

The function add_float_parameter has following flags:

Flag

Explanation

name

Key used in the Python dictionary “parameters”

label

Label shown to the Petrel user in the Prizm Workflow Runner UI

description

A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the Prizm Workflow Runner UI.

minimum_value (optional)

If defined this specifies the lowest value the field can accept. Defaults to None.

maximum_value (optional)

If defined this specifies the highest value the field can accept. Defaults to None.

default_value (optional)

If defined this specifies the default value to be assigned to the parameter. Defaults to 0.

measurement_type (optional)

If defined this specifies the measurement type of the parameter. Defaults to None. If specified the display symbol must also be defined.

display_symbol (optional)

If defined this specifies the units of the supplied parameter. This allows the workflow to ensure that the parameter will be in the given units irrespective of the display units in the Petrel project. Defaults to None.

parameter_group (str, optional)

(New in PWR 1.4) Use this to specify the parameter group this parameter belongs to. Defaults to None.

Access the float input parameter value

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_float_parameter() function is used as a key in the dictionary and the user defined number is used as the value.

Let’s write a simple example that creates a float input parameter UI and then prints the value:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescriptionpwr_description = WorkflowDescription(name="Float example",

                                      category="Examples",

                                      description="Example notebook to showcase the float input parameters",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_float_parameter(name="float_1",label="float input",description="Insert a float value")# End: PWR Description# Retrieve the boolean parameter value from the parameters dictionaryfloat_value=parameters['float_1']print(float_value)

The code from the previous cell created the following UI in Petrel. Notice the the float input parameter will accept integer inputs but the input will always be converted to float value:



Minimum , maximum and default value

The minimum, maximum and default values flags allow you to define boundaries and pre-set options for the user input. These parameters ensure that the values entered are within a specified range thus preventing unrealistic inputs and offering sensible starting points:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnum, TemplateNamesEnumpwr_description = WorkflowDescription(name="Float example",

                                      category="Examples",

                                      description="Example notebook to showcase the float input parameters",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_float_parameter(name="float_1",label="float input",description="Insert a float value",default_value=2, minimum_value=1, maximum_value=5)# End: PWR Description# Retrieve the boolean parameter value from the parameters dictionaryfloat_value=parameters['float_1']print(float_value)

In the example above, we used a default value of 2 , a minimum value of 1 and a maximum one of 5. The default value must be inside the [min,max] interval. Notice that if the user inputs a value outside of the defined interval, the input will be colored red and when hovering with the mouse on it the user will get the message value must be in [min,max] :



Measurement type and display symbol

You can also restrict the user input based on the measurement type. In Petrel, the measurement is defined a category of units associated to a specific template. This can be achieved by using the measurement_type flag. If the measurement flag is used, the display_symbol must also be defined. The display symbol specifies the units (associated to the selected measurement) of the supplied parameter. This allows the workflow to ensure that the parameter will be in the given units irrespective of the display units in the Petrel project.



A list of supported measurement types is shown in the cell below. For the full list simply remove the [0:25] :

[i for i in MeasurementNamesEnum][0:25]

[<MeasurementNamesEnum.StandardDepthIndex: 'Standard_Depth_Index'>,

 <MeasurementNamesEnum.ShortTime: 'Short_Time'>,

 <MeasurementNamesEnum.Length: 'Length'>,

 <MeasurementNamesEnum.Dimensionless: 'Dimensionless'>,

 <MeasurementNamesEnum.Frequency: 'Frequency'>,

 <MeasurementNamesEnum.Rotation: 'Rotation'>,

 <MeasurementNamesEnum.Area: 'Area'>,

 <MeasurementNamesEnum.Velocity: 'Velocity'>,

 <MeasurementNamesEnum.Ratio: 'Ratio'>,

 <MeasurementNamesEnum.AcousticImpedance: 'Acoustic_Impedance'>,

 <MeasurementNamesEnum.Temperature: 'Temperature'>,

 <MeasurementNamesEnum.PressureDensity: 'Pressure_Density'>,

 <MeasurementNamesEnum.Compressibility: 'Compressibility'>,

 <MeasurementNamesEnum.InverseArea: 'Inverse_Area'>,

 <MeasurementNamesEnum.ThermalConductivity: 'Thermal_Conductivity'>,

 <MeasurementNamesEnum.ThermalConductionTransmissibility: 'Thermal_Conduction_Transmissibility'>,

 <MeasurementNamesEnum.VolumetricHeatCapacity: 'Volumetric_Heat_Capacity'>,

 <MeasurementNamesEnum.VolumetricHeatCapacityPerTemperature: 'Volumetric_Heat_Capacity_Per_Temperature'>,

 <MeasurementNamesEnum.HeatTransferCoefficient: 'Heat_Transfer_Coefficient'>,

 <MeasurementNamesEnum.SpecificHeatCapacityPerTemperature: 'Specific_Heat_Capacity_Per_Temperature'>,

 <MeasurementNamesEnum.SpecificHeatCapacityPerTemperatureSquared: 'Specific_Heat_Capacity_Per_Temperature_Squared'>,

 <MeasurementNamesEnum.VaporizationHeat: 'Vaporization_Heat'>,

 <MeasurementNamesEnum.InverseTemperature: 'Inverse_Temperature'>,

 <MeasurementNamesEnum.InverseTemperatureSquared: 'Inverse_Temperature_Squared'>,

 <MeasurementNamesEnum.ThermalResistivity: 'Thermal_Resistivity'>]

In the example below we’re using the Length measurement type and specifying the meter as a unit :



# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnum, TemplateNamesEnumpwr_description = WorkflowDescription(name="Float example",

                                      category="Examples",

                                      description="Example notebook to showcase the float input parameter",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_float_parameter(name="float_1",label="float input",description="Insert a float value",default_value=2, minimum_value=1, maximum_value=5 ,measurement_type=MeasurementNamesEnum.Length , display_symbol='m')# End: PWR Description# Retrieve the float parameter value from the parameters dictionaryfloat_value=parameters['float_1']print(float_value)

The code from the previous cell created the following UI in Petrel:



By clicking on the unit symbol the user can convert or override the unit :



In this example we converted the unit from m to mm. Notice the the input value also changed from 2 to 2000. However, the output value will always be in meters as defined in the add_float_parameter() function by the display_symbol flag.



Float spinner parameter (New in PWR 1.4)

In PWR 1.4 , float spinners have been added as new UI elements in Prizm Workflow Runner. They allow users to enter numeric values with clear minimum/maximum limits and optional step sizes. To add an input float spinner parameter use the .add_float_spinner_parameter() function:

pwr_description.add_float_spinner_parameter(name='float_spinner', label='float_spinner_input', description='float_spinner_input', default_value=0.0, minimum_value=-5.0, maximum_value=5.0, increment=0.2)

The function add_float_spinner_parameter has the following flags:

Flag

Explanation

name (str)

The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str)

The label text that will be displayed next to the field in the workflow UI.

description (str)

A description of what the parameter represents. This text will be shown in the tooltip next to the field in the workflow UI.

default_value (float)

The default value to be assigned to the parameter.

minimum_value (float)

The lowest value the field can accept.

maximum_value (float)

The highest value the field can accept.

increment (float)

The increment (step size) for the spinner control. Increment must be greater than zero.

measurement_type (Union[Enum(str), str], optional)

If defined, this specifies the measurement type of the parameter. Defaults to None.

display_symbol (str, optional)

If defined, this specifies the units of the supplied parameter. This ensures that the workflow receives the value in the correct units, regardless of Petrel’s display units. Defaults to None.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional)

Link another boolean, enum, or object_ref parameter’s state to this parameter’s visual state. All linked conditions must be true for the parameter to be enabled/visible. Defaults to None.

show_increment (bool, optional)

Specifies whether the increment value should be shown in the UI. Defaults to False.

decimal_places (int, optional)

Specifies the number of decimal places to display in the UI.

parameter_group (str, optional)

Specifies the parameter group this parameter belongs to. Defaults to None.

Access the float spinner parameter value

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_float_spinner_parameter() function is used as a key in the dictionary and the user defined number is used as the value.

Let’s write a simple example that creates a floating spinner input parameter UI and then prints the value:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,pwr_description = WorkflowDescription(name="Floating spinner example",

                                      category="Examples",

                                      description="Example notebook to showcase the floating spinner input parameter",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_float_spinner_parameter(name="float_spinner_1",

                                            label="Float Spinner input",

                                            description="Insert a floating value",

                                            default_value=5.0,

                                            minimum_value=0.0,

                                            maximum_value=20.0,

                                            increment=0.2,

                                            measurement_type=MeasurementNamesEnum.Length ,

                                            display_symbol='m',

                                            show_increment=True,

                                            decimal_places=1)# End: PWR Description# Retrieve the integer parameter value from the parameters dictionaryfloat_value=parameters['float_spinner_1']print(float_value)

The code from the previous cell created the following UI in Petrel:



Integer parameter

The integer (int) input parameter allows users to input whole numbers. To add an input integer parameter use the .add_integer_parameter() function:

pwr_description.add_integer_parameter(name="int_1",label="Integer input",description="Insert an integer value")

The function add_integer_parameter has the following flags:

Flag

Explanation

name

Key used in the Python dictionary “parameters”

label

Label shown to the Petrel user in the Prizm Workflow Runner UI

description

A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the Prizm Workflow Runner UI.

minimum_value (optional)

If defined this specifies the lowest value the field can accept. Defaults to None.

maximum_value (optional)

If defined this specifies the highest value the field can accept. Defaults to None.

default_value (optional)

If defined this specifies the default value to be assigned to the parameter. Defaults to 0.

parameter_group (str, optional)

(New in PWR 1.4) Use this to specify the parameter group this parameter belongs to. Defaults to None.

Access the integer input parameter value

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_integer_parameter() function is used as a key in the dictionary and the user defined number is used as the value.

Let’s write a simple example that creates an integer input parameter UI and then prints the value:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnum, TemplateNamesEnumpwr_description = WorkflowDescription(name="Integer example",

                                      category="Examples",

                                      description="Example notebook to showcase the integer input parameter",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_integer_parameter(name="int_1",label="Integer input",description="Insert a integer value",default_value=200, minimum_value=100, maximum_value=400)# End: PWR Description# Retrieve the integer parameter value from the parameters dictionaryinteger_value=parameters['int_1']print(integer_value)

In the example above we’re also making use of the minimum, maximum and default value flags which allow you to define boundaries and pre-set options for the user input. These parameters ensure that the values entered are within a specified range thus preventing unrealistic inputs and offering sensible starting points. The code from the previous cell created the following UI in Petrel:



Integer spinner parameter (New in PWR 1.4)

The add_integer_spinner_parameter() function was introduced in PWR 1.4 and adds an integer spinner input field to the workflow description.This creates a numeric UI element in the Prizm Workflow Runner that allows the user to adjust values using arrow controls.

pwr_description.add_integer_spinner_parameter(name='int_spinner', label='int_spinner_input', description='int_spinner_input', default_value=0, minimum_value=0, maximum_value=10)

The function add_integer_spinner_parameter has the following flags:

Flag

Explanation

name (str)

The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str)

The label text that will be displayed next to the field in the workflow UI.

description (str)

A description of what the parameter represents. This description will be shown in the tooltip next to the field in the workflow UI.

default_value (int)

This specifies the default value to be assigned to the parameter.

minimum_value (int)

This specifies the lowest value the field can accept.

maximum_value (int)

This specifies the highest value the field can accept.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional)

Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional)

(New in PWR 1.4) Use this to specify the parameter group this parameter belongs to. Defaults to None.

Access the integer spinner parameter value

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_integer_spinner_parameter() function is used as a key in the dictionary and the user defined number is used as the value.

Let’s write a simple example that creates an integer spinner input parameter UI and then prints the value:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,MeasurementNamesEnumpwr_description = WorkflowDescription(name="Integer spinner example",

                                      category="Examples",

                                      description="Example notebook to showcase the integer spinner input parameter",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_integer_spinner_parameter(name="int_spinner_1",

                                            label="Integer Spinner input",

                                            description="Insert an integer value",

                                            default_value=5,

                                            minimum_value=0,

                                            maximum_value=20,

                                            )# End: PWR Description# Retrieve the integer parameter value from the parameters dictionaryint_value=parameters['int_spinner_1']print(int_value)

The code from the previous cell created the following UI in Petrel:



String parameter

The string parameter enables users to input text-based data, such as names, labels, or descriptions, providing a flexible means for adding qualitative information to a workflow. To add a string input parameter use the .add_string_parameter() function:

pwr_description.add_string_parameter(name="str_1",label="String input",description="Insert a string",default_value="I am a string")

The function add_string_parameter has following flags:

Flag

Explanation

name

Key used in the Python dictionary “parameters”

label

Label shown to the Petrel user in the Prizm Workflow Runner UI

description

A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the Prizm Workflow Runner UI.

default_value (optional)

The default value to be assigned to the parameter.

parameter_group (str, optional)

(New in PWR 1.4) Use this to specify the parameter group this parameter belongs to. Defaults to None.

Access the string input parameter value

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_string_parameter() function is used as a key in the dictionary and the user defined number is used as the value.

Let’s write a simple example that creates a string input parameter UI and then prints the value:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnum, TemplateNamesEnumpwr_description = WorkflowDescription(name="String example",

                                      category="Examples",

                                      description="Example notebook to showcase the string input parameter",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_string_parameter(name="str_1",label="String input",description="Insert a string",default_value="I am a string")# End: PWR Description# Retrieve the string parameter value from the parameters dictionarystring_value=parameters['str_1']print(string_value)

The code from the previous cell created the following UI in Petrel:



====

User selection parameters- Enumerators, Files, Folders

This notebook shows how you can give Petrel users to select external (from Petrel) files or a selection of options (enumerators) as input for the Cegal Prizm workflow. We will discuss file, folder and enumerator parameters.

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescriptionpwr_description = WorkflowDescription(name="Name as shown in Petrel",

                                      category="Category used in filter",

                                      description="Describe here what your notebook or script does",

                                      authors="contact details of the workflow author",

                                      version="version_number")#Add user selection parameterspwr_description.add_enum_parameter(name="",label="",description="",options={1:"Option1",2:"Option2"},default_value=1)pwr_description.add_file_parameter(name="",label="",description="",file_extensions="",select_multiple=True/False)pwr_description.add_folder_parameter(name="",label="",description="")# End: PWR Description

Enumerator parameter

The enumerator parameter in the Prizm Workflow Runner facilitates user choice by presenting a dropdown menu of predefined options, simplifying the selection process within a Cegal Prizm workflow.

To add an input enumerator parameter use the .add_enum_parameter() function:

pwr_description.add_enum_parameter(name="enum_1",label="Select option",description="Option 1 does this, option 2 does that",options={1:"Option1",2:"Option2"},default_value=1)

An enumerator allows you to create a list of options for the Petrel user to select before executing a Cegal Prizm workflow. The function add_enum_parameter has following flags:

Flag

Explanation

name

Key used in the Python dictionary “parameters”

label

Label shown to the Petrel user in the Prizm Workflow Runner UI

description

A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the Prizm Workflow Runner UI.

options

A dictionary of options where each option is described by a value and the text to be shown for it.

default_value (optional)

The default value of the bool. Either True or False. Cegal Prizm workflow will be executed with the default value if Petrel user doesn’t change it.

parameter_group (str, optional)

(New in PWR 1.4) Use this to specify the parameter group this parameter belongs to. Defaults to None.

Access the Enumerator input parameter value

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_enum_parameter() function is used as a key in the dictionary and the user selected option is used as the value.

Let’s write a simple example that creates an Enumerator input parameter which gives the user two choices and based on the user selection prints a statement:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescriptionpwr_description = WorkflowDescription(name="Enumerator example",

                                      category="Examples",

                                      description="Example notebook to showcase the enumerator input parameter",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_enum_parameter(name="enum_1",label="Select option",description="Option 1 does this, option 2 does that",options={1:"Option 1",2:"Option 2"},default_value=1)# End: PWR Description# Retrieve the Enumerator parameter value from the parameters dictionaryenumerator_value=parameters['enum_1']if enumerator_value==1:

    print(f'User selected option from the dropdown menu is Option 1. Enumerator parameter value :{enumerator_value}')else:

    print(f'User selected option from the dropdown menu is Option 2. Enumerator parameter value :{enumerator_value}')

The script above will create a UI in the Prizm Workflow Runner with an input Enumerator parameter represented by a dropdown menu. The available options were provided using the option flag within within the .add_enum_parameter() function and providing a dictionary where the keys represent the value of the Enumerator parameter and the values represents the label shown in the Petrel UI. The default available option is Option 1 as defined by the default_value flag . Within the script we retrieved the enumerator value from the parameters dictionary , checked it’s value and printed a statement based on the enumerator parameter value.



Radio button parameter (new in PWR 1.4)

The add_radio_parameter() function adds a set of radio buttons to the workflow description. This input type allows the user to select exactly one option from a predefined list. They work similarly to enumerators but are better suited when presenting a small number of mutually exclusive options. Enumerators remain recommended for larger lists.

To add an input radio button parameter use the .add_radio_parameter() function:

pwr_description.add_radio_parameter(name='radio', label='radio_selector', description='radio_selector', options={1:"Option1", 2:"Option2", 3:"Option3"})

The function add_radio_parameter has following flags:

Flag

Explanation

name (str)

The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str)

The label text that will be displayed next to the text field in the workflow UI.

description (str)

A description of what the parameter is used for. This description will be shown in the tooltip next to the radio buttons in the workflow UI.

options (Dict[int, str])

A dictionary of options where each option is described by a value and the text to be shown for it.

default_value (int, optional)

The default value to be assigned to the parameter.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional)

Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional)

(New in PWR 1.4) Use this to specify the parameter group this parameter belongs to. Defaults to None.

Access the radio button parameter value

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_radio_parameter() function is used as a key in the dictionary and the user selected option is used as the value.

Let’s write a simple example that creates a radio button parameter which gives the user two choices and based on the user selection prints a statement:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescriptionpwr_description = WorkflowDescription(name="Radio example",

                                      category="Examples",

                                      description="Example notebook to showcase the radio button input parameter",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_radio_parameter(name='radio', label='radio_selector', description='radio_selector', options={1:"Option1", 2:"Option2"},default_value=1)# End: PWR Description# Retrieve the radio button parameter value from the parameters dictionaryradio_value=parameters['radio']if radio_value==1:

    print(f'User selected radio button is Option 1. Radio parameter value :{radio_value}')else:

    print(f'User selected radio button is Option 2. Radio parameter value :{radio_value}')

The script above will create a UI in the Prizm Workflow Runner with a radio button parameter. The available options were provided using the options flag within the .add_radio_parameter() function, where a dictionary is supplied: the keys represent the internal value of the radio selection, and the values represent the label shown in the Petrel UI.

The default selected option is determined by the default_value flag. Inside the script, we retrieve the selected radio value from the parameters dictionary, check its value, and then perform logic or printing based on the chosen option.



File parameter

The file parameter in the Prizm Workflow Runner enables Petrel users to select and incorporate external files into the workflow, broadening the scope of data sources and inputs. Configured via the .add_file_parameter() function, it allows for specifying supported file extensions and the option to select multiple files:

pwr_description.add_file_parameter(name="file_1",label="Select files",description="Select the files you want the script to use", file_extensions=".xlsx", select_multiple=True)

It is possible to let Petrel users select a file outside Petrel to include in the Cegal Prizm workflow. The function add_file_parameter has following flags:

Flag

Explanation

name

Key used in the Python dictionary “parameters”

label

Label shown to the Petrel user in the Prizm Workflow Runner UI

description

A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the Prizm Workflow Runner UI.

file_extensions

The file extensions supported

select_multiple (optional)

Specifies if the parameter can contain multiple values. Defaults to False.

parameter_group (str, optional)

(New in PWR 1.4) Use this to specify the parameter group this parameter belongs to. Defaults to None.

Access the file input parameter value

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_file_parameter() function is used as a key in the dictionary and the paths to the user selected files are used as the value.

Let’s write a simple example that creates a file input parameter UI and then prints the value:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescriptionpwr_description = WorkflowDescription(name="File example",

                                      category="Examples",

                                      description="Example notebook to showcase the file input parameter",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_file_parameter(name="file_1",label="Select files",description="Select the files you want the script to use", file_extensions=".xlsx" ,select_multiple=True)# End: PWR Description# Retrieve the File parameter value from the parameters dictionaryfile_value=parameters['file_1']print(f'File parameter value is: {file_value}')print(type(file_value))

In the above code cell we create a file input parameter and restrict it to only accept .xlsx files using the file_extensions flag. We allow the user to select multiple files by setting the select_multiple flag to True. The code from the previous cell created the following UI in Petrel:



By clicking on on the File input UI component , the user can navigate to the desired files and select them:



After selecting the files, we’re printing the file input parameter value and it’s type. Notice that the file input parameter returns a string containing the paths of the selected files , separated by ; :



File transfer

To copy a file to another location (e.g. for remote deployments with Python and Petrel on different machines) you need to use the class FileServices from cegalprizm.pycoderunner library.



# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescriptionpwr_description = WorkflowDescription(name="Name as shown in Petrel",

                                      category="Category used in filter",

                                      description="Describe here what your notebook or script does",

                                      authors="contact details of the workflow author",

                                      version="version_number")pwr_description.add_file_parameter(name="user_file",label="Select a file",description="Petrel user can select a file to be included in the Cegal Prizm workflow",file_extensions="csv")# End: PWR Descriptionfrom cegalprizm.pycoderunner import FileServices# Use the method download_file to copy a file from the Petrel machine to the Python machine:# You can pass the value of the user selected path to the class file servicesuser_selected_file=parameters["user_file"]FileServices.download_file(src_path=user_selected_file, dest_path="Destination path on the Python machine",overwrite= False)# Use the method upload_file to copy a file from the Python machine to the Petrel machine:FileServices.upload_file(src_path="Output file of the Cegal Prizm workflow on the Python machine", abs_dest_path="Destination path on the Petrel machine",overwrite= False, open_file_on_complete=True)



Folder parameter

The folder parameter in the Prizm Workflow Runner is a feature that allows Petrel users to specify a directory path, enabling the integration of external data storage locations into the workflow. This can be for example used as location to store output files of the Cegal Prizm workflow that does not go into Petrel.

To add an input folder parameter use the .add_folder_parameter() function:

pwr_description.add_folder_parameter(name="folder_1",label="Select folder",description="Select the folder you want the script to use")

The function add_folder_parameter has following flags:

Flag

Explanation

name

Key used in the Python dictionary “parameters”

label

Label shown to the Petrel user in the Prizm Workflow Runner UI

description

A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the Prizm Workflow Runner UI.

parameter_group (str, optional)

(New in PWR 1.4) Use this to specify the parameter group this parameter belongs to. Defaults to None.

Access the file input parameter value

When Petrel users execute a Cegal Prizm workflow from Petrel the WorkFlowDescription cell is executed and returns a Python dictionary called “parameters”. The name flag defined in the .add_folder_parameter() function is used as a key in the dictionary and the path to the user selected folder are used as the value.

Let’s write a simple example that creates a folder input parameter UI and then prints the value:

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescriptionpwr_description = WorkflowDescription(name="Folder example",

                                      category="Examples",

                                      description="Example notebook to showcase the folder input parameter",

                                      authors="contact details of the workflow author",

                                      version="version_number")# Add user defined input parameterspwr_description.add_folder_parameter(name="folder_1",label="Select folder",description="Select the folder you want the script to use")# End: PWR Description# Retrieve the Folder parameter value from the parameters dictionaryfolder_value=parameters['folder_1']print(f'File parameter value is: {folder_value}')print(type(folder_value))

The code from the previous cell created the following UI in Petrel:



By clicking on on the Folder input UI component , the user can navigate to the desired folder and select it:



After selecting the folder, we’re printing the folder input parameter value and it’s type. Notice that the folder input parameter returns a string containing the path of the selected selected:



===

Link reference parameters to user selection

The library cegalprizm.pycoderunner version 1.1 introduces functionality to link reference paremeters to the user selection in the Prizm Workflow Runner UI. It is possible to hide reference parameters that become visible after users selected previous reference parameters. It is also possible to disable parameters until users have made a predefined selection of previous reference parameters.

When adding a reference parameter you can make use of a new flag linked_visual_parameters. This flag defines the state of the parameter (Disabled/Enabled or Hidden/Visible) and which other reference parameter defines the state. It is possible to visually link a reference parameter to reference parameter of type: boolean, enumerator or object reference.

The flag linked_visual_parameters takes a dictionary as an input with a ParameterState as the key and a visual enumerator as the value. The ParameterState function takes as arguments the Python name of the linked reference parameter, and the value of the linked reference parameter required to trigger the change in behaviour, and what the behaviour change is (Disabled/Enabled or Hidden/Visible).

from cegalprizm.pycoderunner import ParameterState, ObjectRefStateEnum, VisualEnum, ParameterRefprint(ParameterState.__doc__)

A class to define a desired parameter state.

    Used as the key in the linked_visual_parameters dictionary when add_*_parameter is called on the WorkflowDescription object. The ParameterState links the visual state of a parameter to the state of another parameter.



    **Example**:



    Add an integer parameter that is only enabled in the UI when the linked boolean reference is True (Integer value can only be set when checkbox is checked):



    .. code-block:: python

        linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)

        linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Enabled}

        pwr_description.add_integer_parameter(name="int", label="int", description="int", default_value=0, linked_visual_parameters=linked_visual_parameters)



    **Example**:



    Add an object reference parameter that is only visible in the UI when the linked enum reference is set to a specific value (Well selector only shows when the enum drop-down is set to Value3):



    .. code-block:: python

        linked_enum_ref = pwr_description.add_enum_parameter(name="enum1", label="enum1", description="enum1", options={1:"Value1", 2:"Value2", 3:"Value3"}, default_value=1)

        linked_visual_parameters = {ParameterState(linked_enum_ref, 3): VisualEnum.Visible}

        pwr_description.add_object_ref_parameter(name='well', label='well_selector', description='well_selector', object_type=DomainObjectsEnum.Well, select_multiple=False, linked_visual_parameters=linked_visual_parameters)



    **Example**:



    Add a float parameter that is only enabled in the UI when the linked object reference parameter has a selection (Float value can only be set when a well is selected):



    .. code-block:: python

        linked_object_ref = pwr_description.add_object_ref_parameter(name='well', label='well_selector', description='well_selector', object_type=DomainObjectsEnum.Well, select_multiple=False)

        linked_visual_parameters = {ParameterState(linked_object_ref, ObjectRefStateEnum.Selected): VisualEnum.Enabled}

        pwr_description.add_float_parameter(name="float", label="float", description="float", default_value=0.0, linked_visual_parameters=linked_visual_parameters)

To make use of these functionality following classes must be imported from cegalprizm.pycoderunner

VisualEnum, ParameterState, ParameterRef, ObjectRefStateEnum



Boolean reference parameter

Linking to a boolean reference parameters allows you to enable or set visible a parameter after the user tick a checkbox. To make use of this functionality the boolean reference must be assigned to a Python variable using the method add_boolean_parameter()

The ParameterState used in the linked_visual_parameters has a parameter_ref the enumerator reference, the state is the value of the options dictionary in the enumerator.



Use boolean reference to set parameter enabled

linked_visual_parameters={ParameterState(parameter_ref=bool1_ref, state=True): VisualEnum.Enabled}

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnum, VisualEnum, ParameterState, ObjectRefStateEnumpwr_description = WorkflowDescription(name="Interactivity-Boolean reference",

                                      category="Examples",

                                      description="This workflow shows example of boolean reference parameters",

                                      authors="author@company.com",

                                      version="1.0")bool1_ref = pwr_description.add_boolean_parameter(name='check1',label='Allow selection of seismic?',description='Check this box to make the next line visisble',default_value=False)linked_visual_parameter_state = {ParameterState(parameter_ref=bool1_ref, state=True): VisualEnum.Enabled}pwr_description.add_object_ref_parameter(name='seismic',label='seismic cube',description='Select seismic', object_type=DomainObjectsEnum.SeismicCube, linked_visual_parameters=linked_visual_parameter_state)# End: PWR Description

Use boolean reference to set parameter visible

linked_visual_parameters={ParameterState(parameter_ref=bool1_ref, state=True): VisualEnum.Visible}

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnum, VisualEnum, ParameterState, ObjectRefStateEnumpwr_description = WorkflowDescription(name="Interactivity-Boolean reference",

                                      category="Examples",

                                      description="This workflow shows example of boolean reference parameters",

                                      authors="author@company.com",

                                      version="1.0")bool1_ref = pwr_description.add_boolean_parameter(name='check1',label='Allow selection of seismic?',description='Check this box to make the next line visisble',default_value=False)linked_visual_parameter_state = {ParameterState(parameter_ref=bool1_ref, state=True): VisualEnum.Visible}pwr_description.add_object_ref_parameter(name='seismic',label='seismic cube',description='Select seismic', object_type=DomainObjectsEnum.SeismicCube, linked_visual_parameters=linked_visual_parameter_state)# End: PWR Description

<cegalprizm.pycoderunner.workflow_description.ParameterRef at 0x16fc4a356c0>

Enumerator reference parameter

Using a enumerator parameter it is possible to give users a list of options to select from. Depending on their selection other parameters become enabled or made visible. To make use of this functionality the boolean reference must be assigned to a Python variable using the method add_enum_parameter(). The ParameterState used in the linked_visual_parameters has a parameter_ref the enumerator reference, the state is the value of the options dictionary in the enumerator.

linked_visual_parameters={ParameterState(parameter_ref=enum_ref, state=1): VisualEnum.Visible})

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnum, VisualEnum, ParameterState, ObjectRefStateEnumpwr_description = WorkflowDescription(name="Interactivity-Enum reference",

                                      category="Examples",

                                      description="This workflow shows example of boolean reference parameters",

                                      authors="author@company.com",

                                      version="1.0")enum_ref = pwr_description.add_enum_parameter(name="enum1", label="Select data type", description="uniform", options={1:'Well data',2:'Seismic data',3:'3d grid model properties'},default_value=1)well_ref=pwr_description.add_object_ref_parameter(name="wellid",

                                         label="Select a well",

                                         description="wellfromenum",

                                         object_type=DomainObjectsEnum.Well,

                                         linked_visual_parameters={ParameterState(parameter_ref=enum_ref, state=1): VisualEnum.Visible})seis_ref=pwr_description.add_object_ref_parameter(name="seismicid",

                                         label="Select a seismic cube",

                                         description="seismicfromenum",

                                         object_type=DomainObjectsEnum.SeismicCube,

                                         linked_visual_parameters={ParameterState(parameter_ref=enum_ref, state=2): VisualEnum.Visible})# End: PWR Description

Object reference parameter

It is also possible to link to a object reference parameter. The ParameterState has as parameter_ref the object reference and as state a ObjectRefStateEnum.Selected (ObjectRefStateEnum.NotSelected is also possible). When the user selects a object in the linked object reference parameter the target reference parameter becomes visible or enabled.

ParameterState(parameter_ref=obj1_ref, state=ObjectRefStateEnum.Selected): VisualEnum.Enabled)

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnum, VisualEnum, ParameterState, ObjectRefStateEnumpwr_description = WorkflowDescription(name="Interactivity-Obj reference",

                                      category="Examples",

                                      description="This workflow shows example of boolean reference parameters",

                                      authors="author@company.com",

                                      version="1.0")obj1_ref = pwr_description.add_object_ref_parameter(name='object1',label='Select a seismic', object_type=DomainObjectsEnum.SeismicCube,description='Selection of a seismic')pwr_description.add_object_ref_parameter(name='fault',label='Fault interpretation',description='Select fault', object_type=DomainObjectsEnum.FaultInterpretation, linked_visual_parameters={ParameterState(parameter_ref=obj1_ref, state=ObjectRefStateEnum.Selected): VisualEnum.Enabled})# End: PWR Description

===

Deploy Cegal Prizm workflows into Petrel workflows

Cegal Prizm workflows can be deployed using a workstep in the Petrel workflow editor. The workstep can be found under Processes > Prizm Workflow Runner

It is then possible to use global variable as an input for the Cegal Prizm workflow. Users can set the reference of the global variable in the Petrel workflow editor.



Accessing $-sign variables defined in a Petrel Workflow

$-sign variable such as numeric expression, string expression or date expression defined in a Petrel workflow can be access by a Cegal Prizm workflow using the workflow_vars property from Python Tool Pro’s API.

Let’s look at an example of how to do that. The starting point is the Petrel workflow shown in the picture below. We have 3 $-sign variables :

a numeric expression ($Num) - 15

a string expression ($Str) - ‘Hello world’

a date expression ($Date) - 2021-10-01

We want to write a Cegal Prizm workflow which can access the user defined $-sign variables and modify them. For this particular example we don’t need to define any input parameters for the Prizm Workflow Runner plugin. We’ll just create the PWR description. Then , we create a Petrel Connection using Python Tool Pro. Using the workflow_vars property we can access the user defined $-sign variables from the Petrel workflow. Note that this property is only available if the PetrelConnection is established as part of a Cegal Prizm workflow executed within a Petrel workflow. After accessing the $-sign variables we print out their values before overwriting them with new values. Lastly, we print out the newly modified $-sign variables to verify that their value changed.

# Start: PWR Descriptionfrom cegalprizm.pycoderunner import WorkflowDescriptionpwr_description = WorkflowDescription(name="Workflow vars",

                                    category="Well",

                                    description="Example on how to interact with Petrel workflow $-sign variables",

                                    authors="contact details of the workflow author",

                                    version="version_number")# End: PWR Descriptionfrom cegalprizm.pythontool import PetrelConnectionimport datetime# Use Python Tool Pro to create a Petrel Connectionpetrel = PetrelConnection(allow_experimental = True)#Print the user defined $-sign variablesprint(petrel.workflow_vars["$Num"])print(petrel.workflow_vars["$Str"])print(petrel.workflow_vars["$Date"])#Modify the user defined $-sign variablespetrel.workflow_vars["$Num"] = 333.0petrel.workflow_vars["$Str"] = "Hello from Petrel"petrel.workflow_vars["$Date"] = datetime.datetime(year=2023,month=11,day=22)print('The new values are: \n')#Print the new $-sign variablesprint(petrel.workflow_vars["$Num"])print(petrel.workflow_vars["$Str"])print(petrel.workflow_vars["$Date"])

Now that we have the script we can add a new Prizm Workflow Runner workstep in the Petrel workflow and select this script:

We can execute the workflow and check the results in the Message log in Petrel:



===

WorkflowDescription

class cegalprizm.pycoderunner.WorkflowDescription(name: str, category: str, description: str, authors: str, version: str)

Describes a PWR workflow

Parameters:

name (str) – The name of the workflow.

category (str) – The category of the workflow (this is a free text string that can be used by the user to help filter and discover workflows)

description (str) – A free text field description of the workflow and what is does.

authors (str) – A free text field that can be used to list the names/email addresses of who should be contacted for support and/or additional information about this workflow.

version – A free text field that can be used to describe the version of the workflow.

add_boolean_parameter(name: str, label: str, description: str, default_value: bool, linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, parameter_group: str = None)

Adds a boolean parameter to the workflow description.

This will generate a checkbox in the workflow UI.

Example:

Add a boolean parameter:

pwr_description.add_boolean_parameter(name='bool', label='bool_input', description='bool_input', default_value=False)

Example:

Add a boolean parameter that is only visible in the UI when the linked enum reference is set to a specific value (Checkbox only shows when the enum drop-down is set to Value3):

linked_enum_ref = pwr_description.add_enum_parameter(name="enum1", label="enum1", description="enum1", options={1:"Value1", 2:"Value2", 3:"Value3"}, default_value=1)linked_visual_parameters = {ParameterState(linked_enum_ref, 3): VisualEnum.Visible}pwr_description.add_boolean_parameter(name='bool', label='bool_input', description='bool_input', default_value=False, linked_visual_parameters=linked_visual_parameters)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the checkbox in the workflow UI.

description (str) – A description of what the parameter represents. This description will be shown in the tooltip next to the checkbox in the workflow UI.

default_value (bool) – The default value to be assigned to the parameter.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the default_value is not a bool.

add_enum_parameter(name: str, label: str, description: str, options: Dict[int, str], default_value: int = None, linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, parameter_group: str = None)

Adds an enum parameter to the workflow description.

This will generate a combobox in the workflow UI.

Example:

Add an enum parameter to select between three options:

pwr_description.add_enum_parameter(name='enum', label='enum_selector', description='enum_selector', options={1:"Option1", 2:"Option2", 3:"Option3"})

Example:

Add an enum parameter to select between three options that is only enabled in the UI when the linked boolean reference is set to True:

linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Enabled}pwr_description.add_enum_parameter(name='enum', label='enum_selector', description='enum_selector', options={1:"Option1", 2:"Option2", 3:"Option3"}, linked_visual_parameters=linked_visual_parameters)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the text field in the workflow UI.

description (str) – A description of what the parameter is used for. This description will be shown in the tooltip next to the combobox in the workflow UI.

options (Dict[int, str]) – A dictionary of options where each option is described by a value and the text to be shown for it.

default_value (int, optional) – The default value to be assigned to the parameter.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the options is not a dict, or if the options dictionary is empty.

ValueError – If the options dictionary contains a key that is not an int or a value that is not a str.

ValueError – If the options dictionary contains a value that is already defined as an option.

ValueError – If the default_value is not an int, or if the default_value is not a defined option.

add_file_parameter(name: str, label: str, description: str, file_extensions: str, select_multiple: bool = False, linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, parameter_group: str = None)

Adds a file parameter to the workflow description.

This will generate a file selection in the workflow UI.

Example:

Add a file parameter to select a file:

pwr_description.add_file_parameter(name='file', label='file_selector', description='file_selector', file_extensions='*.txt')

Example:

Add a file parameter to select multiple files that is only enabled in the UI when the linked boolean reference is set to True:

linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Enabled}pwr_description.add_file_parameter(name='file', label='file_selector', description='file_selector', file_extensions='*.txt', select_multiple=True, linked_visual_parameters=linked_visual_parameters)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the text field in the workflow UI.

description (str) – A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the workflow UI.

file_extensions (str) – The file extensions supported.

select_multiple (bool, optional) – Specifies if the parameter can contain multiple values. Defaults to False.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the file_extensions is not a str.

ValueError – If the select_multiple is not a bool.

add_float_parameter(name: str, label: str, description: str, default_value: float = 0.0, minimum_value: float = None, maximum_value: float = None, measurement_type: Enum | str = None, display_symbol: str = None, linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, parameter_group: str = None)

Adds a float parameter to the workflow description.

This will generate an float number field in the workflow UI.

Example:

Add a float parameter:

pwr_description.add_float_parameter(name='float', label='float_input', description='float_input', default_value=0.0)

Example:

Add a float parameter that is only visible in the UI when the linked boolean reference is set to True:

linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Visible}pwr_description.add_float_parameter(name='float', label='float_input', description='float_input', default_value=0.0, linked_visual_parameters=linked_visual_parameters)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the field in the workflow UI.

description (str) – A description of what the parameter represents. This text will be shown in the tooltip next to the field in the workflow UI.

default_value (float, optional) – If defined this specifies the default value to be assigned to the parameter. Defaults to 0.

minimum_value (float, optional) – If defined this specifies the lowest value the field can accept. Defaults to None.

maximum_value (float, optional) – If defined this specifies the highest value the field can accept. Defaults to None.

measurement_type (Union[Enum(str), str], optional) – If defined this specifies the measurement type of the parameter. Defaults to None.

display_symbol (str, optional) – If defined this specifies the units of the supplied parameter. This allows the workflow to ensure that the parameter will be in the given units irrespective of the display units in the Petrel project. Defaults to None.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the measurement_type is not Enum(str) or a str or None

ValueError – If the display_symbol is not a str or None

ValueError – If the display_symbol is defined while measurement_type is not defined, or the display_symbol is not defined while measeurement_type is defined

ValueError – If the default_value is not a float or int

ValueError – If the minimum_value or maximum_value is not a float or int or None

add_float_spinner_parameter(name: str, label: str, description: str, default_value: float, minimum_value: float, maximum_value: float, increment: float, measurement_type: Enum | str = None, display_symbol: str = None, linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, show_increment: bool = False, decimal_places: int = -1, parameter_group: str = None)

Adds a float spinner parameter to the workflow description.

This will generate a float spinner in the workflow UI.

Example:

Add a float spinner parameter:

pwr_description.add_float_spinner_parameter(name='float_spinner', label='float_spinner_input', description='float_spinner_input', default_value=0.0, minimum_value=-5.0, maximum_value=5.0, increment=0.2)

Example:

Add a float spinner parameter that is only visible in the UI when the linked boolean reference is set to True:

linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Visible}pwr_description.add_float_spinner_parameter(name='f_s', label='f_s_input', description='f_s_input', default_value=2.5, minimum_value=0.0, maximum_value=5.0, increment=0.1, linked_visual_parameters=linked_visual_parameters)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the field in the workflow UI.

description (str) – A description of what the parameter represents. This text will be shown in the tooltip next to the field in the workflow UI.

default_value (float) – The default value to be assigned to the parameter.

minimum_value (float) – The lowest value the field can accept.

maximum_value (float) – The highest value the field can accept.

increment (float) – The increment (step size) for the spinner control. Increment must be greater than zero.

measurement_type (Union[Enum(str), str], optional) – If defined this specifies the measurement type of the parameter. Defaults to None.

display_symbol (str, optional) – If defined this specifies the units of the supplied parameter. This allows the workflow to ensure that the parameter will be in the given units irrespective of the display units in the Petrel project. Defaults to None.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

show_increment (bool, optional) – Use this to specify if the increment value should be shown in the UI. Defaults to False.

decimal_places (int, optional) – Use this to specify the number of decimal places to show in the UI.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the measurement_type is not Enum(str) or a str or None

ValueError – If the display_symbol is not a str or None

ValueError – If the display_symbol is defined while measurement_type is not defined, or the display_symbol is not defined while measurement_type is defined

ValueError – If the default_value is not a float or int

ValueError – If the minimum_value or maximum_value is not a float or int

ValueError – If the increment is not a float or int, or the increment is less than or equal to zero

ValueError – If the decimal_places is not an int

add_folder_parameter(name: str, label: str, description: str, linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, default_folder: Enum | str = None, parameter_group: str = None)

Adds a folder parameter to the workflow description.

This will generate a folder selection in the workflow UI.

Example:

Add a folder parameter to select a folder:

pwr_description.add_folder_parameter(name='folder', label='folder_selector', description='folder_selector')

Example:

Add a folder parameter to select a folder that is only enabled in the UI when the linked enum reference is set to “Value3”:

linked_enum_ref = pwr_description.add_enum_parameter(name="enum1", label="enum1", description="enum1", options={1:"Value1", 2:"Value2", 3:"Value3"}, default_value=1)linked_visual_parameters = {ParameterState(linked_enum_ref, 3): VisualEnum.Enabled}pwr_description.add_folder_parameter(name='folder', label='folder_selector', description='folder_selector', linked_visual_parameters=linked_visual_parameters, default_folder=WellKnownFolderLocationsEnum.Documents)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the text field in the workflow UI.

description (str) – A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the workflow UI.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

default_folder (Union[Enum, str], optional) – If defined this specifies the initially selected folder. Defaults to None.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the default_folder is not Enum(str) or a str

add_integer_parameter(name: str, label: str, description: str, default_value: int = 0, minimum_value: int = None, maximum_value: int = None, linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, parameter_group: str = None)

Adds an integer parameter to the workflow description.

This will generate an integer number field in the workflow UI.

Example:

Add an integer parameter:

pwr_description.add_integer_parameter(name='int', label='int_input', description='int_input', default_value=0)

Example:

Add an integer parameter that is only visible in the UI when the linked boolean reference is set to True:

linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Visible}pwr_description.add_integer_parameter(name='int', label='int_input', description='int_input', default_value=0, linked_visual_parameters=linked_visual_parameters)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the field in the workflow UI.

description (str) – A description of what the parameter represents. This description will be shown in the tooltip next to the field in the workflow UI.

default_value (int, optional) – If defined this specifies the default value to be assigned to the parameter. Defaults to 0.

minimum_value (int, optional) – If defined this specifies the lowest value the field can accept. Defaults to None.

maximum_value (int, optional) – If defined this specifies the highest value the field can accept. Defaults to None.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the default_value is not an int.

ValueError – If the minimum_value or maximum value is not an int or None.

add_integer_spinner_parameter(name: str, label: str, description: str, default_value: int, minimum_value: int, maximum_value: int, linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, parameter_group: str = None)

Adds an integer spinner parameter to the workflow description.

This will generate an integer spinner field in the workflow UI.

Example:

Add an integer spinner parameter:

pwr_description.add_integer_spinner_parameter(name='int_spinner', label='int_spinner_input', description='int_spinner_input', default_value=0, minimum_value=0, maximum_value=10)

Example:

Add an integer spinner parameter that is only visible in the UI when the linked boolean reference is set to True:

linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Visible}pwr_description.add_integer_spinner_parameter(name='i_s', label='i_s_input', description='i_s_input', default_value=0, minimum_value=0, maximum_value=10, linked_visual_parameters=linked_visual_parameters)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the field in the workflow UI.

description (str) – A description of what the parameter represents. This description will be shown in the tooltip next to the field in the workflow UI.

default_value (int) – This specifies the default value to be assigned to the parameter.

minimum_value (int) – This specifies the lowest value the field can accept.

maximum_value (int) – This specifies the highest value the field can accept.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the default_value is not an int.

ValueError – If the minimum_value or maximum value is not an int.

add_object_ref_parameter(name: str, label: str, description: str, object_type: Enum | str, template_type: Iterable[Enum | str] | Enum | str = None, measurement_type: Enum | str = None, select_multiple: bool = False, linked_input_name: ParameterRef | str = None, linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, parameter_group: str = None)

Adds an object_ref parameter to the workflow description.

This will generate a domain object selector (blue arrow control) in the workflow UI.

Note: If select_multiple is False then the parameter value will be set to the DROID of the selected domain object.

If select_multiple is True then the parameter value will be a list of DROIDs for the selected domain objects.

Example:

Add a single object reference parameter to select a well object:

pwr_description.add_object_ref_parameter(name='well', label='well_selector', description='well_selector', object_type='well')

Example:

Add two object reference parameters to select a well object and then select multiple well continuous log objects for the selected well. Both drop-downs are only set to be visible when the linked boolean parameter is set to True:

linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Visible}well_ref = pwr_description.add_object_ref_parameter(name='well', label='well_selector', description='well_selector', object_type=DomainObjectsEnum.Well, select_multiple=False, linked_visual_parameters=linked_visual_parameters)well_log_ref = pwr_description.add_object_ref_parameter(name='well_log', label='well_log_selector', description='well_log_selector', object_type=DomainObjectsEnum.WellContinuousLog, select_multiple=True, linked_input_name=well_ref, linked_visual_parameters=linked_visual_parameters)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the dropbox in the workflow UI.

description (str) – A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the workflow UI.

object_type (Union[Enum(str), str]) – The domain object type that must be supplied for this parameter. The workflow UI will limit the user to selecting only domain objects for this type.

template_type (Union[Iterable[Union[Enum(str), str]], Enum(str), str], optional) – If defined this specifies the template types accepted for the parameter. Defaults to None.

measurement_type (Union[Enum(str), str], optional) – If defined this specifies the measurement type accepted for the parameter. Defaults to None.

select_multiple (bool, optional) – Specifies if the parameter can contain multiple values. Defaults to False.

linked_input_name (Union[ParameterRef, str], optional) – If defined this links to another parameter defined in the workflow which must be specified to enable this parameter in the workflow UI. Can be specified either using the ParameterRef of another parameter or the name of the parameter as a string. Defaults to None.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the object_type is not Enum(str) or a str

ValueError – If the template_type is not Iterable[Enum(str)] or a Iterable[str] or Enum(str) or a str

ValueError – If the measurement_type is not Enum(str) or a str

ValueError – If the select_multiple is not a bool

ValueError – If the linked_input_name is not a str or ParameterRef

add_radio_parameter(name: str, label: str, description: str, options: Dict[int, str], default_value: int = None, linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, parameter_group: str = None)

Adds a radio parameter to the workflow description.

This will generate set of radio buttons in the workflow UI.

Example:

Add a radio parameter to select between three options:

pwr_description.add_radio_parameter(name='radio', label='radio_selector', description='radio_selector', options={1:"Option1", 2:"Option2", 3:"Option3"})

Example:

Add a radio parameter to select between three options that is only enabled in the UI when the linked boolean reference is set to True:

linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Enabled}pwr_description.add_radio_parameter(name='radio', label='radio_selector', description='radio_selector', options={1:"Option1", 2:"Option2", 3:"Option3"}, linked_visual_parameters=linked_visual_parameters)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the text field in the workflow UI.

description (str) – A description of what the parameter is used for. This description will be shown in the tooltip next to the radio buttons in the workflow UI.

options (Dict[int, str]) – A dictionary of options where each option is described by a value and the text to be shown for it.

default_value (int, optional) – The default value to be assigned to the parameter.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the options is not a dict, or if the options dictionary is empty.

ValueError – If the options dictionary contains a key that is not an int or a value that is not a str.

ValueError – If the options dictionary contains a value that is already defined as an option.

ValueError – If the default_value is not an int, or if the default_value is not a defined option.

add_string_parameter(name: str, label: str, description: str, default_value: str = '', linked_visual_parameters: Dict[ParameterState, VisualEnum] = None, parameter_group: str = None)

Adds a string parameter to the workflow description.

This will generate a text field in the workflow UI.

Example:

Add a string parameter to input a string:

pwr_description.add_string_parameter(name='string', label='string_input', description='string_input', default_value='Please type someting here')

Example:

Add a string parameter that is only enabled in the UI when the linked boolean reference is set to True:

linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Enabled}pwr_description.add_string_parameter(name='string', label='string_input', description='string_input', default_value='You can only type here after checking the checkbox', linked_visual_parameters=linked_visual_parameters)

Parameters:

name (str) – The name of the object created in the parameters dictionary. This name must be unique within the workflow.

label (str) – The label text that will be displayed next to the text field in the workflow UI.

description (str) – A description of what the parameter is used for. This description will be shown in the tooltip next to the text field in the workflow UI.

default_value (str, optional) – The default value to be assigned to the parameter.

linked_visual_parameters (Dict[ParameterState, VisualEnum], optional) – Use this to specify a link between another boolean, enum or object_ref parameter state and this parameter’s visual state. If the linked visual parameter have correct state the parameter will be enabled/visible accordingly. If adding multiple linked visual parameters, all must be true for the parameter to be enabled/visible. Defaults to None.

parameter_group (str, optional) – Use this to specify the parameter group this parameter belongs to. Defaults to None.

Returns:

a reference to the parameter that was added

Return type:

ParameterRef

Raises:

ValueError – If the name is not a string, is not lowercase or contains spaces.

ValueError – If the name is already used in the workflow.

ValueError – If the label is not a string.

ValueError – If the description is not a string.

ValueError – If the linked_visual_parameters is not a dict where all keys are ParameterState and all values are VisualEnum.

ValueError – If the default_value is not a str.

get_default_parameters() → Dict[str, object]

Returns a dictionary of the default values for parameters required by the workflow.

This is useful when testing the workflow outside of PWR.

Returns:

_description_

Return type:

Dict[str, object]

is_valid() → bool

Returns a bool indicating if the workflow is valid

Returns:

Indicates the if the workflow is valid

Return type:

bool

====

DomainObjectsEnum

class cegalprizm.pycoderunner.DomainObjectsEnum(value, names=<not given>, *values, module=None, qualname=None, type=None, start=1, boundary=None)



Warning

Deprecated: This enum is deprecated and will be removed in a future version.

The DomainObjectsEnum defines the supported domain objects

PropertiesCheckshots

FaultInterpretation

InterpretationFolder

GlobalLogContinuous

GlobalLogDiscrete

Grid

GridContinuousProperty

GridDiscreteProperty

GridZone

GridSegment

HorizonInterpretation

HorizonInterpretation3D

HorizonInterpretation3DProperty

Investigation

ObservedDataset

ObservedDatasetForWell

ObservedData

PointSet

PolylineSet

PolylineSetContinuousProperty

PolylineSetDiscreteProperty

SavedSearch

Seismic2D

SeismicLine

Seismic3D

SeismicCube

Surface

SurfaceContinuousProperty

SurfaceContinuousAttribute

SurfaceDiscreteProperty

SurfaceDiscreteAttribute

TemplateContinuous

TemplateDiscrete

Wavelet

WellsFolder

Well

WellContinuousLog

WellDiscreteLog

WellAttribute

WellMarkerCollection

WellMarkerContinuousProperty

WellMarkerDiscreteProperty

WellMarkerStratigraphy

WellSurvey

WellSurvey_XY_Z

WellSurvey_XY_TVD

WellSurvey_Dx_Dy_TVD

WellSurvey_MD_Inc_Azi

WellSurvey_Explicit

WellPerforation

WellCasing

WellPlugback

WellSqueeze

WellCompletion

===

MeasurementNamesEnum

class cegalprizm.pycoderunner.MeasurementNamesEnum(value, names=<not given>, *values, module=None, qualname=None, type=None, start=1, boundary=None)

The MeasurementNamesEnum defines commonly used measurement names

PropertiesStandardDepthIndex

ShortTime

Length

Dimensionless

Frequency

Rotation

Area

Velocity

Ratio

AcousticImpedance

Temperature

PressureDensity

Compressibility

InverseArea

ThermalConductivity

ThermalConductionTransmissibility

VolumetricHeatCapacity

VolumetricHeatCapacityPerTemperature

HeatTransferCoefficient

SpecificHeatCapacityPerTemperature

SpecificHeatCapacityPerTemperatureSquared

VaporizationHeat

InverseTemperature

InverseTemperatureSquared

ThermalResistivity

Porosity

Permeability

Transmissibility

Pressure

DynamicViscosity

Mobility

SimulationTime

Diffusivity

CoalGasVolumePerMass

SurfaceTension

Volume

ReservoirProductionVolume

LiquidProductionVolume

GasProductionVolume

LiquidFormationVolumeFactor

GasFormationVolumeFactor

LowAcousticSlowness

APIGammaRay

UraniumConcentration

ThoriumConcentration

PotassiumConcentration

Percent

Resistivity

Density

LowElectricPotential

Conductivity

CylinderDiameter

SmallRotationPerLength

PressureGradient

ReservoirFlowrate

Fraction

LiquidProductivityIndex

GasProductivityIndex

CompressibleFluidProductivityIndex

PipeCrossSectionalArea

PressurePerFlowrateSquared

LiquidFlowrate

GasFlowrate

HighMass

HighMassPerTime

LiquidToLiquidRatio

EnergyRate

ReservoirEnergyDensity

MassPerArea

PowerPerArea

GeologicTime

HydrogenIndex

ThermalGradient

Probability

MolarMass

AmountOfSubstance

MolarRate

MolarVolume

MolarDensity

MolarEnthalpy

NormalizedQuantity

Mass

MassPerTime

MassConcentration

CoalGasConcentration

Holdup

ErosionalVelocity

ErosionRate

CorrosionRate

MotorSpeed

TimeDip

===

TemplateNamesEnum

class cegalprizm.pycoderunner.TemplateNamesEnum(value, names=<not given>, *values, module=None, qualname=None, type=None, start=1, boundary=None)

The TemplateNamesEnum defines commonly used template names

PropertiesFracturePatchSet

CompletionCasedLog

CompletionGeneral

CompletionLinedLog

Perforation

ProductionStatus

SlidingSleevePositions

HistoryMatchQualitativeCoarse

HistoryMatchQualitativeFine

HoleClassification

ActiveCellFlag

Bodies

BooleanProperty

BoreholeIndex

ConnectedVolume

DictionaryGeneral

DipClassification

Facies

Faults

Fluids

FluvialFacies

Horizons

Lithologies

RegionId

Segments

StairstepLayers

StairstepSegments

Strings

TimeStratigraphy

ZonesAllK

ZoneLog

ZonesMain

ZonesSub

ZonesSubHierarchy

FaultDisplacement

FaultPermeability

FaultThickness

ShaleGougeRatio

TransmissibilityMultiplier

RockDisplacement

Strain

StressEffective

StressPrincipal

StressTotal

AboveContact

Area

CellAngle

CellDeltaX

CellDeltaY

CellDeltaZ

CellInsideOut

CellTopDepth

DepthContactGasOil

DepthContactGasWater

DepthContactOilWater

DipAngle

DipAzimuth

DipQuality

Distance

MeasuredDepth

Residual

TimeDelta

TimeOneWay

TimeTwoWay

Uncertainty

CompressibilityRock

CompressibilityWater

DifferentialTemperature

HeatTransferCoefficient

HeatTransmissibility

HeatTransmissibilityI

HeatTransmissibilityJ

HeatTransmissibilityK

ImpedanceAcoustic

ImpedanceElasticPP

ImpedanceElasticPS

ImpedanceP

ImpedanceS

InverseTemperature

InverseTemperatureSquared

Lambda

LambdaTimesRho

MatrixFractureCoupling

MatrixFractureThermalCoupling

ModulusBulk

ModulusCompressional

Mu

MuTimesRho

PoissonRatio

ReflectionCoefficient

RelativeTemperature

RockDensity

RockHeatCapacity

RockHeatCapacityTemp

ShearModulus

Temperature

ThermalConductivity

ThermalConductivityCombined

ThermalConductivityGas

ThermalConductivityOil

ThermalConductivityRock

ThermalConductivitySolid

ThermalConductivityWater

ThermalResistance

VaporizationHeat

Velocity

VelocityAverage

VelocityGradientInitialV0

VelocityGradientKFactor

VelocityGradientKFactorInTime

VelocityInterval

VelocityP

VelocityRatio

VelocityS

VelocityStack

Wavelet

ZFactor

KFactor

V0Factor

SpecificHeatCapacityPerTemperature

SpecificHeatCapacityPerTemperatureSquared

BulkDensityCorrection

Caliper

CaliperAcoustic

CaliperMechanical

Conductivity

ConductivityDeep

ConductivityMedium

ConductivityShallow

ConstantMudResistivity

ConstantWaterResistivity

ConstantWaterSalinity

Deepening

Density

DensityCompensatedBulk

DensityDownwardAzimuth

DensityUpwardAzimuth

DoglegSeverity

GammaRay

GammaRayPotassium

GammaRayThorium

GammaRayUranium

GeneralProduction

Neutron

OpenHole

PerforationConnectivity

PhotoelectricFactor

PressureGradient

PSonic

Resistivity

ResistivityDeep

ResistivityMedium

ResistivityMicro

ResistivityShallow

Sonic

SpontaneousPotential

SSonic

VolumeOfShale

WellBoreRadius

CapillaryPressure

FractionalFlow

RelativePermeability

T2Distribution

AmountOfSubstance

CoalGasConcentration

Concentration

CorrosionRate

DistributionFrequency

ErosionRate

ErosionalVelocity

Fraction

FromFacies

GasFlowRate

General

GeneralDerivative

GeneralInteger

HistoryMatchConstant

HistoryMatchPolyLine

HistoryMatchStepWise

HistoryMatchQuantitative

Holdup

Intensity

Mass

MassFlowRate

MolarDensity

MolarEnthalpy

MolarMass

MolarRate

MotorSpeed

MolarVolume

Percent

PlugbackTotalDepth

PrincipalComponent

Probability

OilFlowRate

SummaryData

TotalDepth

Variance

WaterFlowRate

Adsorption

CoalGasVolumePerMass

Diffusivity

GasHeatCapacity

GasVelocity

LithologyFraction

Mobility

NetGross

NetPay

OilHeatCapacity

OilVelocity

Permeability

PermeabilityI

PermeabilityIJ

PermeabilityIK

PermeabilityJ

PermeabilityJK

PermeabilityK

PermeabilityMF

PermeabilityX

PermeabilityXY

PermeabilityXZ

PermeabilityY

PermeabilityYZ

PermeabilityZ

PoreVolumeMultiplier

Porosity

PorosityEffective

PorosityTotal

Pressure

SaturationCriticalGas

SaturationCriticalWater

SaturationGas

SaturationGasResidualOil

SaturationHydrocarbons

SaturationIrreducibleGas

SaturationIrreducibleWater

SaturationOil

SaturationPressure

SaturationWater

SaturationWaterResidualOil

SimulationTime

StreamlineBoundaryID

SurfaceTension

TransmissibilityI

TransmissibilityJ

TransmissibilityK

ViscosibilityWater

ViscosityGas

ViscosityOil

ViscosityWater

WaterHeatCapacity

WaterVelocity

WellIndex

EnergyRate

EnthalpyFlowRate

GasMassProduction

GasMassProductionRate

InjectionRateGas

InjectionRateOil

InjectionRateReservoirVolume

InjectionRateWater

OilMassProduction

OilMassProductionRate

ProductionGas

ProductionLiquid

ProductionOil

ProductionRateGas

ProductionRateLiquid

ProductionRateOil

ProductionRateReservoirVolume

ProductionRateWater

ProductionReservoirVolume

ProductionWater

RatioGasOil

RatioOilGas

RatioWaterGas

ReservoirEnergyDensity

UptimeFraction

WaterCut

WaterMassProduction

WaterMassProductionRate

SeismicAntTracking

SeismicAttenuation

SeismicConsistentCurvature

SeismicContrast

SeismicCorrelationCoefficient

SeismicCosineOfPhase

SeismicDefault

SeismicDipAngle

SeismicDipAzimuth

SeismicDipError

SeismicDipRatio

SeismicEdge

SeismicFrequency

SeismicGradient

SeismicLocalFlatness

SeismicPhase

SeismicPolarity

SeismicShapeIndex

SeismicVariance

ElevationDepth

ElevationProperty

ElevationTime

GeneralTime

ThicknessDepth

ThicknessGeneral

ThicknessTime

ThicknessTrueStratigraphic

ThicknessTrueVertical

FormationVolumeFactorGas

FormationVolumeFactorOil

FormationVolumeFactorWater

HCPVGas

HCPVGasMap

HCPVOil

HCPVOilMap

RatioSolutionGasOil

RatioVaporizedOilGas

RecoverableGas

RecoverableGasMap

RecoverableOil

RecoverableOilMap

RecoveryFactor

RockVolume

VolumeBulk

VolumeBulkMap

VolumeInitialInPlaceGas

VolumeInitialInPlaceGasMap

VolumeInitialInPlaceOil

VolumeInitialInPlaceOilMap

VolumeInPlaceGas

VolumeInPlaceOil

VolumeInPlaceWater

VolumeNet

VolumeNetMap

VolumePore

VolumePoreMap

STOIIP

STOIIPMap

GIIP

GIIPMap

CompletionDepth

CompletionDiameter

ConnectionTransmissibility

Skin

PermeabilityLength

PiLiquid

PiGas

PiCompressibleFluid

PiMultiplier

Roughness

DrainageRadius

CompletionArea

IcdStrength

FracturePermeability

FractureAperture

FractureCompressibility

GasGeneration

OilGeneration

VitriniteReflectance

TransformationRatio

HeatFlow

GeologicalTimeScale

HydrogenIndex

ThermalGradient

WellCalibrationMeasured

WellCalibrationCalculated

SI

GI

E

LambdaOverMu

EI2

EI3

SEI1

SEI2

EEI

Age

===

VisualEnum

class cegalprizm.pycoderunner.VisualEnum(value, names=<not given>, *values, module=None, qualname=None, type=None, start=1, boundary=None)

PropertiesEnabled

Visible

===

ParameterState

class cegalprizm.pycoderunner.ParameterState(parameter_ref: ParameterRef, state)

A class to define a desired parameter state. Used as the key in the linked_visual_parameters dictionary when add_*_parameter is called on the WorkflowDescription object. The ParameterState links the visual state of a parameter to the state of another parameter.

Example:

Add an integer parameter that is only enabled in the UI when the linked boolean reference is True (Integer value can only be set when checkbox is checked):

linked_bool_ref = pwr_description.add_boolean_parameter(name="linked_bool", label="linked_bool", description="linked_bool", default_value=False)linked_visual_parameters = {ParameterState(linked_bool_ref, True): VisualEnum.Enabled}pwr_description.add_integer_parameter(name="int", label="int", description="int", default_value=0, linked_visual_parameters=linked_visual_parameters)

Example:

Add an object reference parameter that is only visible in the UI when the linked enum reference is set to a specific value (Well selector only shows when the enum drop-down is set to Value3):

linked_enum_ref = pwr_description.add_enum_parameter(name="enum1", label="enum1", description="enum1", options={1:"Value1", 2:"Value2", 3:"Value3"}, default_value=1)linked_visual_parameters = {ParameterState(linked_enum_ref, 3): VisualEnum.Visible}pwr_description.add_object_ref_parameter(name='well', label='well_selector', description='well_selector', object_type='well', select_multiple=False, linked_visual_parameters=linked_visual_parameters)

Example:

Add a float parameter that is only enabled in the UI when the linked object reference parameter has a selection (Float value can only be set when a well is selected):

 linked_object_ref = pwr_description.add_object_ref_parameter(name='well', label='well_selector', description='well_selector', object_type='well', select_multiple=False)

 linked_visual_parameters = {ParameterState(linked_object_ref, ObjectRefStateEnum.Selected): VisualEnum.Enabled}

 pwr_description.add_float_parameter(name="float", label="float", description="float", default_value=0.0, linked_visual_parameters=linked_visual_parameters).. rubric:: Functions.. autosummary::



   __init__

   as_string

   is_valid

====

ParameterRef

class cegalprizm.pycoderunner.ParameterRef(name: str, workflow_input: BaseWorkflowInput)

A reference to a parameter in a workflow description.

Functions__init__(name, workflow_input)

is_valid_state(state)

state_as_string(state)

====

ObjectRefStateEnum

class cegalprizm.pycoderunner.ObjectRefStateEnum(value, names=<not given>, *values, module=None, qualname=None, type=None, start=1, boundary=None)

PropertiesSelected

NotSelected



===

FileServices

class cegalprizm.pycoderunner.FileServices

Functions__init__()

download_file(src_path, dest_path[, overwrite])

Download a file to pycoderunner from the source path

upload_file(src_path, abs_dest_path[, ...])

Upload a file from the pycoderunner to the destination path

static download_file(src_path: str, dest_path: str, overwrite: bool = False)

Download a file to pycoderunner from the source path

Parameters:

src_path (str) – the source path of the file

dest_path (str) – the destination path to save the file on the pycoderunner

overwrite (bool, optional) – Whether or not to permit file overwrite if the file exists on the destination path. Defaults to False.

Raises:

ValueError – if there is an issue with the provided arguments

Exception – If there was an issue downloading the file.

static upload_file(src_path: str, abs_dest_path: str, overwrite: bool = False, open_file_on_complete: bool = False)

Upload a file from the pycoderunner to the destination path

Parameters:

src_path (str) – the source path of the file on the pycoderunner

abs_dest_path (str) – the absolute destination path to upload the file to

overwrite (bool, optional) – whether or not you want to overwrite the file if already existing on the destination path. Defaults to False.

open_file_on_complete (bool, optional) – whether or not you want the file to be opened after uploading. Defaults to False.

Raises:

ValueError – if there is an issue with the provided arguments

Exception – if there is an issue uploading the file

Returns:

the empty upload result message if successful

Return type:

UploadFileResult

====

Release Notes Version 1
What’s new in 1.4.0 (November 2025)
Prizm Workflow Runner 1.4 introduces new domain object support, new UI components, and several improvements to workflow execution reliability and performance. This release also includes important bug fixes and stability enhancements across both the plugin and pycoderunner.

New functionality
New supported domain objects
Prizm Workflow Runner 1.4 adds support for selecting Folders, Global Well Log Folders, and Property Folders as workflow inputs.

../../../_images/new_domain_objects.png
Note

These domain objects are only available through the new DomainObjectEnum in Python Tool Pro. They are not included in the deprecated PWR DomainObjectEnum. Update your scripts to use the new enum from PTP.

Folders
from cegalprizm.pycoderunner import WorkflowDescription
from cegalprizm.pythontool import DomainObjectsEnum

pwr_description.add_object_ref_parameter(
    name="folder",
    label="Select a folder",
    description="Choose a folder",
    object_type=DomainObjectsEnum.Folder
)
Global Well Log Folders
from cegalprizm.pycoderunner import WorkflowDescription
from cegalprizm.pythontool import DomainObjectsEnum

pwr_description.add_object_ref_parameter(
    name="gwl_folder",
    label="Select a GWL folder",
    description="Choose a Global Well Log folder",
    object_type=DomainObjectsEnum.GlobalWellLogFolder
)
Property Folders
from cegalprizm.pycoderunner import WorkflowDescription
from cegalprizm.pythontool import DomainObjectsEnum

pwr_description.add_object_ref_parameter(
    name="property_folder",
    label="Select a property folder",
    description="Choose a property folder",
    object_type=DomainObjectsEnum.PropertyFolder
)
New UI elements
Radio buttons
Radio buttons are now supported as a new UI element in Prizm Workflow Runner.

They work similarly to enumerators but are better suited when presenting a small number of mutually exclusive options. Enumerators remain recommended for larger lists.

../../../_images/radio.gif
You can add a radio-button parameter using add_radio_parameter():

pwr_description.add_radio_parameter(
    name="radio",
    label="Select an option",
    description="Choose one of the available options",
    options={1: "Option 1", 2: "Option 2", 3: "Option 3"}
)
Spinner inputs
Integer and float spinners have been added as new UI elements in Prizm Workflow Runner. They allow users to enter numeric values with clear minimum/maximum limits and optional step sizes.

../../../_images/spinners.gif
Integer spinners

Provide whole-number input with defined bounds:

pwr_description.add_integer_spinner_parameter(
    name="int_val",
    label="Integer value",
    description="Select an integer",
    default_value=0,
    minimum_value=0,
    maximum_value=10
)
Float spinners

Support decimal values, increments, and optional unit symbols:

pwr_description.add_float_spinner_parameter(
    name="float_val",
    label="Float value",
    description="Select a float",
    default_value=0.0,
    minimum_value=-5.0,
    maximum_value=5.0,
    increment=0.2
)
Parameter groupings
Parameter grouping is now supported in Prizm Workflow Runner, allowing workflow authors to organize input parameters into collapsible categories in the UI. This improves readability and reduces clutter, especially for complex workflows with many inputs.

../../../_images/groupings.png
Groups are defined using the new parameter_group argument on any parameter:

pwr_description.add_object_ref_parameter(
    name="input_surface",
    label="Surface",
    description="Select a surface",
    object_type=DomainObjectsEnum.Surface,
    parameter_group="Inputs"
)
All parameter types (object refs, booleans, enums, spinners, radio buttons, etc.) support grouping.

Changed functionality
Listing workflows no longer waits for busy pycoderunners; workflows from available runners are listed immediately.

Each executed workflow is now logged with user identity, workflow name, and execution duration.

Running a PWR workflow no longer opens the Task Manager pane.

Reduced message log noise when running PWR inside a Petrel workflow; only print statements and error messages are now shown.

Improved the error message shown when a Petrel workflow references a missing PWR workflow, making it clear which workflow is unavailable and how to resolve the issue.

Performance improvements
Improved the performance of running Prizm Workflow Runner scripts inside Petrel workflows, with up to a 5x speed improvement observed under certain test conditions.

Deprecations and Removals
Deprecation of PWR DomainObjectEnum
Important

The DomainObjectEnum previously provided in the Prizm Workflow Runner API is now deprecated and has been replaced by the new DomainObjectEnum in the Python Tool Pro API. Users must update their workflow scripts to use the PTP version. The deprecated PWR enum will be removed in PWR 2.0.

To learn more about the updated enum and the differences between object types, refer to the User Guide or the Python API documentation.

Bug fixes
Fixed an issue where the PWR output log was cleared while a workflow was still running. The output is now preserved during execution and is only cleared when using the Refresh, Run Workflow actions.

Fixed an issue where PWR would indefinitely attempt to start a pycoderunner for a deleted or missing Python environment.

Fixed an issue where PWR could execute workflows using the wrong Petrel instance when multiple Petrel sessions were open.

Fixed an issue where PWR could lock up Petrel when multiple Petrel instances were open by increasing the default number of concurrent pycoderunner tasks from 1 to 4.

Fixed an issue where scripts and notebooks without a PWR header were incorrectly listed as workflows.

Fixed an issue where switching between workflows during execution cleared the selected input objects in the UI; input parameters are now preserved.

Fixed a “Recursive read lock acquisitions” error that occurred when running PWR inside a Petrel Workflow.

Fixed an issue where PWR could not restore its state or list workflows after the Cegal script directory was deleted and recreated.

Fixed an issue where the Refresh button remained enabled while a workflow was running; it is now disabled during execution to prevent loss of output.

Added support for multiline import statements in workflow scripts, ensuring they are correctly recognized and validated by PWR.

Improved cursor behavior when running a workflow; the Wait cursor now appears only during non-interactive phases to avoid giving the impression that Petrel is frozen.

Fixed an issue where Petrel workflows continued running even when a PWR workstep failed;

Fixed an issue where opening a PWR workstep inside a Petrel workflow reset the selected script and input parameters.

What’s new in 1.3.0 (July 2025)
Prizm Workflow Runner 1.3 adds support for interpretation folders, well attributes, and saved searches , along with performance improvements and various bug fixes.

New functionality
Support for interpretation folders
Interpretation folders are added as an object type in pycoderunner.

pwr_description.add_object_ref_parameter(name="interpretation_folder", label="Select an interpretation folders", description="Choose an interpretation folders", object_type=DomainObjectsEnum.InterpretationFolder)
Support for well attributes
Well attributes are added as an object type in pycoderunner.

pwr_description.add_object_ref_parameter(name="well_attributes", label="Select well attributes", description="Choose well attributes", object_type=DomainObjectsEnum.WellAttribute)
Support for saved searches
Saved searches are added as an object type in pycoderunner.

pwr_description.add_object_ref_parameter(name="saved_searches", label="Select a saved search", description="Choose a saved search", object_type=DomainObjectsEnum.SavedSearch)
Note

Dynamic saved searches are not listed in the generated PWR dropdown. However, you can still select them by highlighting (clicking) the saved search in the Petrel input tree and then using the blue arrow to add it in the PWR UI.

Bug fixes
Fixed a performance issue introduced in PWR 1.2.0 that slowed down workflow script execution.

Fixed an issue where refreshing workflows in Prizm Workflow Runner did not preserve the previously selected workflow.

Fixed an issue where PyCodeRunner would crash if a workflow script was invalid or contained unsupported characters.

Fixed an issue where Petrel could freeze when starting PyCodeRunner with corrupted or invalid workflow scripts

Fixed an issue where instantiating PetrelConnection inside a Prizm Workflow Runner description would lock Petrel.

Fixed a crash that could occur when switching projects multiple times after selecting a category and workflow in Prizm Workflow Runner.

Fixed an issue where Prizm Workflow Runner could hang on first load when opening projects saved with a workflow selected.

What’s new in 1.2.2 (June 2025)
Prizm Workflow Runner 1.2.2 is a patch release with bug fixes and has been included in the Blueback Investigator 6.0.1 release.

Bug fixes
Fixed a file handle issue where pyenvs subprocesses could block Petrel project saves.

What’s new in 1.2.1 (April 2025)
Prizm Workflow Runner 1.2.1 is a patch release with bug fixes.

Only the Prizm Workflow Runner Petrel plugin component has been updated. There is no change to the Python package, which remains at version 1.2.0 — so you do not need to update the Python environment.

Bug fixes
Fixed an issue where the PWR status would not update after the user disconnected and reconnected to the Hub server.

What’s new in 1.2 (March 2025)
UI and UX changes
Prizm Environments status indicator
The PWR UI now has a status indicator for the Prizm Environments tool. The indicator will show if Prizm Environments is Creating a new environment or Running a pycoderunner inside a Prizm environment.

../../../_images/PWRUIupdate.png
Listing the available PWR workflows
Previously, listing the available PWR workflows required a Prizm license, triggering an initial warning pop-up instructing users to authenticate via Cegal Keystone and click the Refresh button.

With this update, listing workflows no longer requires a Prizm license. As a result, the initial warning message has been removed.

../../../_images/refreshPWRerror.png
Refresh button functionality
Previously, clicking the Refresh button in the PWR UI triggered a license check. This behavior has been updated—refreshing the workflow list no longer checks for a license. Instead, the license validation now occurs only when running a workflow.

Improved messaging when PWR is not configured
Previously, if PWR was not configured while running with a local hub server, users would encounter a warning pop-up.

With this update, instead of a pop-up, the PWR UI will now be disabled and will display clear instructions on how to proceed.

../../../_images/PWRUIstatus.png
Improved messaging when Petrel is not connected to a local Hub server
Previously, when Petrel was not connected to a local Cegal Hub server, users would receive a warning pop-up.

With this update, the PWR UI is now disabled in such cases, and clear instructions are displayed within the interface to guide users on how to proceed.

../../../_images/PWRUIHubStatus.png
New functionality
Support for completion data
Completion data objects are added as an object type in pycoderunner. Supported completion objects are:

Perforation

CasingString

Plugback

Squeeze

Completion

Support for grid segments
Grid segments are added as an object type in pycoderunner.

pwr_description.add_object_ref_parameter(name="grid_segment", label="Select a grid segment", description="Choose a grid segment", object_type=DomainObjectsEnum.GridSegment)
Support for marker stratigraphies
Well marker stratigraphies are added as an object type in pycoderunner.

pwr_description.add_object_ref_parameter(name="wellmarkerstratigraphy", label="Select a well marker stratigraphy", description="wellmarkerstratigraphy", object_type=DomainObjectsEnum.WellMarkerStratigraphy)
Changed functionality
Folder UI allows copy&paste folder
When using the ‘add_folder_parameter’ method a different winform UI is displayed to the Petrel user to allow pasting the folder path from the clip board.

Improvements to linked_input_name
Allowing combination of “select multiple” and “linked_input_name”.

Bug fixes
Select_multiple returned the parent grid of selected grid segments not the dictionary of segments

pycoderunner could not handle empty paths passed into the workflow repository flag

Inputs linked to both a linked_input_name and a linked_visual_parameters are enabled incorrectly

When running a Petrel Workflow which contains a Prizm Workflow work-step, user input should not be required if user is authenticated

What’s new in 1.1 (May 2024)
New functionality
Link reference parameter to user selection
It is now possible to link reference parameters to other reference parameters. Parameters can be set Enabled/Disabled or Visible/Hidden based on user selection in other parameters. Reference parameters of type ‘Boolean’, ‘Enumerator’ or ‘Object’ can be linked to any other reference parameters.

Auto select domain object
In cases where there is only on domain object of the required type defined in the Cegal Prizm Workflow the Prizm Workflow Runner auto selects that one object.

Support for new domain objects
Prizm Workflow Runner and pycoderunner now support seismic fault interpretations and polyline set attributes.

Bug fixes
#58018 Circular reference hangs workflow
In the previous version a circular reference of a linked_input_name to it’s own name caused the Prizm workflow to hang. This is now changed to flag the Prizm workflow as invalid.

What’s new in 1.0.1 (April 2024)
New functionality
Petrel version support
Support for Petrel 2024

Support for Hub Labels
Prizm Workflow Runner 1.0.1 supports the use of Hub labels for the pycoderunner. Instances of a pycoderunner can be targeted with the use of a Hub label.

What’s new in 1.0
Version 1 of this release includes the Python library cegalprizm.pycoderunner and the Petrel* plug-in Prizm Workflow Runner. Both of these components are included in the installation of Cegal Prizm Investigator and Cegal Prizm Python Tool Pro.

Prizm Workflow Runner and cegalprizm.pycoderunner 1.0.0 (November 2023)
The plug-in Prizm Workflow Runner includes a tool in Marina that list available Cegal Prizm workflows in an UI and let’s users execute them without interacting with Python code.

The Python library cegalprizm.pycoderunner enables Python users to deploy their Python code to non-Python users as Cegal Prizm workflows. It is possible to create user input fields from the Python code.

Petrel* is a mark of SLB.

=====

Getting Started
This guide explains how to create your first Cegal Prizm workflow that can be executed from Petrel. It assumes that the Prizm Workflow Runner Plugin has already been installed and configured correctly on your system. Should you encounter any errors or issues, it is recommended that you revisit the Installation Guide to ensure all steps have been properly completed. For further assistance with specific problems or error messages, please consult the Troubleshooting Guide.

Basic concepts
Inside Petrel, in the Prizm Workflow Runner plugin, the user interface (UI) elements are dynamically generated through workflow descriptions embedded within your Python script or Jupyter notebook. This is achieved by defining a special section in your code that is specifically interpreted by Petrel to create the UI.

Defining the Workflow Description Section
The workflow description section is clearly marked at the beginning of your script to indicate where the UI generation code begins and ends. This is done using specific comments:

The start of the description is marked with # Start: PWR Description.

The end is indicated by # End: PWR Description.

Between these markers, you define the UI elements and their behavior.

Using the Workflow Description Function
Within this section, you utilize the WorkflowDescription function from the cegalprizm.pycoderunner module. This function allows you to specify basic information about your workflow, such as:

name : The name of the workflow as it will appear in Petrel.

category : The category under which your workflow will be listed in Petrel, aiding in organization and filtering.

description : A brief description of what your script or notebook does.

authors : Contact details of the workflow’s author.

version : The version number of your workflow.

Adding Input Objects
To allow users to select the data needed by the script, you can use the add_object_ref_parameter method. This method is part of the WorkflowDescription and is used to add Petrel input objects to your workflow.

An input object can be defined by providing the following parameters:

name : The name used to retrieve the object from Petrel.

label : The label shown in the Petrel UI for this input.

description : A description for this input, which can be viewed in Petrel’s help section.

object_type : The type of the object, defined using the DomainObjectsEnum.

# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription, MeasurementNamesEnum
from cegalprizm.pythontool import DomainObjectsEnum


pwr_description = WorkflowDescription(name="Name as shown in Petrel",
                                    category="Category used in filter",
                                    description="Describe here what your notebook or script does",
                                    authors="contact details of the workflow author",
                                    version="contact details of the workflow author")


pwr_description.add_object_ref_parameter(name='name_used_to_retrieve_object_from_petrel',
                                     label='LabelShownInPetrelUI',
                                     description='DescriptionAsShownInPetrelHelpButton',
                                     object_type=DomainObjectsEnum.Surface
                                     )

# End: PWR Description
The Workflow description in the code snippet above creates the following Petrel UI letting the user select a surface object as input:

../../_images/Example.png
By following this structure, you can create a user-friendly interface in Petrel that allows users to interact with your Python script or Jupyter notebook effectively, making your workflow both accessible and practical.

While the basics of creating a workflow description have been covered, there’s much more you can do to enhance the interaction between your script and the Petrel UI. The Petrel Python Plugin supports a variety of input object types and parameters, which can be utilized to tailor your workflow to specific needs and data types. Check out the User Guide to learn more.

Write your first script
Now you can start writing the Python code you want Petrel users to execute. In this example we will be using Python Tool Pro to retrieve a well log (Petrel user selects input log), smooth it by applying a rolling window and write it back to Petrel.

As mentioned above, we need to start the script with the workflow description. The Petrel user should be able to select the log and specify the window size. For the window size we’ll use an integer input parameter. We’ll set a default value of 40 and limit the user input to values between [2,300] :

# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription, MeasurementNamesEnum
from cegalprizm.pythontool import DomainObjectsEnum

pwr_description = WorkflowDescription(name="Smooth log",
                                    category="Petrophysics",
                                    description="This workflow creates a smoothed log by using a rolling window to smooth the log values. This is done using the rolling method from Pandas, which calculates a moving average over a specified window size.",
                                    authors="author@company",
                                    version="1.0")

pwr_description.add_object_ref_parameter(name="log_id", label="Select Log", description="Select the log you want to smooth", object_type=DomainObjectsEnum.WellLog)
pwr_description.add_integer_parameter(name="window_length", label="Window size", description="The window size to be used when smoothing", default_value=40, minimum_value=2, maximum_value=300)

# End: PWR Description
We’re now going to use Python Tool Pro to access the log selected by the Petrel User. As the Petrel users selects the input data, it is not possible assign the python variables using the Petrel path as you would normally do with Python Tool Pro.

Instead the Petrel guid is passed once the Petrel users run the workflow and stored in a dictionary called ‘parameters’. This dictionary has the names you used in the workflow description (e.g. pwr_description.add_object_ref_parameter(name=’log_id’,…)) as dictionary keys and the Petrel GUID or input value (for strings, float, bool, etc) as dictionary values.

It is then possible to retrieve the objects using the Python Tool Pro method get_petrel_projects_by_guids():

#import packages
from cegalprizm.pythontool import PetrelConnection
import pandas as pd
import numpy as np

#Connect to Petrel
ptp = PetrelConnection()

#Retrieve the log selected by the Petrel user, using its Guid and the.get_petrelobjects_by_guids function
petrel_objects = ptp.get_petrelobjects_by_guids([parameters['log_id']])
selected_log=petrel_objects[0]

#Retrieve the int value representing the window size
window_size=parameters['window_length']

print('Smoothing the ' + selected_log.petrel_name + ' from well ' + selected_log.well.petrel_name)
When you are writing your scripts, in order to test they work as expected, you can retrieve a Petrel object from your running Petrel instance in the conventional way, using Python Tool Pro (as shown bellow) . After ensuring everything works you can simply replace the input objects with the user select one.

# Example on how to retrieve Petrel objects in the conventional way, using Python Tool Pro :

#import packages
from cegalprizm.pythontool import PetrelConnection
import pandas as pd
import numpy as np

#Connect to Petrel
ptp = PetrelConnection()

#Retrieve the a log using Python Tool Pro
selected_log = ptp.well_logs['Input/Wells/A Wells/A10/Well logs/Gullfaks/Gamma']

#Define the window size
window_size = 40

print('Smoothing the ' + selected_log.petrel_name + ' from well ' + selected_log.well.petrel_name)
Now that we have the log and the window size, lets smooth it and write the results back to Petrel :

#Retrieve the log data as a dataframe
df = selected_log.as_dataframe()
logs_df = df[['MD','Value']]
logs_df = logs_df.set_index('MD')

# Smooth the log values
smooth_logs_df = logs_df['Value'].rolling(window=window_size, center=True).mean()


print('Creating new log: '+ selected_log.petrel_name+'_smoothed')

# Create a new log
new_sm_log = selected_log.clone(selected_log.petrel_name+'_smoothed')  # create the clone if it doesn't already exist

# Get columns of smooth_logs_df DataFrame and convert to NumPy ndarrays
md = smooth_logs_df.index.to_numpy()
new_sm_values = smooth_logs_df.to_numpy()

# Set the newly calculated values to the new log
new_sm_log.set_values(md, new_sm_values)
print('Log successfully created')
If you’re unfamiliar with the Python Tool Pro API, you can learn more about it here.

Now that we have our first script, we can copy it to our defined Workflow Repository and test it inside Petrel :

# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription, MeasurementNamesEnum
from cegalprizm.pythontool import DomainObjectsEnum

pwr_description = WorkflowDescription(name="Smooth log",
                                    category="Petrophysics",
                                    description="This workflow creates a smoothed log by using a rolling window to smooth the log values. This is done using the rolling method from Pandas, which calculates a moving average over a specified window size.",
                                    authors="author@company",
                                    version="1.0")

pwr_description.add_object_ref_parameter(name="log_id", label="Select Log", description="Select the log you want to smooth", object_type=DomainObjectsEnum.WellLog)
pwr_description.add_integer_parameter(name="window_length", label="Window size", description="The window size to be used when smoothing",default_value=40, minimum_value=2, maximum_value=300)

# End: PWR Description

#import packages
from cegalprizm.pythontool import PetrelConnection
import pandas as pd
import numpy as np

#Connect to Petrel
ptp = PetrelConnection()

#Retrieve the log selected by the Petrel user, using its Guid and the.get_petrelobjects_by_guids function
petrel_objects = ptp.get_petrelobjects_by_guids([parameters['log_id']])
selected_log=petrel_objects[0]

#Retrieve the int value representing the window size
window_size=parameters['window_length']

print('Smoothing the ' + selected_log.petrel_name + ' from well ' + selected_log.well.petrel_name)


#Retrieve the log data as a dataframe
df = selected_log.as_dataframe()
logs_df = df[['MD','Value']]
logs_df = logs_df.set_index('MD')

# Smooth the log values
smooth_logs_df = logs_df['Value'].rolling(window=window_size, center=True).mean()


print('Creating new log: '+ selected_log.petrel_name+'_smoothed')

# Create a new log
new_sm_log = petrel_objects[0].clone(selected_log.petrel_name+'_smoothed')  # create the clone if it doesn't already exist

# Get columns of smooth_logs_df DataFrame and convert to NumPy ndarrays
md = smooth_logs_df.index.to_numpy()
new_sm_values = smooth_logs_df.to_numpy()

# Set the newly calculated values to the new log
new_sm_log.set_values(md, new_sm_values)
print('Log successfully created')
../../_images/smoothLog_PWR.gif

====

Velocity anisotropy in sonic logs
This tutorial shows how you can create a Cegal Prizm workflow to correct for velocity anisotropy in sonic logs using Python Tool Pro. The Jupyter notebook using Python Tool Pro to run outside of Petrel can be found in the Tutorials section of Python Tool Pro.

All data used in this notebook is open-source data from the Volve field and can be found at https://www.equinor.com/energy/volve-data-sharing

# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum, MeasurementNamesEnum, TemplateNamesEnum

vel_description='''This Cegal Prizm workflows applies a velocity anisotropy correction on deviated wells. The input log for Vp and Vs must be the brine saturated case.'''

pwr_description = WorkflowDescription(name="Velocity anisotropy",
                                      category="Demo: Python operations - Wells",
                                      description=vel_description,
                                      authors="author@company.com",
                                      version="1.0")

# Use the variable pwr_description to define the UI in the Prizm Workflow Runner and let the Petrel user select the input data.
# This creates a Python dictionary 'parameters' with the GUID and/or values of the user's input data.

pwr_description.add_object_ref_parameter(name='input_well',label='Well',description='Select a well',object_type=DomainObjectsEnum.Well)
pwr_description.add_object_ref_parameter(name='vp',label='VP log (Brine saturated case)',description='Select a vp log',object_type=DomainObjectsEnum.WellContinuousLog,linked_input_name='input_well',template_type='P-velocity',measurement_type='m/s')
pwr_description.add_object_ref_parameter(name='vs',label='VS log (Brine saturated case)',description='Select a vs log',object_type=DomainObjectsEnum.WellContinuousLog,linked_input_name='input_well',template_type='S-velocity',measurement_type='m/s')
pwr_description.add_object_ref_parameter(name='phi',label='PHIE log',description='Select a porosity-effective log',object_type=DomainObjectsEnum.WellContinuousLog,linked_input_name='input_well',template_type='Porosity - effective')
pwr_description.add_object_ref_parameter(name='vsh',label='Vsh log',description='Select a Vshale log',object_type=DomainObjectsEnum.WellContinuousLog,linked_input_name='input_well',template_type='VShale')
pwr_description.add_object_ref_parameter(name='rho',label='Rho log (Brine saturated case)',description='Select a Density log',object_type=DomainObjectsEnum.WellContinuousLog,linked_input_name='input_well',template_type='Density')
pwr_description.add_object_ref_parameter(name='survey',label='Well survey',description='Select a well survey',object_type=DomainObjectsEnum.WellSurvey,linked_input_name='input_well')


# End: PWR Description
import numpy as np
import pandas as pd



from cegalprizm.pythontool import PetrelConnection, GlobalWellLog, Well, WellLog, WellSurvey
ptp = PetrelConnection(allow_experimental=True)
print('Connected to {}'.format(ptp.get_current_project_name()))
Retrieve user input
Python dictionary “parameters” created by the WorkflowDescription is used to retrieve the objects selected by the Petrel user.

It is recommended to run checks on the parameters and pass back clear messages if it fails.

petrel_objects = ptp.get_petrelobjects_by_guids([parameters['input_well'],parameters['vp'],parameters['vs'],parameters['phi'],parameters['vsh'],parameters['rho'],parameters['survey']])

well = petrel_objects[0]
if not isinstance(well, Well)==True:
    raise AssertionError("No well selected")

vp = petrel_objects[1]
if not isinstance(vp, WellLog)==True:
    raise AssertionError("No Vp log selected")

vs = petrel_objects[2]
if not isinstance(vs, WellLog)==True:
    raise AssertionError("No Vs log selected")

phi = petrel_objects[3]
if not isinstance(phi, WellLog)==True:
    raise AssertionError("No porosity log selected")

vshale = petrel_objects[4]
if not isinstance(vshale, WellLog)==True:
    raise AssertionError("No VShale log selected")

rho = petrel_objects[5]
if not isinstance(rho, WellLog)==True:
    raise AssertionError("No density log selected")

survey=petrel_objects[6]
if not isinstance(survey, WellSurvey)==True:
    raise AssertionError("No well survey log selected")

log_list = [vp, vs, phi, vshale, rho]

print('All inputs are passed to the Cegal Prizm workflow')


print('Get petrel name of all objects')
vs_name=vs.petrel_name
vp_name=vp.petrel_name
phi_name=phi.petrel_name
vshale_name=vshale.petrel_name
rho_name=rho.petrel_name
print('Petrel names retrieved')
data = well.logs_dataframe(log_list)


print('DataFrame for velocity anisotropy is created')

print('Converting vp and vs to km/s')
data[vs_name] = data[vs_name]/1000
data[vp_name] = data[vp_name]/1000
print('VP and VS converted to km/s')

Parametric equations to determine Thompson parameters
Tsuneyama and Mavko (2005) compiled an experimental dataset of core velocity anisotropy measurements from different lithologies and developed a method of estimating the Thomsen’s anisotropy parameters by regression. The equations from this paper are converted into a python function below.

It is important to note that the experiments are all on brine saturated rocks, so we must either use brine saturated rocks only or do a fluid substitution before applying the equations.

Tsuneyama, F. and Mavko, G., 2005. Velocity anisotropy estimation for brine-saturated sandstone and shale. The Leading Edge, 24(9), pp.882-888.

def velocity_anisotropy_estimation(quartz, quartzminuswater, const1, const2, vp, vs, phi, vsh, rho):

    A = quartz*vp**2-quartzminuswater*phi*vp**2
    a = (35.525+2.3095*A*phi)/const1

    b = (const2 * (37.403 + 35.525 * A * phi - A * phi + A)) / const1
    c = (37.403 * A * phi) / const1
    p = b - (a**2) / 3
    q = (2*(a**3 / 27))-((a*b)/3) + c
    m1 = const2 * q
    m2 =  np.sqrt(q**2 / 4 - p**3 / 27)
    m = (m1 + m2)**(0.3333)
    n = -1*(abs(-q/2-np.sqrt(q**2/4-p**3/27)))**(1/3)
    M2 = ((const2) * (m+n)) -a/3

    epsilon1 = -1.0428*M2+3.621
    epsilon2 = -0.0809*M2+0.5383
    epsilon3 = -0.0152*M2+0.1446
    epsilon = np.where(M2<3.2048, epsilon1, epsilon2)
    epsilon = np.where(M2>=5.9924, epsilon3, epsilon)
    epsilon = np.where(vsh<0.4, 0, epsilon)
    epsilon = epsilon / 2
    Gamma = -0.0282+1.2*epsilon

    C33 = vp**2 *rho
    C44 = vs**2 * rho
    C11 = 2 * epsilon * C33 + C33
    C66 = 2 * Gamma * C44 + Gamma
    C12 = C11 - 2 * C66
    C13 = 0.9749 * C12 - 2.3471

    Delta = ((C13 + C44)**2 - (C33 - C44)**2) / (2*C33 * (C33 - C44))

    return epsilon, Gamma, Delta
print("Calculate epsilon, gamma and delta")
data['epsilon'], data['gamma'], data['delta'] = velocity_anisotropy_estimation(quartz = 2.65,
                                                                              quartzminuswater = 1.65,
                                                                              const1 = -2.3095,
                                                                              const2 = -1,
                                                                              vp = data[vp_name],
                                                                              vs = data[vs_name],
                                                                              phi = data[phi_name],
                                                                              vsh = data[vshale_name],
                                                                              rho = data[rho_name])
We apply several post processing steps to remove any Thomsen parameters that are calculated on data where the values of phi are above the critical porosity of 0.4 and where there is missing data for any of the logs required for the calculation.

print("Define post processing")
def post_process(data):
    for i in ['epsilon', 'gamma', 'delta']:
        data[i]= np.where(data[phi]>0.4, np.NaN, data[i])
    data['epsilon'] = np.where(data.epsilon <0, np.NaN, data.epsilon)
    data['epsilon'] = np.where(data[[vp_name, phi_name, vshale_name, rho_name]].isnull().sum(axis=1)>0, np.NaN, data.epsilon)
    data['gamma'] = np.where(data[[vp_name, phi_name, vshale_name, rho_name]].isnull().sum(axis=1)>0, np.NaN, data.gamma)

    return data
Now we want to get the inclination of the well to use in the Thomsen equations. We can get this from the well survey by finding the surveys on our well object and the as_dataframe() method.

print("Creating survey dataframe")
df_survey = survey.as_dataframe(get_calculated_trajectory=True)
print(df_survey)
As the number of rows in the survey DataFrame are much less than for the log DataFrame, we interpolate the inclination values between the MD values of the log.

print("Calculate inclination")
data['Inclination'] = np.interp(data['MD'], df_survey['MD'], df_survey['Inclination'])
Corrected sonic logs
Now we can create two functions for the Thomsen equations to calculate Vp and Vs from epsilon, gamma, and the inclination of the well. Then we can apply the corrections to Vp and Vs


def adjusted_vp(vp, epsilon, deviation):
    adjusted_vp = vp/(1+(epsilon*np.sin(np.radians(deviation))**4))
    adjusted_vp = np.where(adjusted_vp.isnull()==True, vp, adjusted_vp)
    return adjusted_vp

print("Calculate adjusted vs")
def adjusted_vs(vs, gamma, deviation):
    adjusted_vs = vs/(1+gamma*np.sin(np.radians(deviation))**2)
    adjusted_vs = np.where(adjusted_vs.isnull()==True, vs, adjusted_vs)
    return adjusted_vs
print("Calculate adjusted vp and vs")
data['corrected_vp'] = adjusted_vp(data[vp_name], data['epsilon'], data['Inclination'])
data['corrected_vs'] = adjusted_vs(data[vs_name], data['gamma'], data['Inclination'])

# Calculate the percentage difference between original sonic logs and re-calculated
print("Calculate vp and vs difference between original and adjusted")
data['vp_difference'] = (data[vp_name]/data['corrected_vp'])*100
data['vs_difference'] = (data[vs_name]/data['corrected_vs'])*100

Write back to Petrel
First we can create two new global well logs, one for the corrected Vp and the other for the corrected Vs. We can assign the correct template for the new logs by setting the template parameter in the clone() method.

Then, we can write the values to the new logs for the well object we got at the start of the tutorial. Note: the sonic logs are converted back to m/s from km/s by multiplying by 1000


print("Create new logs in the input tree")
cols = [('corrected_vp', 'P-velocity'),
        ('corrected_vs', 'S-velocity')]

# We can use the original Vp log to use as a clone
log_to_clone = [i for i in ptp.global_well_logs if type(i)==GlobalWellLog and i.petrel_name==vp_name][0]

# For each new log, create a global well log and assign the correct template
for col in cols:
    vae_logs_in_petrel = [i for i in ptp.global_well_logs if type(i)==GlobalWellLog and i.petrel_name==col[0]]
    if len(vae_logs_in_petrel) == 0:
        template = [i for i in ptp.templates if i.petrel_name == col[1]][0]
        j = log_to_clone.clone(col[0], copy_values = False, template=template)
# Now we can write the values back to Petrel by creating a new log for each of the newly created global well logs for this well
md = data.MD.to_numpy()

print("Write adjusted Vp and Vs to the new logs")

for v in cols:
    gwl = [l for l in ptp.global_well_logs if type(l)==GlobalWellLog and l.petrel_name == v[0]][0]
    log_to_write_to = gwl.create_well_log(well)
    log_to_write_to.readonly = False
    values = data[v[0]].to_numpy() * 1000 # convert back to m/s from km/s
    log_to_write_to.set_values(md, values)


====
Using Bruges Python package to create seismic attributes
There are numerous domain specific open-source Python packages available. Here, we show how to grab a seismic cube, generate several new attributes using the Bruges package and write the results back to Petrel.

The purpose is to show how easy it is to work with other libraries using the Python Tool Pro API and easy it is to generate a UI inside of Petrel that allows user to run this workflow. Attributes can also be create in Petrel, but it is quick to see that with external packages or code a workflow to create attributes can be automated across many seismic cubes and / or Petrel projects. Secondly, as we are working outside Petrel, attributes can be created, visualized, and utilized without ever needing to be saved in Petrel unless necessary.

For a full breakdown of the script please visit the Python Tool Pro tutorial.

Generate Petrel UI
# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum,MeasurementNamesEnum,TemplateNamesEnum

pwr_description = WorkflowDescription(name="Bruges Seismic Attributes",
                                      category="Seismic interpretation",
                                      description="Use this workflow to calculate seismic attributes using the Bruge library. This is a simple Cegal Prizm workflow demonstrating the deployment of Python code to Petrel users and how you can expand Petrel functionality with additional algorithms.",
                                      authors="author@company",
                                      version="1.0")

# Use the variable pwr_description to define the UI in the Prizm Workflow Runner and let the Petrel user select the input data.
# This creates a Python dictionary 'parameters' with the GUID and/or values of the user's input data.

pwr_description.add_enum_parameter(name='attributes',label='Select seismic attribute',description='Chose which seismic attribute you want to run',options={0:'Envelope',1:'Instantaneous Phase',2:'Energy'},default_value=0)
pwr_description.add_string_parameter(name='new_name_seismic',label='Name for attribute cube',description='Give the name of the new processed cube',default_value='Bruge Attribute')
pwr_description.add_integer_parameter(name='chunk_size',label='Chunk size',description='Define the chunk size for writing result back to Petrel',default_value=150, minimum_value=10, maximum_value=200)
pwr_description.add_object_ref_parameter(name='seismic_id',label='Seismic cube',description='Select a seismic cube',object_type=DomainObjectsEnum.Seismic3D)
pwr_description.add_object_ref_parameter(name='template',label='Seismic template',description='Select a template for the seismic attribute',object_type=DomainObjectsEnum.TemplateContinuous)

# End: PWR Description
<cegalprizm.pycoderunner.workflow_description.WorkflowDescription at 0x21ea809e2f0>
Connect to Petrel and retrieve the user input
from cegalprizm.pythontool import *
import bruges as bg
import numpy as np

# Connect to Petrel
petrel=PetrelConnection(allow_experimental=True)
print('PetrelConnection established')

# Retrieve the seismic cube and template selected by the user
petrel_objects = petrel.get_petrelobjects_by_guids([parameters['seismic_id'],parameters['template']])

# Assign the user selected attribute (from the enum input parameter (dropdown menu)) to a variable
attr=parameters['attributes']
print('Seismic attribute selected')

# Assign the user defined name (from the string input parameter) to a variable
newname=parameters['new_name_seismic']
#Verify that a name has been defined
if len(newname) == 0:
    raise ValueError(f"{pwr_description.get_label('new_name_seismic')} : No name defined")
print(f"{pwr_description.get_label('new_name_seismic')} retrieved")

# Assign the user chunk size (from the integer input parameter) to a variable
chunk_size=parameters['chunk_size']
print('Chunk size retrieved')

# Assign the user selected seismic cube to a variable
selected_seismic_cube=petrel_objects[0]
#Verify that the seismic cube has been selected
if selected_seismic_cube is None:
    raise ValueError("No seismic cube has been selected")
print('Selected seismic retrieved')

# Assign the user selected template to variable
selected_seismic_template=petrel_objects[1]
#Verify that a template has been selected
if selected_seismic_template is None:
    raise ValueError("No template has been selected")
print('Selected template retrieved')

# Retrieve the seismic extent
cube_dimensions=selected_seismic_cube.extent

Define chunking function
The get_chunks function divides a seismic cube into smaller chunks based on the provided chunk size and the cube’s dimensions.

def get_chunks(extent, chunk_size):

    # Extract the dimensions of the seismic cube.
    i_range, j_range, k_range = extent

    # Divide the i dimension into chunks. Each chunk is represented as a tuple (start, end).
    # If the chunk goes beyond the cube dimension, the end is set to i_range-1.

    i_chunks = [(start, min(start + chunk_size, i_range-1)) for start in range(0, i_range, chunk_size)]

    # Currently, we are not splitting the j and k dimensions, so we keep them as a single chunk.
    j_chunks = [(0, j_range-1)]
    k_chunks = [(0, k_range-1)]

    # Return the combined chunks for all dimensions.
    return [(i, j, k) for i in i_chunks for j in j_chunks for k in k_chunks]

Process the cube and write the results back to Petrel
The process_all_chunks function processes a seismic cube to compute its envelope, instantaneous phase, and energy attributes using provided chunks and then writing them back to Petrel. It leverages the pre-defined chunking mechanism to handle large seismic volumes efficiently.

# Retrieve chunks based on cube dimensions and chunk size.
chunks = get_chunks(cube_dimensions, chunk_size)
# Clone the original seismic cube to create new cubes for envelope, instantaneous phase, and energy.
# The name of the new cube is going to be defined by the Petrel user (newname)
# The new cube will have the user selected template (selected_seismic_template)
new_cube=selected_seismic_cube.clone(newname,copy_values=False,template=selected_seismic_template)
print('Creating attribute cube')
for chunk in chunks:
    # Extract the chunk from the seismic and convert it to an array
    i_range, j_range, k_range = chunk
    data_chunk = selected_seismic_cube.chunk(i_range, j_range, k_range)
    new_cube_array=data_chunk.as_array()
    #Extract the chunk from the new cube
    new_chunk=new_cube.chunk(i_range, j_range, k_range)
    print('Processing seismic chunk')

    #Calculate the seismic attribute and write it back to Petrel based on the user selection
    if attr==0:
        env = bg.attribute.envelope(new_cube_array)
        new_chunk.set(env)
    elif attr==1:
        phase = bg.attribute.instantaneous_phase(new_cube_array)
        new_chunk.set(phase)
    else:
        energy = bg.attribute.energy(new_cube_array, duration=0.016, dt=0.004)
        new_chunk.set(energy)
print('Seismic attribute successfully created')
bruges_PWR_gif.gif

===
Getting Started
This guide explains how to create your first Cegal Prizm workflow that can be executed from Petrel. It assumes that the Prizm Workflow Runner Plugin has already been installed and configured correctly on your system. Should you encounter any errors or issues, it is recommended that you revisit the Installation Guide to ensure all steps have been properly completed. For further assistance with specific problems or error messages, please consult the Troubleshooting Guide.

Basic concepts
Inside Petrel, in the Prizm Workflow Runner plugin, the user interface (UI) elements are dynamically generated through workflow descriptions embedded within your Python script or Jupyter notebook. This is achieved by defining a special section in your code that is specifically interpreted by Petrel to create the UI.

Defining the Workflow Description Section
The workflow description section is clearly marked at the beginning of your script to indicate where the UI generation code begins and ends. This is done using specific comments:

The start of the description is marked with # Start: PWR Description.

The end is indicated by # End: PWR Description.

Between these markers, you define the UI elements and their behavior.

Using the Workflow Description Function
Within this section, you utilize the WorkflowDescription function from the cegalprizm.pycoderunner module. This function allows you to specify basic information about your workflow, such as:

name : The name of the workflow as it will appear in Petrel.

category : The category under which your workflow will be listed in Petrel, aiding in organization and filtering.

description : A brief description of what your script or notebook does.

authors : Contact details of the workflow’s author.

version : The version number of your workflow.

Adding Input Objects
To allow users to select the data needed by the script, you can use the add_object_ref_parameter method. This method is part of the WorkflowDescription and is used to add Petrel input objects to your workflow.

An input object can be defined by providing the following parameters:

name : The name used to retrieve the object from Petrel.

label : The label shown in the Petrel UI for this input.

description : A description for this input, which can be viewed in Petrel’s help section.

object_type : The type of the object, defined using the DomainObjectsEnum.

# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription, MeasurementNamesEnum
from cegalprizm.pythontool import DomainObjectsEnum


pwr_description = WorkflowDescription(name="Name as shown in Petrel",
                                    category="Category used in filter",
                                    description="Describe here what your notebook or script does",
                                    authors="contact details of the workflow author",
                                    version="contact details of the workflow author")


pwr_description.add_object_ref_parameter(name='name_used_to_retrieve_object_from_petrel',
                                     label='LabelShownInPetrelUI',
                                     description='DescriptionAsShownInPetrelHelpButton',
                                     object_type=DomainObjectsEnum.Surface
                                     )

# End: PWR Description
The Workflow description in the code snippet above creates the following Petrel UI letting the user select a surface object as input:

../../_images/Example.png
By following this structure, you can create a user-friendly interface in Petrel that allows users to interact with your Python script or Jupyter notebook effectively, making your workflow both accessible and practical.

While the basics of creating a workflow description have been covered, there’s much more you can do to enhance the interaction between your script and the Petrel UI. The Petrel Python Plugin supports a variety of input object types and parameters, which can be utilized to tailor your workflow to specific needs and data types. Check out the User Guide to learn more.

Write your first script
Now you can start writing the Python code you want Petrel users to execute. In this example we will be using Python Tool Pro to retrieve a well log (Petrel user selects input log), smooth it by applying a rolling window and write it back to Petrel.

As mentioned above, we need to start the script with the workflow description. The Petrel user should be able to select the log and specify the window size. For the window size we’ll use an integer input parameter. We’ll set a default value of 40 and limit the user input to values between [2,300] :

# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription, MeasurementNamesEnum
from cegalprizm.pythontool import DomainObjectsEnum

pwr_description = WorkflowDescription(name="Smooth log",
                                    category="Petrophysics",
                                    description="This workflow creates a smoothed log by using a rolling window to smooth the log values. This is done using the rolling method from Pandas, which calculates a moving average over a specified window size.",
                                    authors="author@company",
                                    version="1.0")

pwr_description.add_object_ref_parameter(name="log_id", label="Select Log", description="Select the log you want to smooth", object_type=DomainObjectsEnum.WellLog)
pwr_description.add_integer_parameter(name="window_length", label="Window size", description="The window size to be used when smoothing", default_value=40, minimum_value=2, maximum_value=300)

# End: PWR Description
We’re now going to use Python Tool Pro to access the log selected by the Petrel User. As the Petrel users selects the input data, it is not possible assign the python variables using the Petrel path as you would normally do with Python Tool Pro.

Instead the Petrel guid is passed once the Petrel users run the workflow and stored in a dictionary called ‘parameters’. This dictionary has the names you used in the workflow description (e.g. pwr_description.add_object_ref_parameter(name=’log_id’,…)) as dictionary keys and the Petrel GUID or input value (for strings, float, bool, etc) as dictionary values.

It is then possible to retrieve the objects using the Python Tool Pro method get_petrel_projects_by_guids():

#import packages
from cegalprizm.pythontool import PetrelConnection
import pandas as pd
import numpy as np

#Connect to Petrel
ptp = PetrelConnection()

#Retrieve the log selected by the Petrel user, using its Guid and the.get_petrelobjects_by_guids function
petrel_objects = ptp.get_petrelobjects_by_guids([parameters['log_id']])
selected_log=petrel_objects[0]

#Retrieve the int value representing the window size
window_size=parameters['window_length']

print('Smoothing the ' + selected_log.petrel_name + ' from well ' + selected_log.well.petrel_name)
When you are writing your scripts, in order to test they work as expected, you can retrieve a Petrel object from your running Petrel instance in the conventional way, using Python Tool Pro (as shown bellow) . After ensuring everything works you can simply replace the input objects with the user select one.

# Example on how to retrieve Petrel objects in the conventional way, using Python Tool Pro :

#import packages
from cegalprizm.pythontool import PetrelConnection
import pandas as pd
import numpy as np

#Connect to Petrel
ptp = PetrelConnection()

#Retrieve the a log using Python Tool Pro
selected_log = ptp.well_logs['Input/Wells/A Wells/A10/Well logs/Gullfaks/Gamma']

#Define the window size
window_size = 40

print('Smoothing the ' + selected_log.petrel_name + ' from well ' + selected_log.well.petrel_name)
Now that we have the log and the window size, lets smooth it and write the results back to Petrel :

#Retrieve the log data as a dataframe
df = selected_log.as_dataframe()
logs_df = df[['MD','Value']]
logs_df = logs_df.set_index('MD')

# Smooth the log values
smooth_logs_df = logs_df['Value'].rolling(window=window_size, center=True).mean()


print('Creating new log: '+ selected_log.petrel_name+'_smoothed')

# Create a new log
new_sm_log = selected_log.clone(selected_log.petrel_name+'_smoothed')  # create the clone if it doesn't already exist

# Get columns of smooth_logs_df DataFrame and convert to NumPy ndarrays
md = smooth_logs_df.index.to_numpy()
new_sm_values = smooth_logs_df.to_numpy()

# Set the newly calculated values to the new log
new_sm_log.set_values(md, new_sm_values)
print('Log successfully created')
If you’re unfamiliar with the Python Tool Pro API, you can learn more about it here.

Now that we have our first script, we can copy it to our defined Workflow Repository and test it inside Petrel :

# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription, MeasurementNamesEnum
from cegalprizm.pythontool import DomainObjectsEnum

pwr_description = WorkflowDescription(name="Smooth log",
                                    category="Petrophysics",
                                    description="This workflow creates a smoothed log by using a rolling window to smooth the log values. This is done using the rolling method from Pandas, which calculates a moving average over a specified window size.",
                                    authors="author@company",
                                    version="1.0")

pwr_description.add_object_ref_parameter(name="log_id", label="Select Log", description="Select the log you want to smooth", object_type=DomainObjectsEnum.WellLog)
pwr_description.add_integer_parameter(name="window_length", label="Window size", description="The window size to be used when smoothing",default_value=40, minimum_value=2, maximum_value=300)

# End: PWR Description

#import packages
from cegalprizm.pythontool import PetrelConnection
import pandas as pd
import numpy as np

#Connect to Petrel
ptp = PetrelConnection()

#Retrieve the log selected by the Petrel user, using its Guid and the.get_petrelobjects_by_guids function
petrel_objects = ptp.get_petrelobjects_by_guids([parameters['log_id']])
selected_log=petrel_objects[0]

#Retrieve the int value representing the window size
window_size=parameters['window_length']

print('Smoothing the ' + selected_log.petrel_name + ' from well ' + selected_log.well.petrel_name)


#Retrieve the log data as a dataframe
df = selected_log.as_dataframe()
logs_df = df[['MD','Value']]
logs_df = logs_df.set_index('MD')

# Smooth the log values
smooth_logs_df = logs_df['Value'].rolling(window=window_size, center=True).mean()


print('Creating new log: '+ selected_log.petrel_name+'_smoothed')

# Create a new log
new_sm_log = petrel_objects[0].clone(selected_log.petrel_name+'_smoothed')  # create the clone if it doesn't already exist

# Get columns of smooth_logs_df DataFrame and convert to NumPy ndarrays
md = smooth_logs_df.index.to_numpy()
new_sm_values = smooth_logs_df.to_numpy()

# Set the newly calculated values to the new log
new_sm_log.set_values(md, new_sm_values)
print('Log successfully created')

===

Working with Seismic Cubes: Chunking, Masking and Trace Processing
This tutorial showcases an example of processing seismic data with an emphasis on masking techniques and trace analysis.

Key aspects of the script include:

Chunking the Data: The script divides the large seismic dataset into smaller, more manageable chunks. This is important for efficient processing of extensive seismic datasets.

Data Conversion to xarray: For easier manipulation, the script converts the seismic data into xarray format, a Python package that simplifies working with labeled multi-dimensional arrays.

Mask Creation : The script generates a mask to differentiate between positive and negative amplitudes.

Seismic Trace Processing: Each seismic trace is processed by averaging amplitudes in segments identified by the mask.

For a full breakdown of the script please visit the Python Tool Pro tutorial.

Generate Petrel UI
# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum,MeasurementNamesEnum,TemplateNamesEnum

pwr_description = WorkflowDescription(name="Seismic trace averaging",
                                      category="Seismic interpretation",
                                      description="Use this workflow to average the seismic amplitudes trace by trace",
                                      authors="author@company",
                                      version="1.0")


pwr_description.add_string_parameter(name='new_name_seismic',label='Name for processed cube',description='Give the name for the new processed cube',default_value='Avg. Amplitudes')
pwr_description.add_integer_parameter(name='chunk_size',label='Chunk size',description='Define the chunk size for writing result back to Petrel',default_value=150, minimum_value=0, maximum_value=500)
pwr_description.add_object_ref_parameter(name='seismic_id',label='Seismic cube',description='Select a seismic cube',object_type=DomainObjectsEnum.Seismic3D)

# End: PWR Description
Connect to Petrel and retrieve the user input
from cegalprizm.pythontool import *

# Connect to Petrel
petrel=PetrelConnection(allow_experimental=True)
print('PetrelConnection established')

# Retrieve the seismic cube selected by the user
petrel_objects = petrel.get_petrelobjects_by_guids([parameters['seismic_id']])

# Assign the user defined name (from the string input parameter) to a variable
newname=parameters['new_name_seismic']
#Verify that a name has been defined
if len(newname) == 0:
    raise ValueError(f"{pwr_description.get_label('new_name_seismic')} : No name defined")
print(f"{pwr_description.get_label('new_name_seismic')} retrieved")

# Assign the user chunk size (from the integer input parameter) to a variable
chunk_size=parameters['chunk_size']
print('Chunk size retrieved')

# Assign the user selected seismic cubes
selected_seismic_cube=petrel_objects[0]
#Verify that the seismic cube has been selected
if selected_seismic_cube is None:
    raise ValueError("No seismic cube has been selected")
print('Selected seismic retrieved')

# Retrieve the seismic extent
cube_dimensions=selected_seismic_cube.extent
Divide cube into equal chunks based on the intial chunk size input
def get_chunks(extent, chunk_size):

    # Extract the dimensions of the seismic cube.
    i_range, j_range, k_range = extent

    # Divide the i,j,k dimension into chunks. Each chunk is represented as a tuple (start, end).
    i_chunks = [(start, min(start + chunk_size, i_range-1)) for start in range(0, i_range, chunk_size)]
    j_chunks = [(start, min(start + chunk_size, j_range-1)) for start in range(0, j_range, chunk_size)]
    k_chunks = [(start, min(start + chunk_size, k_range-1)) for start in range(0, k_range, chunk_size)]

    return [(i, j, k) for i in i_chunks for j in j_chunks for k in k_chunks]

Convert numpy array into xarray
import xarray as xr

def numpy_to_xarray(arr):
    return xr.DataArray(arr)
Create a masked volume (1= positive amplitudes, 0=negative amplitudes)
In the next code cell we’ll define two functions pos_neg_mask and create_mask which work together to create a mask based on the positive and negative values in the xarray data.

import numpy as np

def pos_neg_mask(x):
    return 1 if x >= 0 else 0



def create_mask(xarray_data):
    vectorized_mask = np.vectorize(pos_neg_mask)
    return xr.apply_ufunc(vectorized_mask, xarray_data)

Proccess seismic trace
The process_trace function performs segment-wise averaging on a seismic trace based on a corresponding mask trace. Each segment in the trace, delineated by changes in the mask, is replaced with the average value of that segment.

def process_trace(trace, mask_trace):
    avg_trace = trace.copy()

    # Start segment marker
    start_segment = None

    # Initial mask value
    current_mask_value = mask_trace[0]

    # Iterate over the trace
    for k in range(1, len(trace)):

        # Check if the mask has changed
        if mask_trace[k] != current_mask_value:

            # If we have a previous segment
            if start_segment is not None:
                avg_value = np.mean(trace[start_segment:k])
                avg_trace[start_segment:k] = avg_value

            # Reset the start segment marker
            start_segment = k

        # Update the current mask value
        current_mask_value = mask_trace[k]

        # If we are at the end of the trace
        if k == len(trace) - 1 and start_segment is not None:
            avg_value = np.mean(trace[start_segment:])
            avg_trace[start_segment:] = avg_value

    return avg_trace

Repeat the seismic trace proccess for the entire seismic chunk
def process_cube(seismic_data, mask_data):
    # Create an output array to hold the processed data
    processed_cube = seismic_data.copy()

    # Get the shape of the seismic cube
    n_ilines, n_xlines, n_samples = seismic_data.shape

    # Iterate over every trace in the cube
    for i in range(n_ilines):
        for j in range(n_xlines):
            # Get the current trace and mask
            trace = seismic_data[i, j, :]
            trace_mask = mask_data[i, j, :]

            # Process the trace
            processed_trace = process_trace(trace, trace_mask)

            # Store the processed trace back into the cube
            processed_cube[i, j, :] = processed_trace

    return processed_cube

# Process the entire cube

Iterate over all chunks and write the results back to Petrel

def process_all_chunks(seismic_cube, extent, chunk_size):
    chunks = get_chunks(extent, chunk_size)

    print('Creating new seismic cube')
    new_cube=seismic_cube.clone(newname,copy_values=False)

    print(f"Total number of seismic chunks{len(chunks)}")

    i=0
    for chunk in chunks:
        i+=1
        print(f"Processing chunk {i}/{len(chunks)}")
        # Extract the chunk
        i_range, j_range, k_range = chunk
        data_chunk = seismic_cube.chunk(i_range, j_range, k_range)
        new_cube_all=new_cube.chunk(i_range, j_range, k_range)
        new_cube_array=new_cube_all.as_array()
        # Convert to numpy array
        np_data = data_chunk.as_array()

        # Convert to xarray
        xr_data = numpy_to_xarray(np_data)

        # Create mask
        masked_data = create_mask(xr_data)

        # Get stats
        processed_cube = process_cube(xr_data.values, masked_data.values)
        new_cube_all.set(processed_cube)
        print("Seismic chunk successfully processed ")

    return processed_cube

Apply the workflow to the whole cube
seismic_cube = process_all_chunks(selected_seismic_cube,cube_dimensions,chunk_size)
print("Entire seismic cube successfully processed")

==

Calculating Vsh
This tutorial shows how you can create a Cegal Prizm workflow to calculate the Vshale log from a gamma ray log. The Jupyter notebook using Python Tool Pro to run outside of Petrel can be found in the Tutorials section of Python Tool Pro.

# Start: PWR Description

from cegalprizm.pycoderunner import *

# The class WorkflowDescription is used to define the Cegal Prizm workflow. It is assigned to a Python variable called 'pwr_description'
pwr_description = WorkflowDescription(name="Vsh Calculator",
                                      category="Demo: Python operations - Wells",
                                      description="Calculate Vsh using different algorithms",
                                      authors="author@company",
                                      version="1.0")

# Use the variable pwr_description to define the UI in the Prizm Workflow Runner and let the Petrel user select the input data.
# This creates a Python dictionary 'parameters' with the GUID and/or values of the user's input data.

pwr_description.add_object_ref_parameter(name="well_id", label="Select well", description="Select the well", object_type=DomainObjectsEnum.Well)
pwr_description.add_object_ref_parameter(name="log_id", label="Gamma ray input log",description="Gamma ray log used to calculate Vshale", object_type=DomainObjectsEnum.WellContinuousLog, template_type='GammaRay', linked_input_name="well_id")
pwr_description.add_object_ref_parameter(name="gwl_id",label= "Target Vsh global well log", description="Select the global well log the calculated Vshale should be written to", object_type=DomainObjectsEnum.GlobalLogContinuous, template_type='VShale')
pwr_description.add_boolean_parameter(name="overwrite_vsh",label="Overwrite if Vsh log exist",description="Decide if existing vsh log should be overwritten",default_value=False)
pwr_description.add_integer_parameter(name='grs_input',label='Clean rock GR value:',description='The GammaRay value associated with a clean reservoir having no shale ',default_value=30, minimum_value=1, maximum_value=1000)
pwr_description.add_integer_parameter(name='grsh_input',label='Shale GammaRay value',description='The GammaRay value associated with a zone of 100% shale',default_value=130, minimum_value=1, maximum_value=1000)
pwr_description.add_enum_parameter(name='methods',label='Select method:',description='Choose which method you want to use for calculation Vsh',options={0:'Linear',1:'Larionov - tertiary rocks',2:'Larionov - older rocks',3:'Clavier',4:'Stieber'})
# End: PWR Description

Retrieve user input
Python dictionary “parameters” created by the WorkflowDescription is used to retrieve the objects selected by the Petrel user.

It is recommended to run checks on the parameters and pass back clear messages if it fails.

print("Establishing PetrelConnection")

from cegalprizm.pythontool import PetrelConnection, Well, WellLog, GlobalWellLog
ptp=PetrelConnection()

print("PetrelConnection established")

# Retrieve the selected well using its GUID and check if it's a valid Well object
user_well=ptp.get_petrelobjects_by_guids([parameters['well_id']])[0]
if not isinstance(user_well, Well)==True:
    raise AssertionError("No well selected")

print("Retrieved well by guid")

# Retrieve the selected gamma ray log using its GUID and check if it's a valid WellLog object
gr_log = ptp.get_petrelobjects_by_guids([parameters['log_id']])[0]
if not isinstance(gr_log, WellLog)==True:
    raise AssertionError("No gamma ray log selected as input")

print("Retrieved gamma ray input log by guid")

# Retrieve the selected Vshale global well log using its GUID and check if it's a valid GlobalWellLog object
target_gwl=ptp.get_petrelobjects_by_guids([parameters['gwl_id']])[0]
if not isinstance(target_gwl, GlobalWellLog)==True:
    raise AssertionError("No vshale global well log selected as target log")
print("Retrieved target vshale global well log by guid")

# Check if the Vshale log already exists in the well and set the overwrite flag accordingly
try:
    existing_log=target_gwl.log(user_well.petrel_name)
    print("Target log does exist in well. Values will be overwritten.")
    overwrite_log=True
except:
    print("Target log does not exist in well. New log will be created.")
    overwrite_log=False
    pass

petrel_overwrite=parameters['overwrite_vsh']

# Raise an exception if the user chose not to overwrite the Vshale but the log already exists
if petrel_overwrite==False and overwrite_log==True:
    raise Exception("Log already exist,but overwrite is set to False")

# Retrieve the selected method and input values for the Vsh calculation
method=parameters['methods']
GRS_input=parameters['grs_input']
GRSh_input=parameters['grsh_input']


Vshale calculation
From the gamma ray log and Pandas DataFrame is create and the Vshale values are calculated.

# Convert the gamma ray log to a Pandas DataFrame and check if it's not empty
df=gr_log.as_dataframe()
if not (len(df)>0)==True:
   raise AssertionError("Gamma ray log is empty. Creation of DataFrame failed")

print("Created Pandas Dataframe from gamma ray input log")

# Function to calculate shale volume using the selected method
import numpy as np
from numpy import sqrt
import pandas as pd
def calculate_vshale(method,GRS_input,GRSh_input):

    # Calculate the Gamma Ray Index
    GR_index = (df['Value'] - GRS_input) / (GRSh_input - GRS_input)
    GR_index = np.where(GR_index < 0, 0, GR_index)
    GR_index = np.where(GR_index > 1, 1, GR_index)

    # Calculate Vshale based on the selected method
    if method == 0:
        vshale = GR_index
    elif method == 1:
        vshale = 0.083 * (2 ** (3.7 * GR_index) - 1.0)
    elif method == 2:
        vshale = 0.33 * (2 ** (2.0 * GR_index) - 1.0)
    elif method == 3:
        vshale = 1.7 - sqrt(3.38 - (GR_index + 0.7) ** 2)
    elif method == 4:
        vshale = GR_index / (3 - 2 * GR_index)
    else:
        vshale = pd.Series([])

    # Ensure Vshale values are within the range 0 to 1
    vshale = np.where(vshale < 0, 0, vshale)  # Set lower limit to 0
    vshale = np.where(vshale > 1, 1, vshale)
    return vshale
# Calculate Vshale using the selected method and add it to the DataFrame
vshale = calculate_vshale(method,GRS_input,GRSh_input)
df['VSH'] = vshale
print("Calculated vshale values")

Write results back to Petrel
# Assign the MD values to a variable
MD_values=df['MD'].to_list()
# Assign the Vsh values to a variable
Vsh_values=df['VSH'].to_list()

# Check if the log needs to be overwritten or a new log needs to be created
if overwrite_log==True:
    Vsh_log=target_gwl.log(user_well.petrel_name)
    Vsh_log.readonly=False
    #Assign the MD and Vsh values to the new log
    Vsh_log.set_values(MD_values,Vsh_values)
    print("Vshale values written to log. Existing values are overwritten.")
elif overwrite_log==False:
    # Create a new well log for the calculated Vshale values
    Vsh_log=target_gwl.create_well_log(well=user_well)
    print("Created new vshale log for selected well")
    Vsh_log.readonly=False
    #Assign the MD and Vsh values to the new log
    Vsh_log.set_values(MD_values,Vsh_values)
    print("Vshale values written to new log")



===

Log Despiking
Despiking is the process of identifying and removing abnormal spikes in data, which can arise due to various factors like equipment error, environmental noise, or data transmission errors. These spikes can distort analyses and interpretations, making their removal crucial for accurate seismic data analysis.

In this example, we remove spikes (outliers) from log data by using a median filter. This filter replaces values that significantly deviate from the local median (determined by a specified window size) with the median value, effectively smoothing out spikes.

Generate Petrel UI
# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription, DomainObjectsEnum, MeasurementNamesEnum

# The class WorkflowDescription is used to define the Cegal Prizm workflow. It is assigned to a Python variable called 'pwr_description'
pwr_description = WorkflowDescription(name="Despike logs",
                                      category="Petrophysics",
                                      description="Simple approach to remove outliers in your log data.\n  Despiking based on difference between the rolling median and the rolling std deviation.",
                                      authors="author@company",
                                      version="0.1")

# Use the variable pwr_description to define the UI in the Prizm Workflow Runner and let the Petrel user select the input data.
# This creates a Python dictionary 'parameters' with the GUID and/or values of the user's input data.

pwr_description.add_integer_parameter(name="int_value", label="Window size: ", description="An integer input", default_value=5, minimum_value=2, maximum_value=100)
pwr_description.add_object_ref_parameter(name="log_id", label="Select logs:", description="A continuous welllog",object_type=DomainObjectsEnum.WellContinuousLog, select_multiple=True)
pwr_description.add_boolean_parameter(name='overwrite',label='Overwrite existing logs?',description='Choose if you want to overwrite the existing logs or create new ones',default_value=False)

# End: PWR Description
Connect to Petrel and retrieve the user input
from cegalprizm.pythontool import *

petrel=PetrelConnection(allow_experimental=True)

#Retrieve the user defined window size and assign it to a variable
window_size=parameters['int_value']

#Retrieve the user defined value of the boolean parameter
overwrite_logs=parameters['overwrite']

# Initialize a list to store the user selected logs
nested_logs=[]

for el in parameters['log_id']:
    nested_logs.append(petrel.get_petrelobjects_by_guids([el]))

# Check if no logs are selected and raise an error if true
if len(nested_logs) == 0:
    raise ValueError("No wells have been selected")

# Check if any selected logs are invalid and raise an error if true
if any(item is None for item in nested_logs):
    raise ValueError("Some selected wells are not valid")
Despike logs
import numpy as np
def despike_log(df, window_size):
    #performs median filtering on the 'Value' column of the DataFrame.
    #The rolling() function creates a rolling window of size window_size centered around each value
    #The median() function computes the median within each window.
    median_filtered = df['Value'].rolling(window=window_size, center=True).median()
    #Compare each value in the 'Value' column of the DataFrame with the corresponding value in the median-filtered series.
    #If the difference is greater than two times the standard deviation of the median-filtered series, it replaces the value with the median-filtered value; otherwise, it keeps the original value.
    gr_despiked = np.where(df['Value'] - median_filtered > 2 * median_filtered.std(), median_filtered, df['Value'])
    df['Value_despiked'] = gr_despiked
    return df

Write results back to Petrel
# Initialize list to keep track of processed global well log templates
global_well_log_template=[el.petrel_name for el in petrel.global_well_logs]


# Iterate over each log in the nested_logs list
for el in nested_logs:
    log=el[0] # Extract the log object
    well=log.well # Extract the well associated to the log
    gwl=log.global_well_log # Get the global well log associated with the log
    df=log.as_dataframe() # Convert the log to a DataFrame
    df=df[['MD', 'Value']] # Select only the 'MD' and 'Value' columns
    df.set_index('MD',inplace=True)  # Set 'MD' as the index of the DataFrame
    print(f'Despiking log: {el[0].petrel_name}')

    # Skip processing if the log template is 'One-way time'
    if el[0].template == 'One-way time':
        continue

    # Handle the case where logs are not to be overwritten
    elif overwrite_logs==0:
        # Check if a despiked version of the global well log already exists
        if gwl.petrel_name+ '_despiked' in global_well_log_template:
            # Find the existing despiked global well log
            print(f"Creating new log assigned to the following global well log: {log.petrel_name + '_despiked'}")
            new_gwl=[el for el in petrel.global_well_logs if el.petrel_name==gwl.petrel_name+ '_despiked'][0]
            new_log= new_gwl.create_well_log(log.well) # Create a new log in the existing despiked global well log

            df_despiked = despike_log(df, window_size) # Apply the despiking function to the DataFrame

            # Update the new log with despiked values and write the results back to Petrel
            new_log.readonly=False
            MD_index=df_despiked.index.to_list()
            Despike_values=df_despiked['Value_despiked'].to_list()
            new_log.set_values(MD_index,Despike_values)

            print(f"{log.petrel_name} log associated to well {well.petrel_name} succesfully despiked")
        # Create a new global well log
        else:
            # Create a clone of the log if a despiked version does not exist
            print(f"Creating global well log: {log.petrel_name + '_despiked'}")
            new_log=log.clone(log.petrel_name + '_despiked',copy_values=False)
            df_despiked = despike_log(df, window_size)# Apply the despiking function to the DataFrame

            # Update the cloned log with despiked values and write the results back to Petrel
            new_log.readonly=False
            MD_index=df_despiked.index.to_list()
            Despike_values=df_despiked['Value_despiked'].to_list()
            new_log.set_values(MD_index,Despike_values)

            print(f"{log.petrel_name} log associated to well {well.petrel_name} succesfully despiked")

        # Add the despiked global well log name to the list to avoid reprocessing
        global_well_log_template.append(gwl.petrel_name+ '_despiked')
    # Handle the case where logs are to be overwritten
    else :
        print(f'Overwriting log: {log.petrel_name}')
        df_despiked = despike_log(df, window_size) # Apply the despiking function to the DataFrame

        # Update the original log with despiked values
        log.readonly=False
        MD_index=df_despiked.index.to_list()
        Despike_values=df_despiked['Value_despiked'].to_list()
        log.set_values(MD_index,Despike_values)

        print(f"{log.petrel_name} log associated to {well.petrel_name} succesfully despiked")

print("Workflow completed")

===
Smooth well log
The script applies a filter to smooth a well log, using a specified window size to determine the range of data points considered for each smoothing operation.

To learn more about well log operations check out this Python Tool Pro tutorial.

Generate Petrel UI
# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum

smoothing_list={0:"barthann",1:"bartlett",2:"blackman",3:"bohman",4:"boxcar",5:"hann",6:"cosine",7:"nuttall",8:"exponential",9:"flattop",10:"hamming",11:"parzen",12:"taylor",13:"triang",14:"tukey",15:"gaussian"}

# The class WorkflowDescription is used to define the Cegal Prizm workflow. It is assigned to a Python variable called 'pwr_description'
pwr_description = WorkflowDescription(name="Smooth well log",
                                      category="Demo: Python operations - Wells",
                                      description="The script applies a rolling filter to smooth a well log, using a specified window size to determine the range of data points considered for each smoothing operation. This is a simple Cegal Prizm worklfow demonstrating the deployment of Python code to Petrel users and how you can expand Petrel functionality with additional algorithms.",
                                      authors="author@company",
                                      version="1.0")

# Use the variable pwr_description to define the UI in the Prizm Workflow Runner and let the Petrel user select the input data.
# This creates a Python dictionary 'parameters' with the GUID and/or values of the user's input data.

pwr_description.add_object_ref_parameter(name="well_id", label="Well", description="Select well", object_type=DomainObjectsEnum.Well)
pwr_description.add_object_ref_parameter(name="log_id", label="Log", description="The well log to be smoothed", object_type=DomainObjectsEnum.WellContinuousLog, linked_input_name="well_id")
pwr_description.add_enum_parameter(name="algorithm_smooth",label="Select the smoothing algorithm",description="List of available algorithms. This is a selection of window types in scipy.signal.windows",options=smoothing_list,default_value=15)
pwr_description.add_integer_parameter(name="window_length", label="Window Length", description="The window length to be used when smoothing", default_value=80, minimum_value=2, maximum_value=500)
pwr_description.add_string_parameter(name="suffix", label="Suffix", description="The suffix to be appended to the name of the smoothed log", default_value="smooth")


# End: PWR Description

Connect to Petrel and retrieve the user input
Using the class PetrelConnection from Python Tool Pro the Cegal Prizm workflow connects into Petrel and retrieves the object by GUID.

from cegalprizm.pythontool import PetrelConnection, Well ,WellLog

ptp = PetrelConnection()
print('PetrelConnection established')

petrel_objects = ptp.get_petrelobjects_by_guids([parameters['well_id'], parameters['log_id']])

# Extract the well object from the retrieved objects and check if it's valid
well = petrel_objects[0]
if not isinstance(well, Well)==True:
    raise AssertionError("No well selected")

print("Selected well passed to Cegal Prizm workflow")

# Extract the continuous log object from the retrieved objects and check if it's valid
cont_log = petrel_objects[1]
if not isinstance(cont_log, WellLog)==True:
    raise AssertionError("No well log selected")

print("Selected well log passed to Cegal Prizm workflow")


Apply the filter and write back the results to Petrel
# Convert the selected continuous log to a Pandas DataFrame and set the index to MD (Measured Depth)
logs_df = well.logs_dataframe(cont_log)
logs_df = logs_df.set_index('MD')
logs_df = logs_df[cont_log.petrel_name]

print("Pandas dataframe created for log calculation")

# Retrieve the selected smoothing algorithm from the parameters
selected_algorithm=parameters['algorithm_smooth']

# Apply the selected smoothing algorithm to the log DataFrame
if selected_algorithm==15:
    smooth_logs_df = logs_df.rolling(parameters['window_length'], win_type=smoothing_list[selected_algorithm], center=True).mean(std=20)
else:
    smooth_logs_df = logs_df.rolling(parameters['window_length'], win_type=smoothing_list[selected_algorithm], center=True).mean()

print("Smoothed log values created")

# Clone the original continuous log and append the specified suffix and algorithm details to its name
new_sm_log = cont_log.clone(f'{cont_log.petrel_name}_{parameters["suffix"]}_{smoothing_list[selected_algorithm]}_{parameters["window_length"]}')  # create the clone if it doesn't already exist

print("New log created in input tree")

# get columns of smooth_logs_df DataFrame and convert to NumPy ndarrays
md = smooth_logs_df.index.to_numpy()
new_sm_values = smooth_logs_df.to_numpy()

# Write the smoothed log values to the new log
new_sm_log.set_values(md, new_sm_values)

print("Smoothed log values written to new log")

==
Missing VS logs imputation
One of the main advantages of Python Tool Pro is that it opens data normally residing in Petrel to machine learning algorithms from open-source Python libraries like scikit learn or xgboost. A common workflow is to predict values for missing data, either because there is no data for that section of the log or because the log is missing for the well.

By using the available logs and high performing machine learning algorithms, it is possible to predict the missing log values effectively. We show here that we can predict Vs values in wells where this log is missing or incomplete with average absolute percentage errors of around 3-5% (around 95-98% accuracy).

However, it is important to note that the quality of the results is highly dependent on the amount and quality of the data being used. The workflow could also be improved with further data cleaning and handling prior to using machine learning, as well a fine tuning of the selected models.

For a full breakdown of the script please visit the Python Tool Pro tutorial.

Generate Petrel UI
# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription, DomainObjectsEnum, MeasurementNamesEnum

pwr_description = WorkflowDescription(name="VS log augmentation",
                                      category="ML",
                                      description="Augmenting missing values from the VS log",
                                      authors="author@company",
                                      version="1.0")

pwr_description.add_object_ref_parameter(name="training_well_ids", label="Input wells (minimum 10) for training set", description="Select wells you want to use as a training set", object_type=DomainObjectsEnum.Well, select_multiple=True)
pwr_description.add_boolean_parameter(name='ignore_min_train',label='Ignore minimum number (10) of training wells?',description='Choose if you ignore the minimum number of wells used for training the ML algorithm. It is recommended to use at least 10 wells.',default_value=False)
pwr_description.add_object_ref_parameter(name="training_gr_id", label="Select the gamma ray log for training", description="The gamma ray global well log used for training the model", object_type=DomainObjectsEnum.GlobalLogContinuous, template_type=['Gamma ray'])
pwr_description.add_object_ref_parameter(name="training_neutron_id", label="Select the neutron porosity logs for training", description="The neutron porosity global well log used for training the model", object_type=DomainObjectsEnum.GlobalLogContinuous, template_type=['Neutron'])
pwr_description.add_object_ref_parameter(name="training_rho_id", label="Select the density log for training", description="The density global well log used for training the model", object_type=DomainObjectsEnum.GlobalLogContinuous, template_type=['Density'])
pwr_description.add_object_ref_parameter(name="training_vp_id", label="Select the P-velocity log for training", description="The P-velocity global well log used for training the model", object_type=DomainObjectsEnum.GlobalLogContinuous, template_type=['P-velocity'])
pwr_description.add_object_ref_parameter(name="training_vs_id", label="Select the S-velocity log for training", description="The S-velocity global well log used for training the model", object_type=DomainObjectsEnum.GlobalLogContinuous, template_type=['S-velocity'])

# End: PWR Description
Import packages
from cegalprizm.pythontool import PetrelConnection, GlobalWellLog
import numpy as np
import pandas as pd

import warnings
warnings.filterwarnings('ignore')

# Machine learning libraries
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
Connect to Petrel and retrieve the user input

ptp = PetrelConnection()

vs_log=ptp.get_petrelobjects_by_guids([parameters["training_vs_id"]])[0]
print(vs_log)

# Initialize a list to store the user selected wells
nested_wells=[]
for el in parameters['training_well_ids']:
    nested_wells.append(ptp.get_petrelobjects_by_guids([el]))
# Check if no wells are selected and raise an error if true
if len(nested_wells) == 0:
    raise ValueError("No wells have been selected")

# Check if any selected wells are invalid and raise an error if true
if any(item is None for item in nested_wells):
    raise ValueError("Some selected wells are not valid")

# Check if the number of wells is less than the recommended value and the user has not chosen to ignore this minimum
if len(nested_wells) < 10 and parameters["ignore_min_train"]==False:
    raise ValueError("Number of wells used for training is less than the recommended value of 10.")

# Flatten the list of well objects
wells = []
wells = [item for sublist in nested_wells for item in sublist]

print("Training data wells retrieved")

# Retrieve log objects from Petrel based on user input
logs_list=ptp.get_petrelobjects_by_guids([parameters['training_gr_id'],parameters['training_neutron_id'],parameters['training_rho_id'],parameters['training_vp_id'],parameters['training_vs_id']])

# Check if no logs are selected or any selected logs are invalid and raise an error if true
if all(item is None for item in logs_list):
    raise ValueError("No training logs have been selected")

if not logs_list or any(item is None for item in logs_list):
    raise ValueError("Some selected training logs are not valid")

print("Training data logs retrieved")
Model Training and Validation

def data_augmentation(dataset, logs, targets):
    # Extract the specified logs from the dataset
    data=dataset[logs]

    # Define a list of estimators (machine learning models) to be used
    estimators = [XGBRegressor(n_estimators=300,
                               tree_method='gpu_hist',
                               learning_rate=0.05,
                               early_stopping_rounds=100,
                              ),
                  CatBoostRegressor(task_type='GPU',
                                    early_stopping_rounds=100,
                                   )
                 ]

    # Names for the estimators for reference
    estimator_names = ['EXTREME BOOST REGRESSOR',
                       'CATBOOST REGRESSOR']

    # Copy the dataset to store results
    results = dataset.copy()

    # Loop through each target log to predict its values
    for target in targets:
        print('----- Predicting values for: {} -----'.format(target))

        # Prepare training data by dropping rows where target is NaN
        traindata = data[data[target].notna()]
        X = traindata.drop([target], axis = 1)
        Y = traindata[target]

        # Fill NaN values in features with their mean
        X_inp = X.apply(lambda x: x.fillna(x.mean()), axis = 0)

        # Split data into training and validation sets
        X_train, X_val, Y_train, Y_val = train_test_split(X_inp,
                                                          Y,
                                                          test_size = 0.25,
                                                          random_state = 42)

        # Initialize variables for model selection
        i = 0
        rme_errors = []

        # Train each estimator and evaluate its performance
        for estimator in estimators:
            print('- Model: {}'.format(estimator_names[i]))
            estimator.fit(X_train,
                          Y_train.values.ravel(),
                          eval_set = [(X_val, Y_val)],
                          verbose=False
                          )
            # Predict on training and validation data
            train_pred = estimator.predict(X_train)
            val_pred = estimator.predict(X_val)

            # Calculate mean absolute error for validation data
            mabs_error_train = mean_absolute_error(Y_train, train_pred)
            mabs_error_val = mean_absolute_error(Y_val, val_pred)
            rme_errors.append(mabs_error_val)
            print('-- Mean absolute error for validation data: ' + str(round(mabs_error_val,3)))

            i += 1


        # Select the best performing model for imputation
        selected_model_index = rme_errors.index(min(rme_errors))
        print('Best model for augmentation: {}'.format(estimator_names[selected_model_index]))

        model = estimators[selected_model_index]
        model.fit(X_train,
                      Y_train.values.ravel(),
                      eval_set = [(X_val, Y_val)],
                      verbose = 0
                    )

        # Prepare the entire dataset for prediction
        X_train_log = data.drop([target], axis=1)
        X_train_log2 = X_train_log.apply(lambda x: x.fillna(x.mean()), axis=0)

        # Predicting values for log on whole dataset
        results.loc[:, target + '_predicted'] = model.predict(X_train_log2)

        # Impute NaN values in log using the model predictions
        results[target + '_combined'] = results[target]
        results[target + '_combined'].fillna(results[target + '_predicted'], inplace=True)

    return results, model

Define function which writes the results back to Petrel


def write_back(wells, well_data,vs_log):

    #Loop through each well and process its data
    for w in wells:

        print("Vs prediction for well:")
        print(w.petrel_name)

        # Create new logs in Petrel for predicted and combined VS data
        print("Creating vs_prediction log for well "+w.petrel_name)
        vs_pred_well=vs_pred.create_well_log(w)
        print("Creating vs_combined log for well "+w.petrel_name)
        vs_combined_well=vs_combined.create_well_log(w)

        # Extract the relevant data for the current well
        print("Creating current DataFrame for well "+w.petrel_name)
        current_well_df = well_data.loc[well_data['WELL'] == w.petrel_name]

        # Retrieve MD values and predicted VS values for the well
        print("Getting MD values for well "+w.petrel_name)
        md_values=current_well_df['MD'].to_list()
        print("Getting vs_predicted values for well "+w.petrel_name)
        predict_values=current_well_df[vs_log.petrel_name+'_predicted'].to_numpy()
        print("Getting vs_combined values for well "+w.petrel_name)
        combined_values=current_well_df[vs_log.petrel_name+'_combined'].to_numpy()

        # Write the predicted and combined VS values back to the well logs in Petrel
        print("Setting vs_predicted values for well "+w.petrel_name)
        vs_pred_well.readonly=False
        vs_pred_well.set_values(md_values,predict_values)
        print("Setting vs_combined values for well "+w.petrel_name)
        vs_combined_well.readonly=False
        vs_combined_well.set_values(md_values,combined_values)
Clean the data , apply the trained model and write the results back to Petrel


log_names=[i.petrel_name for i in logs_list]


print("Creating Pandas DataFrame from training dataset")
well_data = pd.DataFrame()

for w in wells:
    df = w.logs_dataframe(logs_list)
    df['WELL'] = w.petrel_name
    well_data = pd.concat([well_data, df])

print("Pandas DataFrame created")


print("Data clean-up")

print("Cleaning up neutron porosity")
well_data[log_names[1]] = np.where((well_data[log_names[1]] >= 0) & (well_data[log_names[1]] <= 1), well_data[log_names[1]], np.nan)

print("Cleaning up gamma ray")
well_data[log_names[0]] = np.where(well_data[log_names[0]] <= 300, well_data[log_names[0]], np.nan)

print("Cleaning up null values")
null_counts = well_data.groupby('WELL')[log_names].apply(lambda x: x.isnull().sum()/ len(x) * 100).round(1)
null_counts.sort_values(log_names[3])

logs = ['MD', log_names[0], log_names[3], log_names[2], log_names[1], log_names[4]]
target = vs_log.petrel_name

print("Starting data augmentation")
results, model = data_augmentation(well_data, [log_names[0], log_names[3], log_names[2], log_names[1], log_names[4], 'MD'], [target])
print("Finished data augmentation")


# Write the augmented data back to Petrel
print("Writing data back to Petrel")
vs_pred=vs_log.clone(name_of_clone ='VS_predicted')
vs_combined=vs_log.clone(name_of_clone ='VS_combined')
print("Created Vs_predicted and vs_combined global well logs ")

write_back(wells = wells,well_data = results,vs_log=vs_log)
print("All data written back to Petrel")

print("This workflow uses the gamma ray, p-velocity, s-velocity, neutron porosity and density logs from all selected wells to train a machine learning algorithm to predict the s-velocity. This predictor is applied to all selected input wells to fill gaps in the Vs log. If any one input logs exist for a well the predictor will be applied. Be aware that in the case that only one log is used to apply the predictor the results might not be accurate.")


===
Fault prediction
In this Notebook, we show how you can apply complex machine learning algorithms on your Petrel data. In this case, we will use a neural network to predict a fault model on a seismic cube.

For a full breakdown of the script please visit the Python Tool Pro tutorial.

Generate Petrel UI
# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum,MeasurementNamesEnum,TemplateNamesEnum

pwr_description = WorkflowDescription(name="Fault prediction",
                                      category="ML",
                                      description="Use this workflow to create a fault model",
                                      authors="author@company",
                                      version="0.1")


pwr_description.add_object_ref_parameter(name='seismic_id',label='Seismic input cube',description='Select a seismic cube',object_type=DomainObjectsEnum.Seismic3D)
pwr_description.add_string_parameter(name='new_name_seismic',label='Name for fault prediction cube',description='Give the name for the new fault prediction cube',default_value='fault_prediction')


# End: PWR Description
Connect to Petrel and retrieve the user input
import math
from tensorflow.keras.models import load_model, model_from_json
import numpy as np
import tensorflow as tf
import os
import numpy as np
import pandas as pd
from cegalprizm.pythontool import PetrelConnection

# Connect to Petrel
ptp = PetrelConnection()
print('Petrel connection established')

# Retrieve the seismic cube and template selected by the user
petrel_objects = ptp.get_petrelobjects_by_guids([parameters['seismic_id']])

# Assign the user defined name (from the string input parameter) to a variable
newname=parameters['new_name_seismic']
#Verify that a name has been defined
if len(newname) == 0:
    raise ValueError(f"{pwr_description.get_label('new_name_seismic')} : No name defined")
print(f"{pwr_description.get_label('new_name_seismic')} retrieved")

# Assign the user selected seismic cube to a variable
cube=petrel_objects[0]
#Verify that the seismic cube has been selected
if cube is None:
    raise ValueError("No seismic cube has been selected")
print('Selected seismic retrieved')
Chunk sesismic data
We will create a chunk of the seismic of dimensions 128x128x128. This size is used because the neural network algorithm in this specific case requires the input data to to have these dimensions.

span = 127
x = int((cube.extent.i - 128)/2)
y = int((cube.extent.j - 128)/2)
z = int((cube.extent.k - 128)/2)
arr  = cube.chunk((x,x+span),(y,y+span),(z,z+span)).as_array()

print('Created seismic array')
Load pre-trained model
This machine learning algorithm is published and GitHub and can be found using following link #### xinwucwp/faultSeg

faultpred.png
loaded_model = load_model("fseg-70.hdf5", custom_objects={'cross_entropy_balanced': tf.keras.losses.BinaryCrossentropy()})
print('Loaded pretrained model')
Applying a pre-trained neural network algorithm
This function processes a 3D array (representing a seismic chunk) by rotating it, normalizing it, reshaping it for a machine learning model, obtaining predictions, and then reshaping and rotating the output back to its original orientation.


def fault_attribute_calculator(arr):
    arr = np.rot90(arr, 1, (0,2))
    arr = (arr - arr.mean())/arr.std()
    n1, n2, n3 = 128, 128, 128
    gx = np.reshape(arr,(1,n1,n2,n3,1))
    Y = loaded_model.predict(gx,verbose=1)
    Y = Y.reshape((n1,n2,n3))
    return np.rot90(Y, -1, (0,2))

Writing results back to Petrel
We can now apply the fault prediction on our entire seismic cube and write the results back to Petrel. We will create an empty clone of our seismic data and write the results back to Petrel by inserting the fault prediction values into the cloned seismic cube.

#Retrieve the Variance template
var_temp=[i for i in ptp.templates if i.petrel_name=="Seismic - Variance"][0]

#Create new seismic cube
cube_fault_prediction = cube.clone(newname, copy_values = False, template=var_temp)

print('Created seismic clone')

Here we create a Python function to apply the fault prediction on the entire cube and using an overlap between neighbouring chunks to avoid edge effects.

def apply_calculator(src_cube, dst_cube, calculator, loaded_model,chunk_size = (128,128,128)):

    import math
    loaded_model=loaded_model

    # Define constants for blending and overlap handling
    a = 0.5
    overlapp = 0.1

    # Retrieve the dimensions of the source cube
    m1= src_cube.extent.i
    m2 = src_cube.extent.j
    m3 = src_cube.extent.k

    # Retrieve the chunk size
    n1= chunk_size[0]
    n2= chunk_size[1]
    n3= chunk_size[2]

    # Calculate the number of chunks in each dimension
    x_count = math.ceil(2*m1/n1)
    y_count = math.ceil(2*m2/n2)
    z_count = math.ceil(2*m3/n3)

    # Loop over chunks in the x-direction
    for x in range(x_count):
        print('Applying fault prediction on entire seismic cube and merging overlap. Looping over in x,y and z direction. This is loop '+str(x)+' out of '+str(x_count-1)+' in x-direction')
        # Skip chunks that exceed the cube boundary in the x-direction
        if ( x*(n1/(1+overlapp)) > (m1 - n1/2 -1)):
              continue
        # Loop over chunks in the y-direction
        for y in range(y_count):
            # Skip chunks that exceed the cube boundary in the y-direction
            if (y*(n2/(1+overlapp)) > (m2 - n2/2 -1)):
                continue
            # Loop over chunks in the z-direction
            for z in range(z_count):
                # Skip chunks that exceed the cube boundary in the z-direction
                if (z*(n3/(1+overlapp)) > (m3 - n3/2 -1) ):
                      continue
                # Calculate the offset for each dimension
                x_offset = math.floor(min(x*(n1/(1+overlapp)), m1 - n1 -1))
                y_offset = math.floor(min(y*(n2/(1+overlapp)), m2 - n2 -1))
                z_offset = math.floor(min(z*(n3/(1+overlapp)), m3 - n3 -1))
                # Define the range for each dimension
                x_range = (x_offset + 1, x_offset+n1)
                y_range = (y_offset + 1, y_offset+n2)
                z_range = (z_offset + 1, z_offset+n3)
                # Retrieve the chunk of data from the source cube
                src_data = src_cube.chunk(x_range, y_range, z_range).as_array()
                # Process the chunk with the fault attribute calculator
                with dst_cube.chunk(x_range, y_range, z_range).values() as dst:
                    result = calculator(src_data,loaded_model)
                    # Apply a mask to blend the results and existing data
                    mask = (dst == 0)
                    dst[mask] = result[mask]
                    dst[2:-2,2:-2,2:-2] = a*result[2:-2,2:-2,2:-2] + (1-a)*dst[2:-2,2:-2,2:-2]
Apply the workflow to the whole cube
apply_calculator(cube, cube_fault_prediction, fault_attribute_calculator,loaded_model)
faultprediction_PWR_gif.gif


===
Create Pseudo Wells
This workflow is designed to create pseudo wells within a specified polygon in a Petrel project. The workflow allows users to select a polygon, define the number of pseudo wells, set the TVD (True Vertical Depth) at the first and last points, and choose a folder to place the pseudo wells in. The script generates wells with an adjustable grid approach, ensuring they fit within the polygon and are as evenly spaced as possible. The wells are then created in Petrel with specified wellhead coordinates and surveys.

To learn more about how to create wells, check out this Python Tool Pro tutorial.

Generate Petrel UI
# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum,MeasurementNamesEnum,TemplateNamesEnum

pwr_description = WorkflowDescription(name="Create Pseudo Wells",
                                      category="Wells",
                                      description="Use this workflow to create pseudo wells within an input polygon",
                                      authors="author@company",
                                      version="1.0")

# Use the variable pwr_description to define the UI in the Prizm Workflow Runner and let the Petrel user select the input data.
# This creates a Python dictionary 'parameters' with the GUID and/or values of the user's input data.


pwr_description.add_object_ref_parameter(name='polygon_id',label='Polygon',description='Select a polygon. The polygon must be closed and must contain only 1 polyline,',object_type=DomainObjectsEnum.PolylineSet)
pwr_description.add_integer_parameter(name='pseudo_id',label='Number of Pseudo Wells',description='Define the number of pseudo wells you want to create. ',default_value=200, minimum_value=1, maximum_value=1000)
pwr_description.add_integer_parameter(name='tvd_start_id',label='TVD at first point',description='Define the starting point of the pseudo wells. ',default_value=0, minimum_value=0, maximum_value=10000)
pwr_description.add_integer_parameter(name='tvd_bottom_id',label='TVD at last point',description='Define the last TVD point of the pseudo wells. ',default_value=4000, minimum_value=25, maximum_value=10000)
pwr_description.add_object_ref_parameter(name='folder_id',label='Well Folder',description='Select the well folder you want to place the pseudo wells in.',object_type=DomainObjectsEnum.WellsFolder)


# End: PWR Description
Connect to Petrel and retrieve the user input
from cegalprizm.pythontool import *
import numpy as np

# Connect to Petrel
petrel=PetrelConnection(allow_experimental=True)
print('PetrelConnection established')

# Retrieve the Polygon selected by the user
polygon = petrel.get_petrelobjects_by_guids([parameters['polygon_id']])[0]

#Check if the polygon is closed and has only one polyline
if len(list(polygon.polylines)) > 1 :
    raise ValueError(f"{pwr_description.get_label('polygon_id')} : Polygon has more than 1 polyline")

if polygon.is_closed(0) == False:
    raise ValueError(f"{pwr_description.get_label('polygon_id')} : Polygon is not closed.")

print(f"{pwr_description.get_label('polygon_id')} retrieved")

# Assign the user defined number of pseudo wells to a variable
num_wells=parameters['pseudo_id']

# Assign the user defined TVD at first point to a variable
TVD_start=parameters['tvd_start_id']

# Assign the user defined TVD at last point to a variable
TVD_end=parameters['tvd_bottom_id']

# Ensure the start TVD is not larger than the bottom TVD
if TVD_start > TVD_end :
    raise ValueError("Starting depth can't be larger than the TVD at the last point")

# Assign the user selected well folder to a variable
selected_folder=petrel.get_petrelobjects_by_guids([parameters['folder_id']])[0]

#Verify that the well folder has been selected
if selected_folder is None:
    raise ValueError("No well folder has been selected")
print('Well folder retrieved')

Parsing the polygon coordinates
The parse_polygon_coordinates function is designed to process polygon data represented as separate lists of x, y, and z coordinates. The function takes these lists (packed in a tuple) as input , unpacks it and returns a list of vertex tuples, which can be used to represent the polygon in subsequent operations, such as plotting or calculating areas.

def parse_polygon_coordinates(coord_lists):

    # The input 'coord_lists' is a tuple of three lists: x coordinates, y coordinates, and z coordinates.
    # This line unpacks the tuple into three separate lists and ignores the z coordinates using the underscore '_'.
    x_coords, y_coords, _ = coord_lists

    # This line combines the x and y coordinates into pairs (tuples) representing each vertex of the polygon.
    # 'zip' is used to pair corresponding elements from the x and y lists.
    # The resulting pairs are converted into a list, which represents the vertices of the polygon.
    vertices = list(zip(x_coords, y_coords))
    return (vertices)

polygon_data = polygon.get_positions(0)
polygon_coordinates = parse_polygon_coordinates(polygon_data)
print(f"Polygon coordinates : {polygon_coordinates}")
Approximate the area of the polygon
This function is designed to estimate the area of a polygon based on its bounding box. The bounding box is the smallest rectangle that completely encloses the polygon. This method provides an approximation of the area, especially useful when a quick estimation is needed, and the polygon has an irregular shape.

def approximate_polygon_area(polygon):
    # Unpacks the polygon's vertices into separate lists of x and y coordinates.
    # The '*' operator is used to unpack the list of tuples into separate tuples for x and y coordinates.
    # 'zip' then pairs each x coordinate with its corresponding y coordinate.
    x_coords, y_coords = zip(*polygon)

    # Calculates the approximate area of the polygon. This is done by multiplying the width and height of the bounding box
    # The width is the difference between the maximum and minimum x coordinates.
    # The height is the difference between the maximum and minimum y coordinates.
    return (max(x_coords) - min(x_coords)) * (max(y_coords) - min(y_coords))
Check if a point is inside the polygon
This function uses the ray-casting algorithm to determine if a given point is inside a polygon. The basic idea is to draw a horizontal line from the point to the right and count how many times this line intersects with the polygon’s edges. If the number of intersections is odd, the point is inside; if even, it’s outside.

Here’s what happens in the function:

Iterate Through Polygon Edges: The function walks through each edge of the polygon. An edge is defined by two consecutive vertices of the polygon.

Horizontal Line Intersection: For each edge, the function checks if a horizontal line from the point would intersect with it. This is done by comparing the y-coordinate of the point with the y-coordinates of the edge’s vertices and checking if the x-coordinate of the point is to the left of the edge.

Count Intersections: Each time an intersection is found (meaning the point is to the left of the edge and aligned vertically with it), the function toggles the inside variable. This effectively counts how many times the point crosses the boundary of the polygon when moving horizontally to the right.

Determine Inside or Outside: At the end of the iteration, if inside is True, the point is inside the polygon; if False, it’s outside.

def is_point_inside_polygon(x, y, polygon):
    # Get the number of vertices in the polygon.
    n = len(polygon)

    # Initialize a variable to track whether the point is inside the polygon.
    inside = False

    # Get the coordinates of the first vertex of the polygon.
    p1x, p1y = polygon[0]

    # Iterate over the edges of the polygon by walking through each pair of vertices.
    for i in range(n + 1):
        # p2x, p2y are the coordinates of the next vertex in the polygon.
        # The modulo operator (%) is used to loop back to the first vertex at the end.
        p2x, p2y = polygon[i % n]

        # Check if the y-coordinate of the point is between the y-coordinates of the edge.
        if y > min(p1y, p2y):
            # Check if the x-coordinate of the point is to the left of the edge.
            if y <= max(p1y, p2y):
                # Calculate the x-coordinate where the horizontal line through the point intersects the edge.
                # This is only done if the edge is not horizontal.
                if x <= max(p1x, p2x):
                    if p1y != p2y:
                        xints = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x
                    # If the point is to the left of this intersection point, it affects the inside/outside status.
                    if p1x == p2x or x <= xints:
                        inside = not inside

        p1x, p1y = p2x, p2y

    return inside
Generate an adjustable grid of points within the polygon
This function is designed to place a specified number of wells within a polygon by generating a grid of points and adjusting the grid size to accommodate all the wells.

def generate_adjustable_grid(polygon, num_wells):

    # Find the minimum and maximum x and y coordinates of the polygon to determine its bounding box.
    minx, miny = min(x for x, y in polygon), min(y for x, y in polygon)
    maxx, maxy = max(x for x, y in polygon), max(y for x, y in polygon)

    # Calculate the approximate area of the polygon using its bounding box.
    area = approximate_polygon_area(polygon)

    # Initial estimate of grid spacing based on the approximate area and the number of wells.
    grid_spacing = np.sqrt(area / num_wells)

    # Loop to adjust the grid spacing to fit the wells.
    while True:
        # Initialize an empty list to store grid points that fall inside the polygon.
        grid_points = []
        # Create a grid over the polygon's bounding box with the current grid spacing.
        for x in np.arange(minx, maxx, grid_spacing):
            for y in np.arange(miny, maxy, grid_spacing):
                # Check if the current grid point is inside the polygon and if we haven't exceeded the number of wells.
                if is_point_inside_polygon(x, y, polygon) and len(grid_points) < num_wells:
                    # Add the grid point to the list of well locations.
                    grid_points.append((x, y))

        # Check if the number of grid points is sufficient or if the grid spacing is too small.
        if len(grid_points) >= num_wells or grid_spacing < 0.01:  # Minimum spacing threshold to prevent infinite loop
            break

        # Reduce the grid spacing to attempt to fit more wells in the next iteration.
        grid_spacing *= 0.95  # Reduce spacing to fit more points

    return grid_points[:num_wells]  # Return only the required number of well locations

# Generating well coordinates on the adjustable grid
adjustable_grid_placed_wells = generate_adjustable_grid(polygon_coordinates, num_wells)


adjustable_grid_placed_wells

Write the pseudo wells back to Petrel
# Iterate through the list of well coordinates
for wll in range(len(adjustable_grid_placed_wells)):
    # Create new well and place it in the user selected folder
    new_well=petrel.create_well('Pseudowell'+str(wll) ,selected_folder)
    # Set well head coordinates using the generated well coordinates
    new_well.wellhead_coordinates=adjustable_grid_placed_wells[wll]
    # Set the well datum
    new_well.well_datum=('KB',25)
    # Create new deviation survey
    new_surv= new_well.create_well_survey('Pseudo surv','X Y Z survey')
    new_surv.readonly=False
    # Set trajectory of the well. In this case we're creating straight wells (first and last x,y-values are the same). Set the start and end TVD using the user defined values
    new_surv.set(xs=[adjustable_grid_placed_wells[wll][0],adjustable_grid_placed_wells[wll][0]], ys=[adjustable_grid_placed_wells[wll][1],adjustable_grid_placed_wells[wll][1]], zs=[TVD_start,-TVD_end])
    # Set the survey as active
    new_surv.set_survey_as_definitive()
print("Wells successfully created")
create_wells.gif


===

Update well tops from NPD
In this tutorial we’ll update the Groups from the Petrel well tops folder using the data published on the Norwegian Petroleum Directorate (NPD).

For a full breakdown of the script please visit the Python Tool Pro tutorial.

Generate Petrel UI
# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription,DomainObjectsEnum,MeasurementNamesEnum,TemplateNamesEnum

pwr_description = WorkflowDescription(name="Update well tops from NPD",
                                      category="DM",
                                      description="Use this workflow to update the Petrel well tops using the data published on the Norwegian Petroleum Directorate",
                                      authors="author@company",
                                      version="1.0")

# Use the variable pwr_description to define the UI in the Prizm Workflow Runner and let the Petrel user select the input data.
# This creates a Python dictionary 'parameters' with the GUID and/or values of the user's input data.

pwr_description.add_object_ref_parameter(name='marker_collection',label='Select Marker Collection',description='Select a Marker Collection containing the well tops you want to update',object_type=DomainObjectsEnum.WellMarkerCollection)

# End: PWR Description
<cegalprizm.pycoderunner.workflow_description.WorkflowDescription at 0x21ea809e2f0>
Connect to Petrel and retrieve the user input
from cegalprizm.pythontool import PetrelConnection
import pandas as pd
import numpy as np

# Connect to Petrel
ptp = PetrelConnection(allow_experimental=True)
print('PetrelConnection established')

# Retrieve the marker collection selected by the user
petrel_objects = petrel.get_petrelobjects_by_guids([parameters['marker_collection']])

# Assign the user selected marker collection to variable
mc = petrel_objects[0]

#Verify that a marker collection has been selected
if mc is None:
    raise ValueError(f"{pwr_description.get_label('marker_collection')}: no marker collection selected")
print('Selected marker collection retrieved')

Import NPD welltops
We start by accessing the NPD url pointing to the excel table which contains the welltop information and assign that to a dataframe. Then we format the dataframe by drop some unnecessary columns, renaming some other columns and dropping the information regarding Formation.

NPD_WT_df=pd.read_excel("https://factpages.npd.no/ReportServer_npdpublic?/FactPages/tableview/strat_litho_wellbore&rs:Command=Render&rc:Toolbar=false&rc:Parameters=f&IpAddress=not_used&CultureCode=en&rs:Format=EXCEL&Top100=false",sheet_name='strat_litho_wellbore')
NPD_WT_df=NPD_WT_df.drop(columns=['NPDID lithostrat. unit','Wellbore completion date','NPDID wellbore','Date updated','Level','Date sync NPD','Bottom depth [m]'])
NPD_WT_GP_df= NPD_WT_df[NPD_WT_df['Lithostrat. unit'].str.contains(' GP')]
NPD_WT_GP_df.rename(columns = {'Lithostrat. unit':'Surface','Top depth [m]':'MD','Wellbore name':'Well'}, inplace = True)

NPD_WT_GP_df['Surface']=NPD_WT_GP_df['Surface'].str.replace('GP', 'GP. Top')
Create the Petrel welltop DB
Next, we generate a dataframe from the marker collection located in our Petrel project. We drop the information regarding the Formations and we rename some columns.

# Get the markercollection in a data frame
df_mc = mc.as_dataframe(False)

#make a new dataframe using just 3 attributes from the marker collection
newmc_df=df_mc[['Well identifier (Well name)','MD','Surface']]

#Only keep the Groups from the marker collection
Gp_df=newmc_df[newmc_df['Surface'].str.contains('GP.')]
Gp_df=Gp_df.drop_duplicates()

#Sort the dataframe and rename a column
Gp_df=Gp_df.sort_values(by=[ 'Well identifier (Well name)'], ascending=[True])
Gp_df.rename(columns = {'Well identifier (Well name)':'Well'}, inplace = True)
Format the NPD welltop DB
Finally, we eliminate any well which does not exist in the Petrel project from the NPD dataframe and we sort the two data frames on both the well name and the measured depth:

NPD_cut=pd.DataFrame()
well_list = list(Gp_df.Well.unique())
for l in range(len(well_list)):
    NPD_cut=pd.concat([NPD_cut,NPD_WT_GP_df[NPD_WT_GP_df['Well'].str.fullmatch(well_list[l])]],axis=0, ignore_index=True)
NPD_cut.sort_values(["Well","MD"], axis = 0, ascending=True, inplace=True,na_position="first")
Gp_df.sort_values(["Well","MD"], axis = 0, ascending=True, inplace=True,na_position="first")
Check which well tops are missing
Now we’ll compare the two dataframes and for each well, we identify the Group information missing from the Petrel project.

for l in range(len(well_list)):
    NPD_well=NPD_cut[NPD_cut['Well'].str.contains(well_list[l])]
    Ptd_well=Gp_df[Gp_df['Well'].str.contains(well_list[l])]
    missing = pd.concat([NPD_well,Ptd_well]).drop_duplicates(subset=['Surface'], keep=False)
    if len(missing) == 0:
        print(str(well_list[l])+ '  is up to date' )
    elif len(missing) == 1:
        print(str(well_list[l])+ ' is missing the  '+str( missing['Surface'].values[0]))
    else:
        for i in range(len(missing['Surface'])):
            print(str(well_list[l])+ ' is missing the  '+ str(missing['Surface'].values[i]))
Write missing tops to Petrel
After identifying the missing Groups we can write them back to our Petrel project.

mc.readonly = False
for l in range(len(well_list)):
    NPD_well=NPD_cut[NPD_cut['Well'].str.contains(well_list[l])]
    Ptd_well=Gp_df[Gp_df['Well'].str.contains(well_list[l])]
    missing = pd.concat([NPD_well,Ptd_well]).drop_duplicates(subset=['Surface'], keep=False)
    curr_well=ptp.wells["Input/Wells/wellTops/" + well_list[l] ]
    depth = mc.attributes["MD"]
    if len(missing) == 0:
        pass
    elif len(missing) == 1:
        marker = mc.stratigraphies[str(missing['Surface'].values[0])]
        mc.add_marker(well=curr_well,marker_stratigraphy=marker,measured_depth=float(missing['MD'].values[0]))
    else:
        for i in range(len(missing['Surface'])):
            marker = mc.stratigraphies[str(missing['Surface'].values[i])]
            mc.add_marker(well=curr_well,marker_stratigraphy=marker,measured_depth=float(missing['MD'].values[i]))
Check MD values
So far we have added the missing welltops from NPD but we did not check if the existing ones have the correct measured depth.

for l in range(len(well_list)):
    NPD_well=NPD_cut[NPD_cut['Well'].str.contains(well_list[l])]
    Ptd_well=Gp_df[Gp_df['Well'].str.contains(well_list[l])]
    missing = pd.concat([NPD_well,Ptd_well]).drop_duplicates(subset=['MD','Surface'], keep=False)
    missing=missing.sort_values(by=['Surface'], ascending=[True])
    if len(missing) == 0:
        print(str(well_list[l])+'  is up to date' )
    else:
        for i in range(0,len(missing['Surface'])-1,2):
            print(str(well_list[l])+ '--- the '+ str( missing['Surface'].values[i]) + "  has "+ str(missing['MD'].values[i])+ " as MD on NPD and "+ str(missing['MD'].values[i+1]) + " as MD in Petrel" )
Update MD values
Now that we’ve identified each well that contains a well top at the wrong depth we can correct the MD values in Petrel.

mc.readonly = False
for l in range(len(well_list)):
    NPD_well=NPD_cut[NPD_cut['Well'].str.contains(well_list[l])]
    Ptd_well=Gp_df[Gp_df['Well'].str.contains(well_list[l])]
    missing = pd.concat([NPD_well,Ptd_well]).drop_duplicates(subset=['MD','Surface'], keep=False)
    missing=missing.sort_values(by=['Surface'], ascending=[True])
    curr_well=ptp.wells["Input/Wells/wellTops/" + well_list[l] ]
    depth = mc.attributes["MD"]
    if len(missing) == 0:
        pass
    else:
        for i in range(0,len(missing['Surface'])-1,2):
            marker = mc.stratigraphies[str(missing['Surface'].values[i])]
            depth.set_values(data=[missing['MD'].values[i]],marker_stratigraphy=marker,well=curr_well)

print("All welltops have been updated")
well_tops.gif
=====
Investigator - Well Report
This tutorial showcases an example of how, using an investigation as input, a user can auto-generate a PDF report showing some summary plots followed by a standard set of plots for every well.

Running this workflow requires the use of two different files:

Template notebook (see here)

The template notebook contains python code which populates a report notebook which is parameterized for the specific investigation for which the report is required. For example, it could repeat a group of plots for each dataset or for each entry in a discrete dimension. The template notebook looks complex but it effectively calls Investigator to create the necessary plots. These calls can be wrapped in loops and conditions as necessary to ensure the required plots are produced.

The Report Generation python script (see here)

This python script runs the workflow. It is used to setup the investigation as required and then programmatically runs the template notebook before finally exporting the report notebook to a document.

Generate Petrel UI
# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription, DomainObjectsEnum

pwr_description = WorkflowDescription(name="Well report",
                                      category="Reports",
                                      description="This notebook creates a standard well log report from an investigation and writes the PDF back to the users PC",
                                      authors="author@company",
                                      version="1.0")

# Use the variable pwr_description to define the UI in the Prizm Workflow Runner and let the Petrel user select the input data.
# This creates a Python dictionary 'parameters' with the GUID and/or values of the user's input data.


pwr_description.add_object_ref_parameter(name="investigation_id", label="Investigation", description="The investigation containing the data on which to report", object_type=DomainObjectsEnum.Investigation)
pwr_description.add_string_parameter(name="suffix", label="Suffix", description="The suffix to be applied to the report filename", default_value="")
pwr_description.add_folder_parameter(name="destination_path", label="Destination folder", description="The folder into which the generate report will be uploaded")
pwr_description.add_boolean_parameter(name="can_overwrite", label="Overwrite", description="The generated report will overwrite if necessary", default_value=False)
pwr_description.add_boolean_parameter(name="open_on_upload", label="Open report", description="The generated report will be opened on completion", default_value=True)

# End: PWR Description
<cegalprizm.pycoderunner.workflow_description.WorkflowDescription at 0x21ea809e2f0>
Connect to Petrel and retrieve the user input
if 'parameters' not in locals() and 'parameters' not in globals():
    parameters = pwr_description.get_default_parameters()

# Assign the user selected investigation to a variable
investigation_id = parameters['investigation_id']
# Verify that the an investigation has been selected
if investigation_id is None or len(investigation_id) == 0:
    raise ValueError(f"{pwr_description.get_label('investigation_id')}: No investigation has been selected")

# Assign the user defined folder path to a variable
destination_path = parameters['destination_path']
# Verify that the path has been defined
if destination_path is None or len(destination_path) == 0:
    raise ValueError(f"{pwr_description.get_label('destination_path')}: No folder has been selected")

from cegalprizm.investigator import InvestigatorConnection

# Connect to Petrel
inv_conn = InvestigatorConnection(use_licensed_features=True)

# Load the user selected investigation to a variable
inv = inv_conn.load_investigation(investigation_id=investigation_id)

# Ensure that the user selected investigation has the Z spatial dimension
z_dimension_name = next((dimension.name for dimension in inv.continuous_dimension_property_names if dimension.property_name == 'Spatial/ElevationDepth'), None)
if not z_dimension_name:
  raise ValueError("Selected Investigation must contain a Z spatial dimension")

# Ensure that the user selected investigation has the Facies discrete dimension
facies_dimension_name = next((dimension.name for dimension in inv.discrete_dimension_property_names if dimension.property_name == 'Facies/Facies'), None)
if not facies_dimension_name:
  facies_dimension_name = next((dimension.name for dimension in inv.discrete_dimension_property_names if dimension.property_name.startswith('Facies')), None)
if not facies_dimension_name:
  raise ValueError("Selected Investigation must contain a Facies discrete dimension")

# Ensure that the user selected investigation a wellog dataset with at least on well
wells = [t for t in inv.dataset_geometries if t[1] == 'regular1d']
if len(wells) == 0:
   raise ValueError("Selected Investigation must contain welllog datasets.\nPlease check the data loading report for the investigation.")

Generate Report
We start by accessing the NPD url pointing to the excel table which contains the welltop information and assign that to a dataframe. Then we format the dataframe by drop some unnecessary columns, renaming some other columns and dropping the information regarding Formation.

import os
import sys

# Getting the current working directory and storing it in the variable cwd
cwd = os.getcwd()
print(cwd)
# Appending the "./report_notebooks" directory to the system path for module import
sys.path.append(os.path.join(cwd, "./report_notebooks"))
print(sys.path)
# Importing the generate_report_from_template function from the ReportGenerator module
from ReportGenerator import generate_report_from_template

# Creating the path to the template notebook using the current working directory
template_notebook_path = os.path.join(cwd, "./WellLogReportTemplate.ipynb")
print(template_notebook_path)
# Constructing a suffix for the output file name based on the user defined 'suffix' parameter, if it exists and is non-empty
suffix = ('-' + parameters['suffix']) if len(str(parameters['suffix'])) > 0 else ''
# Formatting the output document's filename with the optional suffix
output_document_filename = f"WellLogReport{suffix}.pdf"

# Calling the generate_report_from_template function with various parameters to generate a report

generate_report_from_template(template_notebook_path=template_notebook_path,
                              output_document_filename=output_document_filename,
                              working_path=working_path,
                              investigation_id=investigation_id,
                              upload_to_client=True,
                              destination_path=destination_path,
                              can_overwrite=parameters['can_overwrite'], # Overwrite existing file with the same name based on user input
                              open_on_upload=parameters['open_on_upload'])# Open the file after completion based on the user input
Petrel_HGR34VAufx.gif

====
Investigator - Model QC Report
This tutorial showcases an example of how, using an investigation as input, a user can auto-generate a PDF report showing some plots which compare the raw well data against the upscaled data followed by an analysis of upscaled vs model properties for each zone in the model.

Running this workflow requires the use of two different files:

Template notebook (see here)

The template notebook contains python code which populates a report notebook which is parameterized for the specific investigation for which the report is required. For example, it could repeat a group of plots for each dataset or for each entry in a discrete dimension. The template notebook looks complex but it effectively calls Investigator to create the necessary plots. These calls can be wrapped in loops and conditions as necessary to ensure the required plots are produced.

The Report Generation python script (see here)

This python script runs the workflow. It is used to setup the investigation as required and then programmatically runs the template notebook before finally exporting the report notebook to a document.

Generate Petrel UI
# Start: PWR Description

from cegalprizm.pycoderunner import WorkflowDescription, DomainObjectsEnum

pwr_description = WorkflowDescription(name="Model upscaling QC report",
                                      category="Reports",
                                      description="This notebook creates a model upscaling QC report from an investigation and writes the PDF back to the users PC",
                                      authors="author@company",
                                      version="1.0")

# Use the variable pwr_description to define the UI in the Prizm Workflow Runner and let the Petrel user select the input data.
# This creates a Python dictionary 'parameters' with the GUID and/or values of the user's input data.

pwr_description.add_object_ref_parameter(name="investigation_id", label="Investigation", description="The investigation containing the data on which to report", object_type=DomainObjectsEnum.Investigation)
pwr_description.add_string_parameter(name="suffix", label="Suffix", description="The suffix to be applied to the report filename", default_value="")
pwr_description.add_folder_parameter(name="destination_path", label="Destination folder", description="The folder into which the generate report will be uploaded")
pwr_description.add_boolean_parameter(name="can_overwrite", label="Overwrite", description="The generated report will overwrite if necessary", default_value=False)
pwr_description.add_boolean_parameter(name="open_on_upload", label="Open report", description="The generated report will be opened on completion", default_value=True)

# End: PWR Description
<cegalprizm.pycoderunner.workflow_description.WorkflowDescription at 0x21ea809e2f0>
Connect to Petrel and retrieve the user input
if 'parameters' not in locals() and 'parameters' not in globals():
    parameters = pwr_description.get_default_parameters()

# Assign the user selected investigation to a variable
investigation_id = parameters['investigation_id']
# Verify that the an investigation has been selected
if investigation_id is None or len(investigation_id) == 0:
    raise ValueError(f"{pwr_description.get_label('investigation_id')}: No investigation has been selected")

# Assign the user defined folder path to a variable
destination_path = parameters['destination_path']
# Verify that the path has been defined
if destination_path is None or len(destination_path) == 0:
    raise ValueError(f"{pwr_description.get_label('destination_path')}: No folder has been selected")

from cegalprizm.investigator import InvestigatorConnection

# Connect to Petrel
inv_conn = InvestigatorConnection(use_licensed_features=True)

# Load the user selected investigation to a variable
inv = inv_conn.load_investigation(investigation_id=investigation_id)

# Ensure that the user selected investigation has the Z spatial dimension
z_dimension_name = next((dimension.name for dimension in inv.continuous_dimension_property_names if dimension.property_name == 'Spatial/ElevationDepth'), None)
if not z_dimension_name:
  raise ValueError("Selected Investigation must contain a Z spatial dimension")

# Ensure that the user selected investigation has the Facies discrete dimension
facies_dimension_name = next((dimension.name for dimension in inv.discrete_dimension_property_names if dimension.property_name == 'Facies/Facies'), None)
if not facies_dimension_name:
  facies_dimension_name = next((dimension.name for dimension in inv.discrete_dimension_property_names if dimension.property_name.startswith('Facies')), None)
if not facies_dimension_name:
  raise ValueError("Selected Investigation must contain a Facies discrete dimension")

# Ensure that the user selected investigation has the Zone discrete dimension
zone_dimension_name = next((dimension.name for dimension in inv.discrete_dimension_property_names if 'zone' in dimension.property_name.lower()), None)
if not zone_dimension_name:
  zone_dimension_name = next((dimension.name for dimension in inv.discrete_dimension_property_names if dimension.property_name.startswith('Zone')), None)
if not zone_dimension_name:
  raise ValueError("Selected Investigation must contain a Zone discrete dimension")

# Ensure that the user selected investigation contains a wellog dataset with at least one well
wells = [t for t in inv.dataset_geometries if t[1] == 'regular1d']
if len(wells) == 0:
   raise ValueError("Selected Investigation must contain welllog datasets.\nPlease check the data loading report for the investigation.")

# Ensure that the user selected investigation contains only one grid dataset
grids = [t for t in inv.dataset_geometries if t[1] == 'sparse3d']
if len(grids) != 1:
   raise ValueError("Selected Investigation must a single grid dataset.\nPlease check the data loading report for the investigation.")
Generate Report
We start by accessing the NPD url pointing to the excel table which contains the welltop information and assign that to a dataframe. Then we format the dataframe by drop some unnecessary columns, renaming some other columns and dropping the information regarding Formation.

import os
import sys

# Getting the current working directory and storing it in the variable cwd
cwd = os.getcwd()

# Appending the "./report_notebooks" directory to the system path for module import
sys.path.append(os.path.join(cwd, "./report_notebooks"))

# Importing the generate_report_from_template function from the ReportGenerator module
from ReportGenerator import generate_report_from_template

# Creating the path to the template notebook using the current working directory
template_notebook_path = os.path.join(cwd, "./ModelQcReportTemplate.ipynb")
# Constructing a suffix for the output file name based on the user defined 'suffix' parameter, if it exists and is non-empty
suffix = ('-' + parameters['suffix']) if len(str(parameters['suffix'])) > 0 else ''
# Formatting the output document's filename with the optional suffix
output_document_filename = f"ModelQcReport{suffix}.pdf"

# Calling the generate_report_from_template function with various parameters to generate a report

generate_report_from_template(template_notebook_path=template_notebook_path,
                              output_document_filename=output_document_filename,
                              working_path=working_path,
                              investigation_id=parameters['investigation_id'],
                              upload_to_client=True,
                              destination_path=destination_path,
                              can_overwrite=parameters['can_overwrite'], # Overwrite existing file with the same name based on user input
                              open_on_upload=parameters['open_on_upload'] # Open the file after completion based on the user input
                              )

Petrel_uLw0GiooU0.gif

Download Cegal Prizm workflow

====
Petrel Connection - Functions and properties you can use once connected to Petrel
This section offers an overview of the different functions and properties available for connecting to Petrel. To start with, we assign the PetrelConnection to the Python variable ‘petrel’ and can now use the properties of ‘petrel’ to return a Python dictionary of domain objects. A full list of available properties can be found in the Python API of the class PetrelConnection.

from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection()
The following parameters can be passed in the PetrelConnection():

petrel_ctx – A context or handle to a Cegal Hub Petrel Connector (check the Hub documentation for more information about the Cegal Hub Petrel Connector)

allow_experimental – Enable experimental methods to be called. Defaults to False. To check which domain objects have available experimental methods please consult the API documentation

enable_history – Petrel data object history is updated when changed from Python Tool Pro. Defaults to True.

allow_deletion - New in Python Tool Pro 2.8, enables deletion of objects. Defaults to False.

To verify if a Petrel project is active on the server you can use the .a_project_is_active() function:

ptp.a_project_is_active()
True
We can verify the connection to the server using the .ping() function which returns an int (1-connection is working, 0-connection is not working):

ptp.ping()
1
The .get_current_project_name() function returns the name of the Petrel project of the established connection:

ptp.get_current_project_name()
'Gullfaks_dataset2.pet'
The .get_petrel_project_units() function returns the Petrel project units of the established connection:

ptp.get_petrel_project_units()
{'XY unit': 'm',
 'Z unit': 'm',
 'Area unit': 'm2',
 'Volume unit': 'm3',
 'Seismic time': 'ms',
 'Seismic velocity': 'm/s'}
You can retrieve Petrel objects using the GUID of the object and the .get_petrelobjects_by_guids() function:

ptp.get_petrelobjects_by_guids(['dbae9e2e-3eea-4f7f-a357-b2d8141eaf3e'])
[Well(petrel_name="C3")]
You can retrieve Petrel objects from Python Tool Pro using the various properties of the class PetrelConnection. All domain objects will be returned as a Python dictionary using the Petrel path as keys. If multiple objects have the same path, a list of them is returned. The image bellow summarizes the petrel objects supported by Python Tool Pro alongside the python property used to retrieve the data objects. All these domain objects will be returned as a Python dictionary using the Petrel path as keys. If multiple objects have the same path, a list of them is returned.

The .get_current_project_path() function has been introduced in Python Tool Pro 2.7 and returns the Petrel project path on disk .

ptp.get_current_project_path()
'D:\\petrel projects\\28\\ptp28.pet'
With the release of Python Tool Pro 2.8, a new property, default_seismic_directory, has been added to PetrelConnection. This allows retrieving the default seismic file directory defined in the Petrel system settings (System Settings → Seismic settings).

image.png
default_seismic = ptp.default_seismic_directory
default_seismic
'D:\\Petrel\\'
This path can be used when cloning a seismic cube. The clone() method for SeismicCube objects has been extended with a new realize_path argument, allowing users to specify the filesystem location where the cloned cube will be realized. Previously, cloned seismic cubes were always realized inside the Petrel project data folder.

seisimc_cube = ptp.seismic_cubes['Input/Seismic/Asterix Seismic/Fault_Demo_Input']

clone = seismic_cube.clone(
    "MyClone",
    realize_path=default_seismic"
)
Object deletion is now supported directly within Python Tool Pro 2.8. The new ``delete()`` functionality enables users to remove Petrel objects programmatically, either individually or in bulk.

Two deletion options are available:

On the object itself - call obj.delete() to remove a single object.

On the PetrelConnection - use petrel.delete([obj1, obj2, …]) to remove multiple objects at once.

Deletion is safeguarded by the following requirements:

allow_deletion=True must be set on the PetrelConnection

The object’s readonly flag must be set to False

This functionality is available for most supported domain objects.

# set allow deletion flag to true
ptp = PetrelConnection(allow_deletion=True)

# wells to be deleted
well1 = ptp.wells['Input/Wells/wellTops/35/9-7']
well2 = ptp.wells['Input/Wells/wellTops/35/9-8']

# set readonly status to false
well1.readonly = False
well2.readonly = False

# delete wells
ptp.delete([well1,well2])

Retrieving data objects
Python Tool Pro allows Petrel objects to be accessed from an external Python IDE and utilized in a wide range of Python functions. The image below summarizes the petrel objects supported by Python Tool Pro alongside the python property used to retrieve the data objects. All these domain objects will be returned as a Python dictionary using the Petrel path as keys. If multiple objects have the same path, a list of them is returned.

Python is a versatile language and often multiple ways are possible to achieve what you want. To work with a Petrel domain object, it needs to be assigned to a Python variable. This can be done by using the path of the Petrel object in the matching property of the PetrelConnection ‘petrel’. E.g. to retrieve a specific well, use the property ‘petrel.wells[‘Petrel path]’.

However, instead of explicitly using the Petrel path to assign a Python variable, it is recommended to iterate over the returned dictionary. When iterated over, the objects are returned, not their paths (unlike a standard Python dictionary which returns the keys).

Using list comprehensions you can create a list of data objects that you can then assign to your Python variable.

Let’s look at an example on how to retrieve all the wells from our Petrel project by using the .wells property.

from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection()

all_wells = petrel.wells
print(all_wells)
{'Input/Wells/Injectors/C2': Well(petrel_name="C2"), 'Input/Wells/Producers/B9': Well(petrel_name="B9"), 'Input/Wells/Wells with Sw-Por/34-5': Well(petrel_name="34-5"), 'Input/Wells/Injectors/C4': Well(petrel_name="C4"), 'Input/Wells/Other wells/C1': Well(petrel_name="C1"), 'Input/Wells/Producers/A15': Well(petrel_name="A15"), 'Input/Wells/Other wells/B1': Well(petrel_name="B1"), 'Input/Wells/34/10 wells/34/10-A 10': Well(petrel_name="34/10-A 10"), 'Input/Wells/Injectors/C5': Well(petrel_name="C5"), 'Input/Wells/Injectors/C6': Well(petrel_name="C6"), 'Input/Wells/Producers/A10': Well(petrel_name="A10"), 'Input/Wells/Producers/A16': Well(petrel_name="A16"), 'Input/Wells/Other wells/C7': Well(petrel_name="C7"), 'Input/Wells/Wells with Sw-Por/34-2': Well(petrel_name="34-2"), 'Input/Wells/34/10 wells/34/10-A 11': Well(petrel_name="34/10-A 11"), 'Input/Wells/34/10 wells/34/10-A 12': Well(petrel_name="34/10-A 12"), 'Input/Wells/Wells with Sw-Por/G12': Well(petrel_name="G12"), 'Input/Wells/Injectors/C3': Well(petrel_name="C3"), 'Input/Wells/Producers/B8': Well(petrel_name="B8"), 'Input/Wells/Other wells/B2': Well(petrel_name="B2"), 'Input/Wells/Other wells/B4': Well(petrel_name="B4")}
The cell above returned all the wells from the project in a dictionary where the keys represents the path of the well within the Petrel input tree (i.e Input/Wells/Injectors/C3 ) and the value represents the name of the well ( Well(petrel_name=”C3”) ). We can also save all the well paths to a list and then use slicing to get the name of a particular well:

# Get all the well paths from the dictionary keys
all_wells_paths=ptp.wells.keys()
# Save them in a list
paths = list(all_wells_paths)
#Slice the list to get the first well
well = ptp.wells[paths[0]]
print(well)
Well(petrel_name="C3")
We can also iterate through all the wells within the Petrel project by using a for loop:

for obj in ptp.wells:
    print(obj)
Well(petrel_name="C3")
Well(petrel_name="C6")
Well(petrel_name="B8")
Well(petrel_name="C1")
Well(petrel_name="B1")
Well(petrel_name="A15")
Well(petrel_name="C2")
Well(petrel_name="34/10-A 12")
Well(petrel_name="B9")
Well(petrel_name="34-2")
Well(petrel_name="34/10-A 10")
Well(petrel_name="B2")
Well(petrel_name="B4")
Well(petrel_name="C5")
Well(petrel_name="A10")
Well(petrel_name="34/10-A 11")
Well(petrel_name="G12")
Well(petrel_name="C7")
Well(petrel_name="34-5")
Well(petrel_name="A16")
Well(petrel_name="C4")
Note: When iterated over, the objects are returned, not their paths (unlike a standard Python dictionary which returns the keys).

Get objects by name
In Python Tool Pro 2.8, A new convenience method, get_by_name(), has been added to all major domain object in Python Tool Pro 2.8. This method allows users to retrieve Petrel objects directly by their Petrel name without needing full paths.

By default, name matching is case-insensitive (case_sensitive=False).

The method returns:

a single object if exactly one match is found

a list of objects if multiple objects share the same name

None if no matching object is found

well = ptp.wells.get_by_name("A16")
surf = ptp.surfaces.get_by_name("Base Cretaceous")
wavelet = ptp.wavelets.get_by_name("Extended White 1")

print (well, surf, wavelet)
Well(petrel_name="A16") Surface(petrel_name="Base Cretaceous") Wavelet(petrel_name="Extended White 1")
Functions and properties
Properties indicate an intrinsic property of the object which is not going to change.

Function calls are requests for data or instructions to do something, and most often contain parameters which specify what kind of data. Functions are called with a parenthesis after the function name, which can receive one or more parameters.

The image below illustrates some of the most common functions and properties supported by most of the Petrel objects. However, each Petrel object also has dedicated functions and properties. To get a detailed description of all of them for each Petrel object type, please navigate to the Python API documentation chapter.

Properties Examples

The .droid property returns the object id or guid which represents the Petrel filename in the project directory.

.droid2.png
well.droid
'dbae9e2e-3eea-4f7f-a357-b2d8141eaf3e'
To access the path of an object which represents the key of the dictionary used to retrieve the data, we can use the .path property:

well.path
'Input/Wells/Injectors/C3'
Similarly, we can access the name of the object which represents the value of the dictionary used to retrieve the data. Note that by using the .petrel_name property we are returning just the name of the object without the prefix petrel_name= as seen in previous examples.

well.petrel_name
'C3'
Now we can combine the .wells property with the .petrel_name and .path properties to iterate over the wells in our project and retrieve their name and path.

for obj in ptp.wells:
    print(obj.petrel_name)
    print(obj.path)
C3
Input/Wells/Injectors/C3
C6
Input/Wells/Injectors/C6
B8
Input/Wells/Producers/B8
C1
Input/Wells/Other wells/C1
B1
Input/Wells/Other wells/B1
A15
Input/Wells/Producers/A15
C2
Input/Wells/Injectors/C2
34/10-A 12
Input/Wells/34/10 wells/34/10-A 12
B9
Input/Wells/Producers/B9
34-2
Input/Wells/Wells with Sw-Por/34-2
34/10-A 10
Input/Wells/34/10 wells/34/10-A 10
B2
Input/Wells/Other wells/B2
B4
Input/Wells/Other wells/B4
C5
Input/Wells/Injectors/C5
A10
Input/Wells/Producers/A10
34/10-A 11
Input/Wells/34/10 wells/34/10-A 11
G12
Input/Wells/Wells with Sw-Por/G12
C7
Input/Wells/Other wells/C7
34-5
Input/Wells/Wells with Sw-Por/34-5
A16
Input/Wells/Producers/A16
C4
Input/Wells/Injectors/C4
The .readonly property retrieves a boolean value that indicates if the object is in a read-only format or not.

well.readonly
True
We can modify the readonly status of any object by assigning it a True or False value. The default value is True.

well.readonly = False
well.readonly
False
Let’s explore the template and unit symbol using some of the grids properties in our project. Similarly to the .wells property the .grid_properties will return a dictionary of the path and the name of each property within our 3D model.

ptp.grid_properties
Properties({'Models/Gullfaks2004/Gullfaks Final (DC)/Properties/NG': GridProperty(petrel_name="NG"), 'Models/Final model/Training/Properties/Conditioned porosity': GridProperty(petrel_name="Conditioned porosity"), 'Models/Final model/Training/Properties/Porosity': GridProperty(petrel_name="Porosity"), 'Models/Gullfaks2004/Gullfaks Final (DC)/Properties/Porosity': GridProperty(petrel_name="Porosity")})
Let’s go ahead and retrieve the Porosity property of our model:

# Get all the properties paths from the dictionary keys
all_grids_properties_paths=ptp.grid_properties.keys()
# Save them in a list
grid_prop_paths = list(all_grids_properties_paths)
#Slice the list to get the first well
grid_prop = ptp.grid_properties[grid_prop_paths[2]]
print(grid_prop)
GridProperty(petrel_name="Porosity")
The .template property returns the Petrel template for the object as a string. If no template is available,it will return an empty string. In Petrel, for the grid property example the template can be found by accessing the setting of a property. Similarly, using the .unit_symbol property we can access the unit for any object associated with a certain template. In Petrel you can access this data by propping up the global settings for the selected property template.

templateUnitSymbol2.png
grid_prop.template
'Porosity'
grid_prop.unit_symbol
'm3/m3'
Functions examples

In the code block below we call the function retrieve_stats(), notice that the parenthesis are empty, but in reality we input a reference to the object the function is called on, although we do not need to state it. The statistics are a snapshot of the information in the Statistics page of the Settings panel of the object in the Petrel tree. Both the dictionary key and value are strings, and may contain punctuation, English phrases or just filler information. Any changes to the returned dictionary will not be saved or affect anything.

retrieveStats2.png
well.retrieve_stats()
{'X Min': '456244.15',
 'X Max': '456651.29',
 'X Delta': '407.139999999956',
 'Y Min': '6788724.75',
 'Y Max': '6788724.75',
 'Y Delta': '0',
 'Elevation depth [m] Min': '-2239.19',
 'Elevation depth [m] Max': '-1852.23',
 'Elevation depth [m] Delta': '386.96',
 'Lat Min': '61.2289616388889',
 'Lat Max': '61.229007',
 'Lat Delta': '4.53611111126406E-05',
 'Long Min': '2.18514680555556',
 'Long Max': '2.19272786111111',
 'Long Delta': '0.00758105555555533',
 'Wellhead X-coord.': '456244.15',
 'Wellhead Y-coord.': '6788724.75',
 'Well datum': 'KB[0.00]',
 'Number of points': '582',
 'Length of deviation': '581.29',
 'Md at first point': '1852.23',
 'TVD at first point': '1852.23',
 'TVDSS at first point': '1852.23',
 'Md at last point': '2433.52',
 'TVD at last point': '2239.19',
 'TVDSS at last point': '2239.19',
 'Bottom hole X': '456651.29',
 'Bottom hole Y': '6788724.75',
 'Number of logs': '',
 '   In this folder': '3',
 '   Includes sub folders': '25',
 'Active time depth log': 'One-way time 1'}
To get and overview of the changes made to a Petrel domain object over time we can use the .retrieve_history() function to return the Petrel history of the object as a Pandas dataframe.

well.retrieve_history()
Date	User	Action	Description
0	Jan 01 0001 01:00		Import	U:\Doc\PETREL Course\Data for course\Updated d...
1	Apr 24 2002 16:05	marit	Import C:\Documents and Settings\marit\Desktop...	Well logs (ASCII)
2	Apr 24 2002 16:06	marit	Import C:\Documents and Settings\marit\Desktop...	Well logs (ASCII)
3	Apr 24 2002 16:06	marit	Import C:\Documents and Settings\marit\Desktop...	Well logs (ASCII)
4	Apr 24 2002 16:07	marit	Import C:\Documents and Settings\marit\Desktop...	Well logs (ASCII)
5	Apr 24 2002 16:08	marit	Import C:\Documents and Settings\marit\Desktop...	Well logs (ASCII)
6	Apr 24 2002 16:09	marit	Import C:\Documents and Settings\marit\Desktop...	Well logs (ASCII)
7	Apr 24 2002 16:15	marit	Import C:\Documents and Settings\marit\Desktop...	Well logs (ASCII)
8	Apr 24 2002 16:16	marit	Import C:\Documents and Settings\marit\Desktop...	Well logs (ASCII)
9	Nov 04 2002 11:35	marit	Import C:\Demo\Dip data for Gullfaks2002\C3.txt	Well logs (ASCII)
10	Dec 30 2015 11:32	schulte9	Upgraded flow correlations	2
11	Jan 09 2017 17:51	maximeg	Survey activated	Explicit survey 1
We can also clone an object and create a copy of it within Petrel. The clone will be placed in the same collection as the source object. This function is useful for creating back-ups of the data we are working with as well as writing new results back to Petrel.

grid_prop.clone("new_prop", copy_values= True)
GridProperty(petrel_name="new_prop")
By running the cell above we’ve successfully created a new property called new_prop in our model. It represents a copy of the existing porosity property, having the same template and values. We could also create a copy without copying the values by setting the copy_values=False . This is particularly useful when writing results back to Petrel. We can create a copy of a property that has the correct template but assign values that were modeled by us, in Python.

clone-2.png
Let’s explore how we can store the values of an object in a DataFrame. For this we will be using the well logs associated to the well we have previously used in several examples. We’ll start by importing the WellLog package. Then we can assign all the logs associated to our well to a new variable. Finally, we can print a string of the well logs in the selected well.

from cegalprizm.pythontool.welllog import WellLog
wellC3_logs=well.logs
print(', '.join([log.petrel_name for log in logs]))
Velocity (Vlin), NtG, Interval velocity (AllCheckShots.txt), DC Time log, DEPTH, DC Velocity log, FaciesCont, Env_AI, Gamma, NetGross, Perm, Porosity, One-way time 1, Facies, Reservoir, Boolean log linked to filter 'Porosity vs. Permeability 1', Zone log linked to 'Reservoir Demo', Facies_Por_LOW, Perforation, Facies_Por, Fluvial facies
Using the .logs_dataframe() function we can create a DataFrame that contains all the logs we assigned to the wellC3_logs variable.

logs_df= well.logs_dataframe(wellC3_logs)
logs_df
Velocity (Vlin)	NtG	Interval velocity (AllCheckShots.txt)	DC Time log	DEPTH	DC Velocity log	FaciesCont	Env_AI	Gamma	NetGross	...	Reservoir	Boolean log linked to filter 'Porosity vs. Permeability 1'	Zone log linked to 'Reservoir Demo'	Facies_Por_LOW	Perforation	Facies_Por	Fluvial facies	MD	TWT	TVD
0	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	...	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	-84.2692	-0.284470	-0.296789
1	NaN	NaN	2086.664209	NaN	NaN	NaN	NaN	NaN	NaN	NaN	...	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	-83.7692	0.173994	0.181529
2	NaN	NaN	2086.795819	NaN	NaN	NaN	NaN	NaN	NaN	NaN	...	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	-83.2692	0.632458	0.659848
3	NaN	NaN	2086.927420	NaN	NaN	NaN	NaN	NaN	NaN	NaN	...	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	-82.7692	1.090922	1.138166
4	NaN	NaN	2087.059010	NaN	NaN	NaN	NaN	NaN	NaN	NaN	...	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	-82.2692	1.549386	1.616485
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
5033	2111.888184	1.0	NaN	2086.064038	2432.230713	2440.941963	NaN	2990.900504	77.704376	0.0	...	False	True	UNDEF	True	UNDEF	True	Background floodplain	2432.2308	2085.230989	2238.641270
5034	NaN	NaN	NaN	2086.231610	2432.730713	2440.948524	NaN	3035.447172	79.911293	0.0	...	True	False	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	2432.7308	2085.389164	2238.852274
5035	NaN	NaN	NaN	2086.399179	2433.230713	2440.955127	NaN	3080.176681	NaN	0.0	...	True	False	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	2433.2308	2085.547410	2239.063277
5036	NaN	NaN	NaN	NaN	2433.730713	NaN	NaN	3125.087919	NaN	0.0	...	UNDEF	False	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	2433.7308	2085.705656	2239.274281
5037	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	...	UNDEF	False	UNDEF	UNDEF	UNDEF	UNDEF	UNDEF	2434.2308	2085.863902	2239.485285
5038 rows × 24 columns

======
Well data - Well headers, surveys and logs
This section offers an overview of the different methods and attributes available for the Petrel well object subcategories.

from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection()
Wells
Check out the API documentation to view a detailed description of all the functions and properties available for working with well headers.

Let’s look at an example on how to retrieve all the wells from our Petrel project by using the .wells property:

all_wells = ptp.wells
print(all_wells)
{'Input/Wells/Pseudowells/Pseudowell104': Well(petrel_name="Pseudowell104"), 'Input/Wells/Volve VS log prediction/15/9-F-12': Well(petrel_name="15/9-F-12"), 'Input/Wells/wellTops/25/10-9': Well(petrel_name="25/10-9"), 'Input/Wells/Pseudowells/Pseudowell0': Well(petrel_name="Pseudowell0"), 'Input/Wells/Pseudowells/Pseudowell51': Well(petrel_name="Pseudowell51"), 'Input/Wells/Pseudowells/Pseudowell27': Well(petrel_name="Pseudowell27"), 'Input/Wells/wellTops/34/3-3 A': Well(petrel_name="34/3-3 A"), 'Input/Wells/Pseudowells/Pseudowell78': Well(petrel_name="Pseudowell78"), 'Input/Wells/Pseudowells/Pseudowell76': Well(petrel_name="Pseudowell76"), 'Input/Wells/Gullfaks wells/Injectors/C4': Well(petrel_name="C4"), 'Input/Wells/Pseudowells/Pseudowell63': Well(petrel_name="Pseudowell63"), 'Input/Wells/Volve VS log prediction/15/9-F-15 B': Well(petrel_name="15/9-F-15 B"), 'Input/Wells/Pseudowells/Pseudowell103': Well(petrel_name="Pseudowell103"), 'Input/Wells/Pseudowells/Pseudowell23': Well(petrel_name="Pseudowell23"), 'Input/Wells/Volve VS log prediction/15/9-F-1': Well(petrel_name="15/9-F-1"), 'Input/Wells/Pseudowells/Pseudowell5': Well(petrel_name="Pseudowell5"), 'Input/Wells/Pseudowells/Pseudowell69': Well(petrel_name="Pseudowell69"), 'Input/Wells/wellTops/25/11-24': Well(petrel_name="25/11-24"), 'Input/Wells/Volve VS log prediction/15/9-F-15': Well(petrel_name="15/9-F-15"), 'Input/Wells/Pseudowells/Pseudowell3': Well(petrel_name="Pseudowell3"), 'Input/Wells/wellTops/34/3-2 S': Well(petrel_name="34/3-2 S"), 'Input/Wells/Pseudowells/Pseudowell39': Well(petrel_name="Pseudowell39"), 'Input/Wells/Pseudowells/Pseudowell74': Well(petrel_name="Pseudowell74"), 'Input/Wells/Pseudowells/Pseudowell83': Well(petrel_name="Pseudowell83"), 'Input/Wells/wellTops/25/10-10': Well(petrel_name="25/10-10"), 'Input/Wells/Pseudowells/Pseudowell7': Well(petrel_name="Pseudowell7"), 'Input/Wells/Pseudowells/Pseudowell72': Well(petrel_name="Pseudowell72"), 'Input/Wells/Pseudowells/Pseudowell14': Well(petrel_name="Pseudowell14"), 'Input/Wells/Pseudowells/Pseudowell55': Well(petrel_name="Pseudowell55"), 'Input/Wells/Pseudowells/Pseudowell114': Well(petrel_name="Pseudowell114"), 'Input/Wells/Pseudowells/Pseudowell15': Well(petrel_name="Pseudowell15"), 'Input/Wells/Pseudowells/Pseudowell29': Well(petrel_name="Pseudowell29"), 'Input/Wells/Pseudowells/Pseudowell41': Well(petrel_name="Pseudowell41"), 'Input/Wells/Volve VS log prediction/15/9-F-11 B': Well(petrel_name="15/9-F-11 B"), 'Input/Wells/Pseudowells/Pseudowell118': Well(petrel_name="Pseudowell118"), 'Input/Wells/wellTops/34/10-16 R': Well(petrel_name="34/10-16 R"), 'Input/Wells/Pseudowells/Pseudowell107': Well(petrel_name="Pseudowell107"), 'Input/Wells/wellTops/29/3-1': Well(petrel_name="29/3-1"), 'Input/Wells/Pseudowells/Pseudowell75': Well(petrel_name="Pseudowell75"), 'Input/Wells/Pseudowells/Pseudowell89': Well(petrel_name="Pseudowell89"), 'Input/Wells/Pseudowells/Pseudowell86': Well(petrel_name="Pseudowell86"), 'Input/Wells/Pseudowells/Pseudowell100': Well(petrel_name="Pseudowell100"), 'Input/Wells/Pseudowells/Pseudowell99': Well(petrel_name="Pseudowell99"), 'Input/Wells/Pseudowells/Pseudowell65': Well(petrel_name="Pseudowell65"), 'Input/Wells/Pseudowells/Pseudowell117': Well(petrel_name="Pseudowell117"), 'Input/Wells/Pseudowells/Pseudowell90': Well(petrel_name="Pseudowell90"), 'Input/Wells/Pseudowells/Pseudowell105': Well(petrel_name="Pseudowell105"), 'Input/Wells/Volve VS log prediction/15/9-F-15 C': Well(petrel_name="15/9-F-15 C"), 'Input/Wells/Pseudowells/Pseudowell67': Well(petrel_name="Pseudowell67"), 'Input/Wells/Pseudowells/Pseudowell26': Well(petrel_name="Pseudowell26"), 'Input/Wells/Volve VS log prediction/15/9-19 SR': Well(petrel_name="15/9-19 SR"), 'Input/Wells/Pseudowells/Pseudowell109': Well(petrel_name="Pseudowell109"), 'Input/Wells/Gullfaks wells/Producers/A15': Well(petrel_name="A15"), 'Input/Wells/Pseudowells/Pseudowell18': Well(petrel_name="Pseudowell18"), 'Input/Wells/Pseudowells/Pseudowell12': Well(petrel_name="Pseudowell12"), 'Input/Wells/Volve VS log prediction/15/9-F-11 A': Well(petrel_name="15/9-F-11 A"), 'Input/Wells/Pseudowells/Pseudowell87': Well(petrel_name="Pseudowell87"), 'Input/Wells/Pseudowells/Pseudowell73': Well(petrel_name="Pseudowell73"), 'Input/Wells/Pseudowells/Pseudowell62': Well(petrel_name="Pseudowell62"), 'Input/Wells/Pseudowells/empty': Well(petrel_name="empty"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-11 A': Well(petrel_name="Copy of 15/9-F-11 A"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-4': Well(petrel_name="Copy of 15/9-F-4"), 'Input/Wells/Pseudowells/Pseudowell53': Well(petrel_name="Pseudowell53"), 'Input/Wells/Gullfaks wells/Producers/A16': Well(petrel_name="A16"), 'Input/Wells/Pseudowells/Pseudowell85': Well(petrel_name="Pseudowell85"), 'Input/Wells/Pseudowells/Pseudowell116': Well(petrel_name="Pseudowell116"), 'Input/Wells/Pseudowells/Pseudowell9': Well(petrel_name="Pseudowell9"), 'Input/Wells/Pseudowells/Pseudowell106': Well(petrel_name="Pseudowell106"), 'Input/Wells/Pseudowells/Pseudowell2': Well(petrel_name="Pseudowell2"), 'Input/Wells/Pseudowells/Pseudowell21': Well(petrel_name="Pseudowell21"), 'Input/Wells/Pseudowells/Pseudowell1': Well(petrel_name="Pseudowell1"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 SR': Well(petrel_name="Copy of 15/9-19 SR"), 'Input/Wells/Volve VS log prediction/15/9-F-1 A': Well(petrel_name="15/9-F-1 A"), 'Input/Wells/Pseudowells/Pseudowell94': Well(petrel_name="Pseudowell94"), 'Input/Wells/Pseudowells/Pseudowell93': Well(petrel_name="Pseudowell93"), 'Input/Wells/Pseudowells/Pseudowell108': Well(petrel_name="Pseudowell108"), 'Input/Wells/Pseudowells/Pseudowell68': Well(petrel_name="Pseudowell68"), 'Input/Wells/Pseudowells/Pseudowell92': Well(petrel_name="Pseudowell92"), 'Input/Wells/Pseudowells/Pseudowell38': Well(petrel_name="Pseudowell38"), 'Input/Wells/Pseudowells/Pseudowell102': Well(petrel_name="Pseudowell102"), 'Input/Wells/wellTops/31/2-21 S': Well(petrel_name="31/2-21 S"), 'Input/Wells/Pseudowells/Pseudowell36': Well(petrel_name="Pseudowell36"), 'Input/Wells/Pseudowells/Pseudowell33': Well(petrel_name="Pseudowell33"), 'Input/Wells/Pseudowells/Pseudowell44': Well(petrel_name="Pseudowell44"), 'Input/Wells/Pseudowells/Pseudowell34': Well(petrel_name="Pseudowell34"), 'Input/Wells/Pseudowells/Pseudowell91': Well(petrel_name="Pseudowell91"), 'Input/Wells/Pseudowells/Pseudowell112': Well(petrel_name="Pseudowell112"), 'Input/Wells/Pseudowells/Pseudowell97': Well(petrel_name="Pseudowell97"), 'Input/Wells/Pseudowells/Pseudowell28': Well(petrel_name="Pseudowell28"), 'Input/Wells/Pseudowells/Pseudowell17': Well(petrel_name="Pseudowell17"), 'Input/Wells/Pseudowells/Pseudowell88': Well(petrel_name="Pseudowell88"), 'Input/Wells/Pseudowells/Pseudowell56': Well(petrel_name="Pseudowell56"), 'Input/Wells/Pseudowells/Pseudowell47': Well(petrel_name="Pseudowell47"), 'Input/Wells/wellTops/35/6-2 S': Well(petrel_name="35/6-2 S"), 'Input/Wells/Pseudowells/Pseudowell82': Well(petrel_name="Pseudowell82"), 'Input/Wells/Volve VS log prediction/15/9-F-4': Well(petrel_name="15/9-F-4"), 'Input/Wells/Pseudowells/Pseudowell50': Well(petrel_name="Pseudowell50"), 'Input/Wells/Pseudowells/Pseudowell119': Well(petrel_name="Pseudowell119"), 'Input/Wells/Pseudowells/Pseudowell57': Well(petrel_name="Pseudowell57"), 'Input/Wells/Pseudowells/Pseudowell70': Well(petrel_name="Pseudowell70"), 'Input/Wells/Pseudowells/Pseudowell10': Well(petrel_name="Pseudowell10"), 'Input/Wells/Pseudowells/Pseudowell20': Well(petrel_name="Pseudowell20"), 'Input/Wells/Gullfaks wells/Injectors/C6': Well(petrel_name="C6"), 'Input/Wells/Gullfaks wells/Producers/B9': Well(petrel_name="B9"), 'Input/Wells/Pseudowells/Pseudowell71': Well(petrel_name="Pseudowell71"), 'Input/Wells/Gullfaks wells/Producers/B8': Well(petrel_name="B8"), 'Input/Wells/Volve VS log prediction/15/9-F-10': Well(petrel_name="15/9-F-10"), 'Input/Wells/wellTops/15/9-23': Well(petrel_name="15/9-23"), 'Input/Wells/wellTops/31/2-10': Well(petrel_name="31/2-10"), 'Input/Wells/Pseudowells/Pseudowell48': Well(petrel_name="Pseudowell48"), 'Input/Wells/Pseudowells/Pseudowell115': Well(petrel_name="Pseudowell115"), 'Input/Wells/Pseudowells/Pseudowell42': Well(petrel_name="Pseudowell42"), 'Input/Wells/wellTops/35/9-8': Well(petrel_name="35/9-8"), 'Input/Wells/Pseudowells/Pseudowell58': Well(petrel_name="Pseudowell58"), 'Input/Wells/Pseudowells/Pseudowell95': Well(petrel_name="Pseudowell95"), 'Input/Wells/wellTops/16/2-7': Well(petrel_name="16/2-7"), 'Input/Wells/Pseudowells/Pseudowell64': Well(petrel_name="Pseudowell64"), 'Input/Wells/Pseudowells/Pseudowell96': Well(petrel_name="Pseudowell96"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 A': Well(petrel_name="Copy of 15/9-19 A"), 'Input/Wells/Pseudowells/Pseudowell13': Well(petrel_name="Pseudowell13"), 'Input/Wells/Pseudowells/Pseudowell40': Well(petrel_name="Pseudowell40"), 'Input/Wells/Pseudowells/Pseudowell79': Well(petrel_name="Pseudowell79"), 'Input/Wells/Pseudowells/Pseudowell49': Well(petrel_name="Pseudowell49"), 'Input/Wells/Pseudowells/Pseudowell84': Well(petrel_name="Pseudowell84"), 'Input/Wells/Gullfaks wells/Injectors/C3': Well(petrel_name="C3"), 'Input/Wells/Gullfaks wells/Producers/A10': Well(petrel_name="A10"), 'Input/Wells/Pseudowells/Pseudowell37': Well(petrel_name="Pseudowell37"), 'Input/Wells/Pseudowells/Pseudowell59': Well(petrel_name="Pseudowell59"), 'Input/Wells/wellTops/16/7-6': Well(petrel_name="16/7-6"), 'Input/Wells/Pseudowells/Pseudowell60': Well(petrel_name="Pseudowell60"), 'Input/Wells/wellTops/17/4-1': Well(petrel_name="17/4-1"), 'Input/Wells/Pseudowells/Pseudowell4': Well(petrel_name="Pseudowell4"), 'Input/Wells/Pseudowells/Pseudowell24': Well(petrel_name="Pseudowell24"), 'Input/Wells/Pseudowells/Pseudowell6': Well(petrel_name="Pseudowell6"), 'Input/Wells/Pseudowells/Pseudowell22': Well(petrel_name="Pseudowell22"), 'Input/Wells/Pseudowells/Pseudowell101': Well(petrel_name="Pseudowell101"), 'Input/Wells/Volve VS log prediction/15/9-F-5': Well(petrel_name="15/9-F-5"), 'Input/Wells/Pseudowells/Pseudowell113': Well(petrel_name="Pseudowell113"), 'Input/Wells/Volve VS log prediction/15/9-19 A': Well(petrel_name="15/9-19 A"), 'Input/Wells/Pseudowells/Pseudowell66': Well(petrel_name="Pseudowell66"), 'Input/Wells/wellTops/25/5-3': Well(petrel_name="25/5-3"), 'Input/Wells/Pseudowells/Pseudowell80': Well(petrel_name="Pseudowell80"), 'Input/Wells/Pseudowells/Pseudowell35': Well(petrel_name="Pseudowell35"), 'Input/Wells/Gullfaks wells/Injectors/C5': Well(petrel_name="C5"), 'Input/Wells/Pseudowells/Pseudowell32': Well(petrel_name="Pseudowell32"), 'Input/Wells/wellTops/15/9-14': Well(petrel_name="15/9-14"), 'Input/Wells/Pseudowells/Pseudowell77': Well(petrel_name="Pseudowell77"), 'Input/Wells/Pseudowells/Pseudowell81': Well(petrel_name="Pseudowell81"), 'Input/Wells/Pseudowells/Pseudowell16': Well(petrel_name="Pseudowell16"), 'Input/Wells/wellTops/35/11-5': Well(petrel_name="35/11-5"), 'Input/Wells/Pseudowells/Pseudowell11': Well(petrel_name="Pseudowell11"), 'Input/Wells/Pseudowells/Pseudowell54': Well(petrel_name="Pseudowell54"), 'Input/Wells/Pseudowells/Pseudowell8': Well(petrel_name="Pseudowell8"), 'Input/Wells/Volve VS log prediction/15/9-F-1 C': Well(petrel_name="15/9-F-1 C"), 'Input/Wells/Volve VS log prediction/15/9-F-15 A': Well(petrel_name="15/9-F-15 A"), 'Input/Wells/Pseudowells/Pseudowell31': Well(petrel_name="Pseudowell31"), 'Input/Wells/Volve VS log prediction/15/9-F-14': Well(petrel_name="15/9-F-14"), 'Input/Wells/Pseudowells/Pseudowell45': Well(petrel_name="Pseudowell45"), 'Input/Wells/wellTops/34/6-1 S': Well(petrel_name="34/6-1 S"), 'Input/Wells/wellTops/35/9-7': Well(petrel_name="35/9-7"), 'Input/Wells/Volve VS log prediction/15/9-19 BT2': Well(petrel_name="15/9-19 BT2"), 'Input/Wells/Volve VS log prediction/15/9-F-1 B': Well(petrel_name="15/9-F-1 B"), 'Input/Wells/Gullfaks wells/Injectors/C2': Well(petrel_name="C2"), 'Input/Wells/Pseudowells/Pseudowell19': Well(petrel_name="Pseudowell19"), 'Input/Wells/Pseudowells/Pseudowell43': Well(petrel_name="Pseudowell43"), 'Input/Wells/Pseudowells/Pseudowell61': Well(petrel_name="Pseudowell61"), 'Input/Wells/Pseudowells/Pseudowell46': Well(petrel_name="Pseudowell46"), 'Input/Wells/Pseudowells/Pseudowell30': Well(petrel_name="Pseudowell30"), 'Input/Wells/Pseudowells/Pseudowell98': Well(petrel_name="Pseudowell98"), 'Input/Wells/Pseudowells/Pseudowell111': Well(petrel_name="Pseudowell111"), 'Input/Wells/Pseudowells/Pseudowell52': Well(petrel_name="Pseudowell52"), 'Input/Wells/Pseudowells/Pseudowell110': Well(petrel_name="Pseudowell110"), 'Input/Wells/Volve VS log prediction/15/9-F-15 D': Well(petrel_name="15/9-F-15 D"), 'Input/Wells/Pseudowells/Pseudowell25': Well(petrel_name="Pseudowell25")}
The cell above returned all the wells from the project in a dictionary where the keys represent the path of the well within the Petrel input tree (i.e Input/Wells/Injectors/C6 ) and the value represents the name of the well ( Well(petrel_name=”C6”) ). We can also save all the well paths to a list and then use slicing to get the name of a particular well:

# Get all the well paths from the dictionary keys
all_wells_paths=ptp.wells.keys()
# Save them in a list
paths = list(all_wells_paths)
#Slice the list to get the first well
well = ptp.wells[paths[2]]
print(well)
Well(petrel_name="Pseudowell67")
Similarly, we can iterate through the dictionary and return all the values:

for obj in ptp.wells:
    print(obj)
Well(petrel_name="A16")
Well(petrel_name="Pseudowell45")
Well(petrel_name="Pseudowell67")
Well(petrel_name="Pseudowell101")
Well(petrel_name="Pseudowell13")
Well(petrel_name="29/3-1")
Well(petrel_name="Pseudowell35")
Well(petrel_name="Pseudowell89")
Well(petrel_name="15/9-F-1 A")
Well(petrel_name="Pseudowell12")
Well(petrel_name="15/9-F-11 A")
Well(petrel_name="Pseudowell115")
Well(petrel_name="C2")
Well(petrel_name="Pseudowell77")
Well(petrel_name="Pseudowell42")
Well(petrel_name="Pseudowell14")
Well(petrel_name="17/4-1")
Well(petrel_name="Pseudowell53")
Well(petrel_name="15/9-F-15 C")
Well(petrel_name="Pseudowell64")
Well(petrel_name="Pseudowell50")
Well(petrel_name="Copy of 15/9-19 SR")
Well(petrel_name="15/9-14")
Well(petrel_name="empty")
Well(petrel_name="Pseudowell102")
Well(petrel_name="Pseudowell63")
Well(petrel_name="Pseudowell81")
Well(petrel_name="Pseudowell46")
Well(petrel_name="Pseudowell60")
Well(petrel_name="Pseudowell105")
Well(petrel_name="Pseudowell22")
Well(petrel_name="Pseudowell47")
Well(petrel_name="35/6-2 S")
Well(petrel_name="Pseudowell2")
Well(petrel_name="34/3-2 S")
Well(petrel_name="Pseudowell21")
Well(petrel_name="15/9-F-1 B")
Well(petrel_name="C5")
Well(petrel_name="Pseudowell58")
Well(petrel_name="Pseudowell92")
Well(petrel_name="Pseudowell16")
Well(petrel_name="Pseudowell61")
Well(petrel_name="Pseudowell10")
Well(petrel_name="Pseudowell98")
Well(petrel_name="Pseudowell55")
Well(petrel_name="Pseudowell111")
Well(petrel_name="Copy of 15/9-19 A")
Well(petrel_name="Pseudowell31")
Well(petrel_name="25/10-9")
Well(petrel_name="Pseudowell96")
Well(petrel_name="Pseudowell69")
Well(petrel_name="Pseudowell0")
Well(petrel_name="31/2-10")
Well(petrel_name="Pseudowell116")
Well(petrel_name="Pseudowell9")
Well(petrel_name="Pseudowell86")
Well(petrel_name="Pseudowell39")
Well(petrel_name="Pseudowell99")
Well(petrel_name="Pseudowell78")
Well(petrel_name="Pseudowell108")
Well(petrel_name="25/10-10")
Well(petrel_name="Pseudowell68")
Well(petrel_name="15/9-F-15 B")
Well(petrel_name="Pseudowell90")
Well(petrel_name="31/2-21 S")
Well(petrel_name="Pseudowell103")
Well(petrel_name="Pseudowell23")
Well(petrel_name="Pseudowell20")
Well(petrel_name="Pseudowell33")
Well(petrel_name="C6")
Well(petrel_name="Pseudowell114")
Well(petrel_name="Pseudowell44")
Well(petrel_name="Pseudowell29")
Well(petrel_name="Pseudowell25")
Well(petrel_name="B8")
Well(petrel_name="Pseudowell82")
Well(petrel_name="34/10-16 R")
Well(petrel_name="Pseudowell80")
Well(petrel_name="Pseudowell3")
Well(petrel_name="Pseudowell100")
Well(petrel_name="Pseudowell87")
Well(petrel_name="Pseudowell74")
Well(petrel_name="Pseudowell65")
Well(petrel_name="Pseudowell117")
Well(petrel_name="Pseudowell95")
Well(petrel_name="35/11-5")
Well(petrel_name="Pseudowell11")
Well(petrel_name="Pseudowell5")
Well(petrel_name="B9")
Well(petrel_name="15/9-F-15 A")
Well(petrel_name="Pseudowell85")
Well(petrel_name="25/11-24")
Well(petrel_name="Pseudowell113")
Well(petrel_name="Pseudowell40")
Well(petrel_name="Pseudowell118")
Well(petrel_name="15/9-19 BT2")
Well(petrel_name="Pseudowell49")
Well(petrel_name="A10")
Well(petrel_name="C3")
Well(petrel_name="Pseudowell59")
Well(petrel_name="Pseudowell52")
Well(petrel_name="16/2-7")
Well(petrel_name="Pseudowell110")
Well(petrel_name="Pseudowell6")
Well(petrel_name="Pseudowell41")
Well(petrel_name="Pseudowell26")
Well(petrel_name="Pseudowell106")
Well(petrel_name="Pseudowell107")
Well(petrel_name="25/5-3")
Well(petrel_name="15/9-19 A")
Well(petrel_name="35/9-7")
Well(petrel_name="Pseudowell109")
Well(petrel_name="Pseudowell79")
Well(petrel_name="34/3-3 A")
Well(petrel_name="Pseudowell62")
Well(petrel_name="Pseudowell32")
Well(petrel_name="Pseudowell43")
Well(petrel_name="Pseudowell84")
Well(petrel_name="Pseudowell57")
Well(petrel_name="Pseudowell70")
Well(petrel_name="16/7-6")
Well(petrel_name="Pseudowell71")
Well(petrel_name="Pseudowell97")
Well(petrel_name="Pseudowell8")
Well(petrel_name="15/9-F-10")
Well(petrel_name="Pseudowell56")
Well(petrel_name="15/9-23")
Well(petrel_name="Pseudowell66")
Well(petrel_name="A15")
Well(petrel_name="34/6-1 S")
Well(petrel_name="Pseudowell1")
Well(petrel_name="Pseudowell18")
Well(petrel_name="Pseudowell48")
Well(petrel_name="35/9-8")
Well(petrel_name="Pseudowell119")
Well(petrel_name="Pseudowell19")
Well(petrel_name="Pseudowell83")
Well(petrel_name="Pseudowell76")
Well(petrel_name="Pseudowell72")
Well(petrel_name="Pseudowell30")
Well(petrel_name="Pseudowell54")
Well(petrel_name="Pseudowell91")
Well(petrel_name="Pseudowell28")
Well(petrel_name="15/9-F-14")
Well(petrel_name="15/9-F-4")
Well(petrel_name="Pseudowell75")
Well(petrel_name="Pseudowell94")
Well(petrel_name="Pseudowell93")
Well(petrel_name="Pseudowell38")
Well(petrel_name="C4")
Well(petrel_name="Pseudowell36")
Well(petrel_name="Pseudowell4")
Well(petrel_name="15/9-F-1")
Well(petrel_name="Pseudowell34")
Well(petrel_name="Pseudowell112")
Well(petrel_name="15/9-F-15 D")
Well(petrel_name="Pseudowell15")
Well(petrel_name="Pseudowell17")
Well(petrel_name="Pseudowell104")
Well(petrel_name="Pseudowell88")
Well(petrel_name="15/9-F-5")
Well(petrel_name="15/9-F-12")
Well(petrel_name="15/9-F-15")
Well(petrel_name="Pseudowell51")
Well(petrel_name="15/9-19 SR")
Well(petrel_name="15/9-F-11 B")
Well(petrel_name="Pseudowell27")
Well(petrel_name="Pseudowell73")
Well(petrel_name="Copy of 15/9-F-11 A")
Well(petrel_name="Pseudowell37")
Well(petrel_name="Pseudowell7")
Well(petrel_name="Copy of 15/9-F-4")
Well(petrel_name="Pseudowell24")
Well(petrel_name="15/9-F-1 C")
Using the .logs property we obtain a readonly iterable collection of the logs available for the selected well:

for obj in well.logs:
    print (obj)
To access the well global observed data we can use the .observed_data_sets property which returns a readonly iterable collection of the observed data sets for the well :

for obs in well.observed_data_sets:
    print (obs)
To access the well survey we can use the .surveys property which returns a readonly iterable collection of the well surveys for the selected well :

for sur in well.surveys:
    print(sur)
WellSurvey(petrel_name="Pseudo surv")
Note: The ability to access well folders and to create Wells is a feature available Python Tool Pro version 2.3.

Accessing well folders
With Python Tool Pro version 2.3 we can now access the wells folders using the .well_folders property. This will retrun all the well folders from the project in a dictionary where the keys represent the path of the well folder within the Petrel input tree and the value represents the name of the folder.

ptp.well_folders
WellFolders({'Input/Wells/wellTops': WellFolder(petrel_name="wellTops"), 'Input/Wells/LAS import': WellFolder(petrel_name="LAS import"), 'Input/Wells/Gullfaks wells/Producers': WellFolder(petrel_name="Producers"), 'Input/Wells': WellFolder(petrel_name="Wells"), 'Input/Wells/Pseudowells': WellFolder(petrel_name="Pseudowells"), 'Input/Wells/Volve VS log prediction': WellFolder(petrel_name="Volve VS log prediction"), 'Input/Wells/Gullfaks wells/Injectors': WellFolder(petrel_name="Injectors"), 'Input/Wells/VelocityAnisotropy': WellFolder(petrel_name="VelocityAnisotropy"), 'Input/Wells/Gullfaks wells': WellFolder(petrel_name="Gullfaks wells")})
We can retrieve the Producers folder using a list comprehension which iterates over each well folder (el) returned by the .well_folders property. The condition el .petrel_name == ‘Producers’ checks if the petrel_name of the folder is equal to ‘Producers’. If the condition is true (i.e., the well folder has a petrel_name equal to ‘Producers’), the folder el is added to the new list wf.

well_folder=[el for el in ptp.well_folders if el.petrel_name=='Producers'][0]
well_folder
WellFolder(petrel_name="Producers")
The path of the folder can be returned using the .path property:

well_folder.path
'Input/Wells/Gullfaks wells/Producers'
The .petrel_name property returns the name of the folder:

well_folder.petrel_name
'Producers'
You .droid porperty returns the GUID of the folder:

well_folder.droid
'076c3186-156a-4d1c-903d-ca545d3d93eb'
You can retrieve the statistics of the folder using the .retrieve_stats() function:

well_folder.retrieve_stats()
{'   In this folder': '5',
 'Number of wells': '',
 'X Min': '456510.41',
 'Lat Min': '61.1630135',
 'Long Max': '2.21830902777778',
 'X Delta': '1426.81',
 'Z Delta': '2989.78',
 'Long Min': '2.19037675',
 'X Max': '457937.22',
 'Lat Max': '61.2185534166667',
 'Y Max': '6787544.54',
 'Z Min': '-2989.78',
 '   Includes sub folders': '5',
 'Number of well logs': '35',
 'Long Delta': '0.027932277777778',
 'Z Max': '0',
 'Y Delta': '6169.96999999974',
 'Y Min': '6781374.57',
 'Lat Delta': '0.0555399166666675'}
We can modify the readonly status of the folder by assigning it a True or False value. The default value is True.

well_folder.readonly=False
The .add_comment function will add a comment to the selected folder:

well_folder.add_comment('This folder has been modified by Python Tool Pro')
add_comment.png
The .comment property will return all the comments associated with the selected folder:

well_folder.comments
'This folder has been modified by Python Tool Pro'
With Python Tool Pro version 2.5 or higher it is possible to retrieve the wells from a well folder object.

[i for i in well_folder.wells]
[Well(petrel_name="A10"),
 Well(petrel_name="A15"),
 Well(petrel_name="B8"),
 Well(petrel_name="A16"),
 Well(petrel_name="B9")]
Create wells
If you want to learn more about creating wells check out the Create Well tutorial.

Main wells
Also new to the Python Tool Pro version 2.3 is the ability to create wells.

Creating a new well is a multi-step process which includes creating the well , setting the wellhead coordinates and setting the well datum.

We can create a well using the .create_well() function which takes in 2 parameters: the name of the well and the folder you want to place the well in:

new_well=ptp.create_well('New_well',well_folder)
new_well
Well(petrel_name="New_well")
We can set the wellhead coordinates of the new well using the .wellhead_coordinates property. Note that you use this property to change the wellhead coordinates on any existing well:

#Provide the X and Y values of the wellhead coordinates as a tuple (x,y)
new_well.wellhead_coordinates=(455029,6785991)
We can set the well datum of the new well using the .well_datum property and a tuple (name, offset, description). The description parameter is optional. You can use this property to change the elevation datum on any existing well. Note that each time you add a new well_datum it will add it to the list of datums in the well and set it active:

new_well.well_datum=("KB", 25, "Kelly Bushing")
The image bellow shows the settings pane of the newly created well. You can see the wellhead coordinates and the well datum which we set. Not that the well has no active survey. We’ll need to create a survey and calucate the trajectory. We’ll do that in the next section of this user guide (Working with well surveys).

new_well.png
The unique well identifier can be set using the property uwi.

Note: The ability to access unique well identifier is a feature available in Python Tool Pro version 2.5.

new_well.uwi = '10-02-2'
new_well.uwi
'10-02-2'
The spud date can be set using the property spud_date.

Note: The ability to access spud date is a feature available in Python Tool Pro version 2.6 or higher.

import datetime
new_well.spud_date=datetime.datetime(2020, 1, 1)
new_well.spud_date
datetime.datetime(2020, 1, 1, 0, 0)
The well symbol can be retrieved and set using the property well_symbol.

Note: The ability to access well symbol is a feature available in Python Tool Pro version 2.6 or higher.

new_well.well_symbol
WellSymbolDescription((0) Undefined)
ptp.available_well_symbols()
[WellSymbolDescription((0) Undefined),
 WellSymbolDescription((1) Proposed),
 WellSymbolDescription((2) Dry),
 WellSymbolDescription((3) Oil),
 WellSymbolDescription((4) Minor oil),
 WellSymbolDescription((5) Gas),
 WellSymbolDescription((6) Minor gas),
 WellSymbolDescription((7) Condensate),
 WellSymbolDescription((8) Platform),
 WellSymbolDescription((9) Abandoned oil and gas),
 WellSymbolDescription((10) Abandoned oil minor gas),
 WellSymbolDescription((11) Abandoned oil condensate),
 WellSymbolDescription((12) Abandoned gas residual oil),
 WellSymbolDescription((13) Abandoned gas condensate),
 WellSymbolDescription((14) Abandoned minor oil and gas),
 WellSymbolDescription((15) Injection water),
 WellSymbolDescription((16) Injection gas),
 WellSymbolDescription((17) Shallow borehole),
 WellSymbolDescription((18) Drilling well),
 WellSymbolDescription((19) Abandoned for techn. reasons),
 WellSymbolDescription((20) Temporarily abandoned),
 WellSymbolDescription((21) Plugged and abandoned),
 WellSymbolDescription((22) Not observed),
 WellSymbolDescription((23) Residual oil),
 WellSymbolDescription((24) Proposed platform),
 WellSymbolDescription((25) Subsea installation),
 WellSymbolDescription((26) Dry, plugged and abandoned),
 WellSymbolDescription((27) Oil, plugged and abandoned),
 WellSymbolDescription((28) Gas, plugged and abandoned),
 WellSymbolDescription((29) Condensate, plugged and abandoned),
 WellSymbolDescription((30) Oil, temp. abandoned),
 WellSymbolDescription((31) Gas, temp. abandoned),
 WellSymbolDescription((32) Gas, residual oil),
 WellSymbolDescription((33) Minor gas, residual oil),
 WellSymbolDescription((34) Dual completion oil),
 WellSymbolDescription((35) Dual completion gas),
 WellSymbolDescription((36) Dual completion oil and gas),
 WellSymbolDescription((37) Planned water injector),
 WellSymbolDescription((38) Planned gas injector),
 WellSymbolDescription((39) Minor oil, plugged and abandoned),
 WellSymbolDescription((40) Minor gas, plugged and abandoned),
 WellSymbolDescription((41) Minor oil and gas, plugged and abandoned),
 WellSymbolDescription((42) Gas condensate, plugged and abandoned),
 WellSymbolDescription((43) Gas condensate, temp. abandoned),
 WellSymbolDescription((44) Well impact),
 WellSymbolDescription((45) Closed oil producer),
 WellSymbolDescription((46) Open oil producer),
 WellSymbolDescription((47) Open water injector),
 WellSymbolDescription((48) Closed water injector),
 WellSymbolDescription((49) Surface location),
 WellSymbolDescription((50) Permitted),
 WellSymbolDescription((51) Water source),
 WellSymbolDescription((52) Oil, minor gas),
 WellSymbolDescription((53) Oil minor gas, temp. abandoned),
 WellSymbolDescription((54) Oil and gas, temp. abandoned),
 WellSymbolDescription((55) Injection steam),
 WellSymbolDescription((56) Injection LPG),
 WellSymbolDescription((57) Injection-production water),
 WellSymbolDescription((58) Injection-production steam),
 WellSymbolDescription((59) Injection-production LPG),
 WellSymbolDescription((308) Relief well)]
new_well_symbol=[i for i in ptp.available_well_symbols()][5]
new_well.well_symbol=new_well_symbol
new_well.well_symbol
WellSymbolDescription((5) Gas)
Sidetracks (lateral wells)
Similarly, we can also use the .create_lateral() function on an existing well to create a sidetrack well:

Sidetrack=new_well.create_lateral('Sidetrack')
Sidetrack
Well(petrel_name="Sidetrack")
Note that you can not set the wellhead coordinates and well datum on lateral wells. These properties are inherited from the main well used to create the sidetrack. The image bellow shows the newly created sidetrack well in Petrel:

lateral.png
You can check if a well is a lateral well or not using the is_lateral property which returns a boolean value (False if the well is a main well, True if a well is a lateral well):

print(new_well.is_lateral)
print(Sidetrack.is_lateral)
False
True
Working with well surveys
Check out the API documentation to view a detailed description of all the functions and properties available for working with well surveys.

To return all surveys as a dictionary with names and paths we can use the .well_surveys property:

ptp.well_surveys
WellSurveys({'Input/Wells/Pseudowells/Pseudowell88/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell11/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-11 A/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/wellTops/35/9-8/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell72/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/16/7-6/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell89/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell67/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell21/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell79/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell4/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell22/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell37/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell86/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell35/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell59/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell103/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/34/3-3 A/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Volve VS log prediction/15/9-F-1 C/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell20/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell31/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell23/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-5/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell66/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell9/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-19 SR/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell102/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell57/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell50/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell45/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell81/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell0/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell73/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell119/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell85/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-15 B/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell58/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell12/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell13/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell38/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/34/3-2 S/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell109/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell56/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell83/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell24/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-15/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell62/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/17/4-1/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell14/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-19 A/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell71/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-11 B/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/wellTops/35/9-7/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell106/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell69/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell96/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell77/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell91/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell30/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell18/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell108/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell60/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell2/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell64/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell28/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/empty/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/wellTops/34/10-16 R/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/wellTops/31/2-10/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/wellTops/25/5-3/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell15/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-1 B/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell5/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/35/6-2 S/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/wellTops/15/9-14/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell3/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell101/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell63/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell87/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell93/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell115/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-15 A/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/wellTops/31/2-21 S/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell117/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell19/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell17/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-1 A/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell8/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell40/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-14/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell1/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell113/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell10/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell48/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell55/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell74/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell44/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-15 D/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell98/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell34/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell54/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell107/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/25/10-9/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell105/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-4/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Volve VS log prediction/15/9-F-10/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell78/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/15/9-23/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell111/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell68/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell99/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell104/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell49/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell33/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell70/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/25/11-24/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell29/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell53/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell51/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/34/6-1 S/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell75/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell32/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/16/2-7/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell25/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-15 C/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell110/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-19 BT2/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell76/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell47/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell116/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell46/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell90/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell27/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell43/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell39/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell36/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell65/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-12/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/wellTops/29/3-1/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Volve VS log prediction/15/9-F-1/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell114/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell42/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell92/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell61/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell16/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell95/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell6/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/35/11-5/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell80/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell26/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell52/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell100/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell112/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell82/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell118/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell84/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell41/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell94/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/25/10-10/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell97/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell7/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-11 A/Copy of MD Incl Azim survey 1': WellSurvey(petrel_name="Copy of MD Incl Azim survey 1"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 A/Copy of MD Incl Azim survey 2': WellSurvey(petrel_name="Copy of MD Incl Azim survey 2"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 SR/Copy of MD Incl Azim survey 2': WellSurvey(petrel_name="Copy of MD Incl Azim survey 2"), 'Input/Wells/Gullfaks wells/Producers/A10/NewWellSurveyName': WellSurvey(petrel_name="NewWellSurveyName"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-4/Copy of MD Incl Azim survey 1': WellSurvey(petrel_name="Copy of MD Incl Azim survey 1"), 'Input/Wells/Gullfaks wells/Producers/A10/Survey_A10_demo': WellSurvey(petrel_name="Survey_A10_demo"), 'Input/Wells/Gullfaks wells/Producers/B8/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Injectors/C4/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Injectors/C5/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Producers/B9/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Injectors/C6/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Injectors/C3/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Injectors/C2/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Producers/A15/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Producers/A16/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Producers/A10/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1")})
Similarly, we can iterate trough the dictionary and return all the values of it:

for w in ptp.well_surveys:
    print(w)
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Copy of MD Incl Azim survey 1")
WellSurvey(petrel_name="Copy of MD Incl Azim survey 2")
WellSurvey(petrel_name="Copy of MD Incl Azim survey 2")
WellSurvey(petrel_name="NewWellSurveyName")
WellSurvey(petrel_name="Copy of MD Incl Azim survey 1")
WellSurvey(petrel_name="Survey_A10_demo")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
Let’s select the Survey_A10_demo:

all_well_surveys = ptp.well_surveys
paths = list(all_well_surveys.keys())
well_survey = ptp.well_surveys[paths[0]]
print(well_survey)
WellSurvey(petrel_name="Pseudo surv")
Using the .azimuth_reference we can obtain the azimuth reference for well survey types of MD inclination azimuth survey and DX DY TVD survey:

well_survey.azimuth_reference
'Grid north'
The .record_count will return the amount of trajectory points as defined in Petrel trajectory spreadsheet for selected well survey:

recordcount2.png
well_survey.record_count
2
We can load the trajectory spreadsheet into a DataFrame using the .as_dataframe() method:

well_survey_df = well_survey.as_dataframe()
well_survey_df
X	Y	Z	MD	Inclination	Azimuth GN
0	456979.0637	6782712.412	-0.0	0.0	0.0	0.0
1	456979.0637	6782712.412	-1000.0	1000.0	0.0	0.0
Determine the well survey type
Petrel well surveys can be of 5 different types. They are: * ‘X Y Z survey’ * ‘X Y TVD survey’ * ‘DX DY TVD survey’ * ‘MD inclination azimuth survey’ * ‘Explicit survey’

Python Tool Pro does not differentiate different well surveys type when retrieving the list of well surveys. But once you retrieve a specific well survey, the type is checked. You can find out the survey type by using the method well_survey_type:

wellsurveytype.png
well_survey.well_survey_type
'X Y Z survey'
Since a well can have several surveys available, users can check if a survey is set as definitive and select which one to use with the .set_survey_as_definitive() function:

Note: The property is_definitive is available in Python Tool Pro version 2.6 or higher

well_survey.is_definitive
True
well_survey.set_survey_as_definitive()
Lateral well surveys will have a tie in point with another well survey. This can be printed by using the tie_in_md property:

PetrelPathToLateralWellSurvey=""
lateral_well_survey=ptp.well_surveys[PetrelPathToLateralWellSurvey]
lateral_well_survey.tie_in_md
You can create a new well survey with the clone function. Using the flag copy_values=False Python Tool Pro will create a new well survey with no trajectory:

well_survey.clone('NewWellSurveyName', copy_values=False)
WellSurvey(petrel_name="NewWellSurveyName")
The results are written back to Petrel in real time. Notice that the newly created survey has no values:

cloneSurvey.png
Creating well surveys
Note: The ability to create well surveys is a feature available Python Tool Pro version 2.3.

We can create a new well survey using the .create_well_survey property on a main well and specifing the name of the new survey and the type of the survey:

# select a well
well=[i for i in ptp.wells][0]
well.readonly=False
[i for i in well.surveys]
[WellSurvey(petrel_name="Pseudo surv")]

# create new survey
new_well_survey=well.create_well_survey('New Survey','X Y Z survey' )
new_well_survey
WellSurvey(petrel_name="New Survey")
In Python Tool Pro version 2.6 or higher it is possible to retrieve the well survey object by name.

well.surveys["New Survey"]
WellSurvey(petrel_name="New Survey")
The image bellow shows the newly created survey in Petrel. Note the trajectory calculation failed as the survey has no records:

failed_trajectory.png
We can set some values to the survey and calculate the trajectory. First we set the readonly status of the new well survey to false so we can modify it.

We can select the algorithm used in the trajectory calculation using the .algorithm property. The avialabe algorithms are : Minimum Curvature and Linearization.

Next we set the values to the survey using the .set() function and provide lists of x and y and z values. In the example bellow we are using the X and Y values from the wellhead coordinates to add 2 points in the survey record. As both values of X and Y are identical the well will be straight.

Lastly, we set this survey as the active one using the .set_survey_as_definitive() function.

new_well_survey.readonly=False
new_well_survey.algorithm='Minimum curvature'
new_well_survey.set(xs=[new_well.wellhead_coordinates[0],new_well.wellhead_coordinates[0]], ys=[new_well.wellhead_coordinates[1],new_well.wellhead_coordinates[1]], zs=[0,-2500])
new_well_survey.set_survey_as_definitive()
The image bellow shows the trajectory calculation of the new well survey in Petrel :

calculation_ok.png
To create a survey for lateral wells we need to use the .create_lateral_well_survey() function and besides the survey name and type we also need to provide the well survey of the main well and the kick-off point:

lateral_well=ptp.wells['Input/Wells/Producers/Sidetrack']
new_s=lateral_well.create_lateral_well_survey('lateral_survey','X Y Z survey',new_well.surveys[0],1500)
We can now set the survey values just how we did it for the main well:

new_s.readonly=False
new_s.algorithm='Minimum curvature'
new_s.set(xs=[455044.36],ys=[6785316.41],zs=[-1960])
new_s.set_survey_as_definitive()
The image bellow shows the trajectory calculation the lateral well:

lateral_traj.png
Well Logs
Python Tool Pro has 4 classes which allow users to work with well logs:

cegalprizm.pythontool.WellLog -> a class holding information about continuous well logs

cegalprizm.pythontool.DiscreteWellLog -> a class holding information about discrete well logs

cegalprizm.pythontool.GlobalWellLog -> a class holding information about global continuous well logs

cegalprizm.pythontool.DiscreteGlobalWellLog -> a class holding information about global discrete well logs

Check out the API documentation to view a detailed description of all the functions and properties available for working with well logs:

Continuous well logs

Continuous global well logs

Discrete well logs

Discrete global well logs

We can retrieve all the continuous logs belonging to all the wells using the .well_logs property which will return a dictionary where the key represents the path of the well log within the Petrel input tree and the value represents the well log name:

ptp.well_logs
WellLogs({'Input/Wells/Injectors/C6/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Injectors/C3/Well logs/Demo logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Producers/A10/Well logs/Demo logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Injectors/C5/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Injectors/C3/Well logs/Demo logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Producers/A10/Well logs/Demo logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Injectors/C3/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Producers/B9/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Injectors/C6/Well logs/Demo logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Injectors/C4/Well logs/Demo logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Producers/B8/Well logs/Demo logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Producers/B8/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Producers/B8/Well logs/Demo logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Producers/A15/Well logs/Demo logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Injectors/C2/Well logs/Demo logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Producers/A16/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Producers/A16/Well logs/Demo logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Injectors/C3/Well logs/Demo logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Injectors/C5/Well logs/Demo logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Producers/A16/Well logs/Demo logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Producers/B9/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Producers/B8/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Injectors/C6/Well logs/Demo logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Producers/A16/Well logs/Demo logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Producers/B9/Well logs/Demo logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Producers/A15/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Injectors/C4/Well logs/Demo logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Producers/B8/Well logs/Demo logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Injectors/C4/Well logs/Demo logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Producers/A15/Well logs/Demo logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Injectors/C5/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Producers/A16/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Producers/A10/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Producers/A15/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Producers/B9/Well logs/Demo logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Injectors/C6/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Injectors/C4/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Injectors/C5/Well logs/Demo logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Injectors/C2/Well logs/Demo logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Producers/B9/Well logs/Demo logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Producers/A10/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Producers/A10/Well logs/Demo logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Injectors/C2/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Injectors/C5/Well logs/Demo logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Injectors/C2/Well logs/Demo logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Injectors/C4/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Injectors/C2/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Producers/A15/Well logs/Demo logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Injectors/C3/Well logs/Porosity': WellLog(petrel_name="Porosity")})
We can use widgets to navigate through different wells and explore the available logs:

import ipywidgets as widgets
well_names = sorted(list(petrel.wells.keys()))
well_name_widget = widgets.Dropdown(
    options=well_names,
    value=well_names[0],
    description='Select well:',
    disabled=False,
)
display(well_name_widget)
Alternatively, we can just assign a particular well to a variable:

well_list=sorted(list(ptp.wells.keys()))
well_A10= well_list[5]
print(well_A10)
Input/Wells/Producers/A10
We can assign all the logs available for well A10 to a variable and by using a nested list we can print out their name:

well=ptp.wells[well_A10]
logs = well.logs
print(', '.join([log.petrel_name for log in logs]))
Gamma, NetGross, Perm, Porosity, One-way time 1, Facies
We can also assign all the well logs to a list:

from cegalprizm.pythontool.welllog import WellLog
A10cont_logs = [log for log in well.logs if type(log) is WellLog]
print(A10cont_logs)
[WellLog(petrel_name="Gamma"), WellLog(petrel_name="NetGross"), WellLog(petrel_name="Perm"), WellLog(petrel_name="Porosity"), WellLog(petrel_name="One-way time 1")]
To determine which global well log the selected log belongs to, we can use the .global_well_log property:

A10cont_logs[1].global_well_log
GlobalWellLog(petrel_name="NetGross")
The .well property allows users to check which well the selected log belongs to:

A10cont_logs[2].well
Well(petrel_name="A10")
To check the Petrel template of a particular log, we can use the .template property:

A10cont_logs[2].template
'Permeability'
Similarly, using the .unit_symbol attribute, we can access the unit for any object associated with a certain template:

symbol=A10cont_logs[2].unit_symbol
"The unit_symbol for the log {} is {}".format(A10cont_logs[2].petrel_name,symbol)
'The unit_symbol for the log Perm is mD'
Different projects use different standard values to mark missing values. To check the value interpreted by Petrel as a ‘missing’ one we can use the .missing_value property:

A10cont_logs[2].missing_value
nan
To get all the continuous wells logs associated to well A10, interpolated at the same depth in a dataframe we can use the .logs_dataframe() function:

A10logs_df = well.logs_dataframe(A10cont_logs)

# Sets MD as index
A10logs_df = A10logs_df.set_index('MD')
A10logs_df
Gamma	NetGross	Perm	Porosity	One-way time 1	TWT	TVD
MD							
-527.621008	NaN	NaN	NaN	NaN	NaN	-510.664881	-527.621008
-527.121008	NaN	NaN	NaN	NaN	0.0	-510.180839	-527.121008
-526.621008	NaN	NaN	NaN	NaN	0.0	-509.696796	-526.621008
-526.121008	NaN	NaN	NaN	NaN	0.0	-509.212754	-526.121008
-525.621008	NaN	NaN	NaN	NaN	0.0	-508.728711	-525.621008
...	...	...	...	...	...	...	...
2413.878992	75.862561	0.0	105.309330	0.173314	NaN	2037.715005	2413.878992
2414.378992	75.399295	0.0	103.075364	0.177510	NaN	2038.055903	2414.378992
2414.878992	NaN	0.0	NaN	NaN	NaN	2038.396801	2414.878992
2415.378992	NaN	0.0	NaN	NaN	NaN	2038.737699	2415.378992
2415.878992	NaN	0.0	NaN	NaN	NaN	2039.078597	2415.878992
5888 rows × 7 columns

The .create_well_log() function creates a well log for a particular well and assigns this log to a specific global well log. The function takes in one parmeter which represents the well object for which the well log is to be created. The function will output an empty well log with no values assigned to it. The difference between this function and the .clone() one is that when using the .clone() function to create a new well log for a well it will also generate a new global well log which is not always ideal .

#Assign the log we want to copy to a variable

new_log=A10cont_logs[3].global_well_log
print(new_log)
GlobalWellLog(petrel_name="Porosity")
#Assign the well we want to generate the new log for to a variable

all_wells_paths=ptp.wells.keys()
paths = list(all_wells_paths)
well15 = ptp.wells[paths[8]]
print(well15)
Well(petrel_name="A15")
#Create a porosity log for well 15 and assign it to the porosity global well log

new_log.create_well_log(well15)
WellLog(petrel_name="Porosity")
The image bellow shows the output of the previous cell. A new porosity log has been created for well 15. Note that the log has no depth or porosity values and it is assigned to the porosity global well log:

createwelllog.png
All the previous examples can be reproduced with discrete logs as most of the attributes and methods are common to all the classes. Let’s select well C2:

from cegalprizm.pythontool.welllog import DiscreteWellLog


well_list=sorted(list(ptp.wells.keys()))
well_C2= well_list[0]
print(well_C2)
Input/Wells/Injectors/C2
Print out the associated discrete logs:

well=ptp.wells[well_C2]
logs = well.logs
discrete_logs = [log for log in logs if type(log) is DiscreteWellLog]
print("Well C2 has", len(discrete_logs), "discrete logs:", "\n")
print(', '.join([log.petrel_name for log in logs if type(log) is DiscreteWellLog]))

Well C2 has 1 discrete logs:

Facies
Create a DataFrame of the discrete logs in well C2:

C2Facies = well.logs_dataframe(discrete_logs[0])

# Sets MD as index
C2Facies = C2Facies.set_index('MD')
C2Facies
Facies	TWT	TVD
MD			
1923.907229	Silt	1824.370861	1924.172392
1928.714834	Sand	1827.628075	1927.607736
1932.181133	Fine Silt	1829.594166	1930.084630
1934.049920	Silt	1830.615324	1931.419999
1935.391227	Sand	1831.348252	1932.378449
...	...	...	...
2448.439087	Clay	2099.553700	2270.344903
2450.193287	Sand	2100.467339	2271.430009
2457.978592	Clay	2104.503249	2276.222562
2473.757075	UNDEF	2112.599674	2285.837806
2476.379880	UNDEF	2113.944556	2287.435320
89 rows × 3 columns

The .discrete_codes property returns a dictionary of discrete codes as keys and the associated facies as values. Changes to this dictionary will not be persisted or affect any Petrel objects:

facies_codes.png
discrete_logs[0].discrete_codes
{0: 'Clay', 1: 'Sand', 2: 'Silt', 3: 'Fine Silt'}
We can retrieve the statics of the Facies log associate with well C2 by using the .retrieve_stats() function:

Faciesstatistic.png
discrete_logs[0].retrieve_stats()
{'X Min': '454635',
 'X Max': '455033.33',
 'X Delta': '398.330000000016',
 'Y Min': '6787607.12',
 'Y Max': '6787607.12',
 'Y Delta': '0',
 'Z Min': '-2283.72',
 'Z Max': '-1924.84',
 'Z Delta': '358.88',
 'Facies Min': '0',
 'Facies Max': '3',
 'Facies Delta': 'NaN',
 'Is synthetic': 'No',
 'Start md': '1923.90722924',
 'Base md': '2476.37988030',
 'Average md increment': '6.27809831',
 'Number of defined samples': '87',
 '-----------------': '-----------------',
 'Type of data': 'Discrete',
 'Min': '0',
 'Max': '3',
 'Delta': '3',
 'Number of defined values': '1100',
 'Mean': '1',
 'Std. dev.': '1',
 'Variance': '1',
 'Sum': '970'}
To create a copy of the Facies log associated to well C2, we can use the .clone() function. The clone is placed in the same collection as the source object. A clone cannot be created with the same name as an existing Petrel object in the same collection.

discrete_logs[0].clone('newFaciesLog', copy_values=True)
DiscreteWellLog(petrel_name="newFaciesLog")
===
Well data
This section offers an overview of the different methods and attributes available for the Petrel well object subcategories.

from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection()
Wells
Check out the API documentation to view a detailed description of all the functions and properties available for working with well headers.

Let’s look at an example on how to retrieve all the wells from our Petrel project by using the .wells property:

all_wells = ptp.wells
print(all_wells)
{'Input/Wells/Pseudowells/Pseudowell104': Well(petrel_name="Pseudowell104"), 'Input/Wells/Volve VS log prediction/15/9-F-12': Well(petrel_name="15/9-F-12"), 'Input/Wells/wellTops/25/10-9': Well(petrel_name="25/10-9"), 'Input/Wells/Pseudowells/Pseudowell0': Well(petrel_name="Pseudowell0"), 'Input/Wells/Pseudowells/Pseudowell51': Well(petrel_name="Pseudowell51"), 'Input/Wells/Pseudowells/Pseudowell27': Well(petrel_name="Pseudowell27"), 'Input/Wells/wellTops/34/3-3 A': Well(petrel_name="34/3-3 A"), 'Input/Wells/Pseudowells/Pseudowell78': Well(petrel_name="Pseudowell78"), 'Input/Wells/Pseudowells/Pseudowell76': Well(petrel_name="Pseudowell76"), 'Input/Wells/Gullfaks wells/Injectors/C4': Well(petrel_name="C4"), 'Input/Wells/Pseudowells/Pseudowell63': Well(petrel_name="Pseudowell63"), 'Input/Wells/Volve VS log prediction/15/9-F-15 B': Well(petrel_name="15/9-F-15 B"), 'Input/Wells/Pseudowells/Pseudowell103': Well(petrel_name="Pseudowell103"), 'Input/Wells/Pseudowells/Pseudowell23': Well(petrel_name="Pseudowell23"), 'Input/Wells/Volve VS log prediction/15/9-F-1': Well(petrel_name="15/9-F-1"), 'Input/Wells/Pseudowells/Pseudowell5': Well(petrel_name="Pseudowell5"), 'Input/Wells/Pseudowells/Pseudowell69': Well(petrel_name="Pseudowell69"), 'Input/Wells/wellTops/25/11-24': Well(petrel_name="25/11-24"), 'Input/Wells/Volve VS log prediction/15/9-F-15': Well(petrel_name="15/9-F-15"), 'Input/Wells/Pseudowells/Pseudowell3': Well(petrel_name="Pseudowell3"), 'Input/Wells/wellTops/34/3-2 S': Well(petrel_name="34/3-2 S"), 'Input/Wells/Pseudowells/Pseudowell39': Well(petrel_name="Pseudowell39"), 'Input/Wells/Pseudowells/Pseudowell74': Well(petrel_name="Pseudowell74"), 'Input/Wells/Pseudowells/Pseudowell83': Well(petrel_name="Pseudowell83"), 'Input/Wells/wellTops/25/10-10': Well(petrel_name="25/10-10"), 'Input/Wells/Pseudowells/Pseudowell7': Well(petrel_name="Pseudowell7"), 'Input/Wells/Pseudowells/Pseudowell72': Well(petrel_name="Pseudowell72"), 'Input/Wells/Pseudowells/Pseudowell14': Well(petrel_name="Pseudowell14"), 'Input/Wells/Pseudowells/Pseudowell55': Well(petrel_name="Pseudowell55"), 'Input/Wells/Pseudowells/Pseudowell114': Well(petrel_name="Pseudowell114"), 'Input/Wells/Pseudowells/Pseudowell15': Well(petrel_name="Pseudowell15"), 'Input/Wells/Pseudowells/Pseudowell29': Well(petrel_name="Pseudowell29"), 'Input/Wells/Pseudowells/Pseudowell41': Well(petrel_name="Pseudowell41"), 'Input/Wells/Volve VS log prediction/15/9-F-11 B': Well(petrel_name="15/9-F-11 B"), 'Input/Wells/Pseudowells/Pseudowell118': Well(petrel_name="Pseudowell118"), 'Input/Wells/wellTops/34/10-16 R': Well(petrel_name="34/10-16 R"), 'Input/Wells/Pseudowells/Pseudowell107': Well(petrel_name="Pseudowell107"), 'Input/Wells/wellTops/29/3-1': Well(petrel_name="29/3-1"), 'Input/Wells/Pseudowells/Pseudowell75': Well(petrel_name="Pseudowell75"), 'Input/Wells/Pseudowells/Pseudowell89': Well(petrel_name="Pseudowell89"), 'Input/Wells/Pseudowells/Pseudowell86': Well(petrel_name="Pseudowell86"), 'Input/Wells/Pseudowells/Pseudowell100': Well(petrel_name="Pseudowell100"), 'Input/Wells/Pseudowells/Pseudowell99': Well(petrel_name="Pseudowell99"), 'Input/Wells/Pseudowells/Pseudowell65': Well(petrel_name="Pseudowell65"), 'Input/Wells/Pseudowells/Pseudowell117': Well(petrel_name="Pseudowell117"), 'Input/Wells/Pseudowells/Pseudowell90': Well(petrel_name="Pseudowell90"), 'Input/Wells/Pseudowells/Pseudowell105': Well(petrel_name="Pseudowell105"), 'Input/Wells/Volve VS log prediction/15/9-F-15 C': Well(petrel_name="15/9-F-15 C"), 'Input/Wells/Pseudowells/Pseudowell67': Well(petrel_name="Pseudowell67"), 'Input/Wells/Pseudowells/Pseudowell26': Well(petrel_name="Pseudowell26"), 'Input/Wells/Volve VS log prediction/15/9-19 SR': Well(petrel_name="15/9-19 SR"), 'Input/Wells/Pseudowells/Pseudowell109': Well(petrel_name="Pseudowell109"), 'Input/Wells/Gullfaks wells/Producers/A15': Well(petrel_name="A15"), 'Input/Wells/Pseudowells/Pseudowell18': Well(petrel_name="Pseudowell18"), 'Input/Wells/Pseudowells/Pseudowell12': Well(petrel_name="Pseudowell12"), 'Input/Wells/Volve VS log prediction/15/9-F-11 A': Well(petrel_name="15/9-F-11 A"), 'Input/Wells/Pseudowells/Pseudowell87': Well(petrel_name="Pseudowell87"), 'Input/Wells/Pseudowells/Pseudowell73': Well(petrel_name="Pseudowell73"), 'Input/Wells/Pseudowells/Pseudowell62': Well(petrel_name="Pseudowell62"), 'Input/Wells/Pseudowells/empty': Well(petrel_name="empty"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-11 A': Well(petrel_name="Copy of 15/9-F-11 A"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-4': Well(petrel_name="Copy of 15/9-F-4"), 'Input/Wells/Pseudowells/Pseudowell53': Well(petrel_name="Pseudowell53"), 'Input/Wells/Gullfaks wells/Producers/A16': Well(petrel_name="A16"), 'Input/Wells/Pseudowells/Pseudowell85': Well(petrel_name="Pseudowell85"), 'Input/Wells/Pseudowells/Pseudowell116': Well(petrel_name="Pseudowell116"), 'Input/Wells/Pseudowells/Pseudowell9': Well(petrel_name="Pseudowell9"), 'Input/Wells/Pseudowells/Pseudowell106': Well(petrel_name="Pseudowell106"), 'Input/Wells/Pseudowells/Pseudowell2': Well(petrel_name="Pseudowell2"), 'Input/Wells/Pseudowells/Pseudowell21': Well(petrel_name="Pseudowell21"), 'Input/Wells/Pseudowells/Pseudowell1': Well(petrel_name="Pseudowell1"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 SR': Well(petrel_name="Copy of 15/9-19 SR"), 'Input/Wells/Volve VS log prediction/15/9-F-1 A': Well(petrel_name="15/9-F-1 A"), 'Input/Wells/Pseudowells/Pseudowell94': Well(petrel_name="Pseudowell94"), 'Input/Wells/Pseudowells/Pseudowell93': Well(petrel_name="Pseudowell93"), 'Input/Wells/Pseudowells/Pseudowell108': Well(petrel_name="Pseudowell108"), 'Input/Wells/Pseudowells/Pseudowell68': Well(petrel_name="Pseudowell68"), 'Input/Wells/Pseudowells/Pseudowell92': Well(petrel_name="Pseudowell92"), 'Input/Wells/Pseudowells/Pseudowell38': Well(petrel_name="Pseudowell38"), 'Input/Wells/Pseudowells/Pseudowell102': Well(petrel_name="Pseudowell102"), 'Input/Wells/wellTops/31/2-21 S': Well(petrel_name="31/2-21 S"), 'Input/Wells/Pseudowells/Pseudowell36': Well(petrel_name="Pseudowell36"), 'Input/Wells/Pseudowells/Pseudowell33': Well(petrel_name="Pseudowell33"), 'Input/Wells/Pseudowells/Pseudowell44': Well(petrel_name="Pseudowell44"), 'Input/Wells/Pseudowells/Pseudowell34': Well(petrel_name="Pseudowell34"), 'Input/Wells/Pseudowells/Pseudowell91': Well(petrel_name="Pseudowell91"), 'Input/Wells/Pseudowells/Pseudowell112': Well(petrel_name="Pseudowell112"), 'Input/Wells/Pseudowells/Pseudowell97': Well(petrel_name="Pseudowell97"), 'Input/Wells/Pseudowells/Pseudowell28': Well(petrel_name="Pseudowell28"), 'Input/Wells/Pseudowells/Pseudowell17': Well(petrel_name="Pseudowell17"), 'Input/Wells/Pseudowells/Pseudowell88': Well(petrel_name="Pseudowell88"), 'Input/Wells/Pseudowells/Pseudowell56': Well(petrel_name="Pseudowell56"), 'Input/Wells/Pseudowells/Pseudowell47': Well(petrel_name="Pseudowell47"), 'Input/Wells/wellTops/35/6-2 S': Well(petrel_name="35/6-2 S"), 'Input/Wells/Pseudowells/Pseudowell82': Well(petrel_name="Pseudowell82"), 'Input/Wells/Volve VS log prediction/15/9-F-4': Well(petrel_name="15/9-F-4"), 'Input/Wells/Pseudowells/Pseudowell50': Well(petrel_name="Pseudowell50"), 'Input/Wells/Pseudowells/Pseudowell119': Well(petrel_name="Pseudowell119"), 'Input/Wells/Pseudowells/Pseudowell57': Well(petrel_name="Pseudowell57"), 'Input/Wells/Pseudowells/Pseudowell70': Well(petrel_name="Pseudowell70"), 'Input/Wells/Pseudowells/Pseudowell10': Well(petrel_name="Pseudowell10"), 'Input/Wells/Pseudowells/Pseudowell20': Well(petrel_name="Pseudowell20"), 'Input/Wells/Gullfaks wells/Injectors/C6': Well(petrel_name="C6"), 'Input/Wells/Gullfaks wells/Producers/B9': Well(petrel_name="B9"), 'Input/Wells/Pseudowells/Pseudowell71': Well(petrel_name="Pseudowell71"), 'Input/Wells/Gullfaks wells/Producers/B8': Well(petrel_name="B8"), 'Input/Wells/Volve VS log prediction/15/9-F-10': Well(petrel_name="15/9-F-10"), 'Input/Wells/wellTops/15/9-23': Well(petrel_name="15/9-23"), 'Input/Wells/wellTops/31/2-10': Well(petrel_name="31/2-10"), 'Input/Wells/Pseudowells/Pseudowell48': Well(petrel_name="Pseudowell48"), 'Input/Wells/Pseudowells/Pseudowell115': Well(petrel_name="Pseudowell115"), 'Input/Wells/Pseudowells/Pseudowell42': Well(petrel_name="Pseudowell42"), 'Input/Wells/wellTops/35/9-8': Well(petrel_name="35/9-8"), 'Input/Wells/Pseudowells/Pseudowell58': Well(petrel_name="Pseudowell58"), 'Input/Wells/Pseudowells/Pseudowell95': Well(petrel_name="Pseudowell95"), 'Input/Wells/wellTops/16/2-7': Well(petrel_name="16/2-7"), 'Input/Wells/Pseudowells/Pseudowell64': Well(petrel_name="Pseudowell64"), 'Input/Wells/Pseudowells/Pseudowell96': Well(petrel_name="Pseudowell96"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 A': Well(petrel_name="Copy of 15/9-19 A"), 'Input/Wells/Pseudowells/Pseudowell13': Well(petrel_name="Pseudowell13"), 'Input/Wells/Pseudowells/Pseudowell40': Well(petrel_name="Pseudowell40"), 'Input/Wells/Pseudowells/Pseudowell79': Well(petrel_name="Pseudowell79"), 'Input/Wells/Pseudowells/Pseudowell49': Well(petrel_name="Pseudowell49"), 'Input/Wells/Pseudowells/Pseudowell84': Well(petrel_name="Pseudowell84"), 'Input/Wells/Gullfaks wells/Injectors/C3': Well(petrel_name="C3"), 'Input/Wells/Gullfaks wells/Producers/A10': Well(petrel_name="A10"), 'Input/Wells/Pseudowells/Pseudowell37': Well(petrel_name="Pseudowell37"), 'Input/Wells/Pseudowells/Pseudowell59': Well(petrel_name="Pseudowell59"), 'Input/Wells/wellTops/16/7-6': Well(petrel_name="16/7-6"), 'Input/Wells/Pseudowells/Pseudowell60': Well(petrel_name="Pseudowell60"), 'Input/Wells/wellTops/17/4-1': Well(petrel_name="17/4-1"), 'Input/Wells/Pseudowells/Pseudowell4': Well(petrel_name="Pseudowell4"), 'Input/Wells/Pseudowells/Pseudowell24': Well(petrel_name="Pseudowell24"), 'Input/Wells/Pseudowells/Pseudowell6': Well(petrel_name="Pseudowell6"), 'Input/Wells/Pseudowells/Pseudowell22': Well(petrel_name="Pseudowell22"), 'Input/Wells/Pseudowells/Pseudowell101': Well(petrel_name="Pseudowell101"), 'Input/Wells/Volve VS log prediction/15/9-F-5': Well(petrel_name="15/9-F-5"), 'Input/Wells/Pseudowells/Pseudowell113': Well(petrel_name="Pseudowell113"), 'Input/Wells/Volve VS log prediction/15/9-19 A': Well(petrel_name="15/9-19 A"), 'Input/Wells/Pseudowells/Pseudowell66': Well(petrel_name="Pseudowell66"), 'Input/Wells/wellTops/25/5-3': Well(petrel_name="25/5-3"), 'Input/Wells/Pseudowells/Pseudowell80': Well(petrel_name="Pseudowell80"), 'Input/Wells/Pseudowells/Pseudowell35': Well(petrel_name="Pseudowell35"), 'Input/Wells/Gullfaks wells/Injectors/C5': Well(petrel_name="C5"), 'Input/Wells/Pseudowells/Pseudowell32': Well(petrel_name="Pseudowell32"), 'Input/Wells/wellTops/15/9-14': Well(petrel_name="15/9-14"), 'Input/Wells/Pseudowells/Pseudowell77': Well(petrel_name="Pseudowell77"), 'Input/Wells/Pseudowells/Pseudowell81': Well(petrel_name="Pseudowell81"), 'Input/Wells/Pseudowells/Pseudowell16': Well(petrel_name="Pseudowell16"), 'Input/Wells/wellTops/35/11-5': Well(petrel_name="35/11-5"), 'Input/Wells/Pseudowells/Pseudowell11': Well(petrel_name="Pseudowell11"), 'Input/Wells/Pseudowells/Pseudowell54': Well(petrel_name="Pseudowell54"), 'Input/Wells/Pseudowells/Pseudowell8': Well(petrel_name="Pseudowell8"), 'Input/Wells/Volve VS log prediction/15/9-F-1 C': Well(petrel_name="15/9-F-1 C"), 'Input/Wells/Volve VS log prediction/15/9-F-15 A': Well(petrel_name="15/9-F-15 A"), 'Input/Wells/Pseudowells/Pseudowell31': Well(petrel_name="Pseudowell31"), 'Input/Wells/Volve VS log prediction/15/9-F-14': Well(petrel_name="15/9-F-14"), 'Input/Wells/Pseudowells/Pseudowell45': Well(petrel_name="Pseudowell45"), 'Input/Wells/wellTops/34/6-1 S': Well(petrel_name="34/6-1 S"), 'Input/Wells/wellTops/35/9-7': Well(petrel_name="35/9-7"), 'Input/Wells/Volve VS log prediction/15/9-19 BT2': Well(petrel_name="15/9-19 BT2"), 'Input/Wells/Volve VS log prediction/15/9-F-1 B': Well(petrel_name="15/9-F-1 B"), 'Input/Wells/Gullfaks wells/Injectors/C2': Well(petrel_name="C2"), 'Input/Wells/Pseudowells/Pseudowell19': Well(petrel_name="Pseudowell19"), 'Input/Wells/Pseudowells/Pseudowell43': Well(petrel_name="Pseudowell43"), 'Input/Wells/Pseudowells/Pseudowell61': Well(petrel_name="Pseudowell61"), 'Input/Wells/Pseudowells/Pseudowell46': Well(petrel_name="Pseudowell46"), 'Input/Wells/Pseudowells/Pseudowell30': Well(petrel_name="Pseudowell30"), 'Input/Wells/Pseudowells/Pseudowell98': Well(petrel_name="Pseudowell98"), 'Input/Wells/Pseudowells/Pseudowell111': Well(petrel_name="Pseudowell111"), 'Input/Wells/Pseudowells/Pseudowell52': Well(petrel_name="Pseudowell52"), 'Input/Wells/Pseudowells/Pseudowell110': Well(petrel_name="Pseudowell110"), 'Input/Wells/Volve VS log prediction/15/9-F-15 D': Well(petrel_name="15/9-F-15 D"), 'Input/Wells/Pseudowells/Pseudowell25': Well(petrel_name="Pseudowell25")}
The cell above returned all the wells from the project in a dictionary where the keys represent the path of the well within the Petrel input tree (i.e Input/Wells/Injectors/C6 ) and the value represents the name of the well ( Well(petrel_name=”C6”) ). We can also retireve the well objects directly by using a list comprehension.

list_of_wells=[i for i in ptp.wells]
list_of_wells[:5] # This will display the first 5 items of the list. Note: Python index starts at 0
[Well(petrel_name="Pseudowell36"),
 Well(petrel_name="Copy of 15/9-19 A"),
 Well(petrel_name="15/9-F-1 A"),
 Well(petrel_name="15/9-F-5"),
 Well(petrel_name="Pseudowell53")]
We can then assign a well object to a Python variable ‘well’. Note: Python index starts at 0

well=list_of_wells[3]
well
Well(petrel_name="15/9-F-5")
Well objects have a set of properties and methods that are common to most of the supported Petrel objects.

Properties:

.comments

.crs_wkt

.droid

.path

.petrel_name

.read_only

.template

Methods:

.retrieve_history()

.retrieve_stats()

.set_petrel_name()

Properties that are unique to well objects are:

.compeletions_set

.is_sidetrack

.logs

.observed_data_sets

.spud_date

.surveys

.uwi

.well_datum

.well_symbol

.wellhead_coordinates

These are discussed further down in this user guide.

Accessing well data from the well object
You can access the logs, observed data sets, and well surveys of the well object.

Well logs
log_list=[i for i in well.logs]
log_list
[WellLog(petrel_name="NPHI"),
 WellLog(petrel_name="RHOB"),
 WellLog(petrel_name="VP"),
 WellLog(petrel_name="Gamma")]
You can then pass the list of logs into the method .logs_dataframe() to create a Pandas Dataframe containing the well logs.

well.logs_dataframe(log_list)
NPHI	RHOB	VP	Gamma	MD	TWT	TVDSS	TVD
0	NaN	NaN	NaN	NaN	421.175567	NaN	366.626309	420.626309
1	NaN	NaN	NaN	11.040	421.275665	NaN	366.725306	420.725306
2	NaN	NaN	NaN	11.040	421.375763	NaN	366.824303	420.824303
3	NaN	NaN	NaN	11.040	421.475861	NaN	366.923300	420.923300
4	NaN	NaN	NaN	11.040	421.575959	NaN	367.022297	421.022297
...	...	...	...	...	...	...	...	...
33673	0.1368	2.37	NaN	60.063	3791.775521	NaN	3192.295639	3246.295639
33674	0.1368	2.37	NaN	60.063	3791.875619	NaN	3192.356332	3246.356332
33675	0.1368	2.37	NaN	60.063	3791.975717	NaN	3192.417026	3246.417026
33676	0.1368	2.37	NaN	60.063	3792.075815	NaN	3192.477719	3246.477719
33677	NaN	NaN	NaN	NaN	3792.175913	NaN	3192.538413	3246.538413
33678 rows × 8 columns

Or you can assign a well log to a Python variable to work directly on the specific log data.

log=log_list[0]
log
WellLog(petrel_name="NPHI")
This is described in more detail in the user guide ‘Well logs’.

Observed data sets
Production data, in Petrel named observed data can be access with the property .observed_data_sets.

obs_list=[i for i in well.observed_data_sets]
obs_list
[]
obs=obs_list[0]
Working with observed data sets will be discussed in more detail in the user guide ‘Observed data’.

Well surveys
survey_list=[i for i in well.surveys]
survey_list
[WellSurvey(petrel_name="Surv")]
survey=survey_list[0]
Working with well surveys will be discussed in more detail in the user guide ‘Well surveys’.

Accessing well folders
Note: The ability to access well folders and to create Wells is a feature available Python Tool Pro version 2.3 or higher.

With Python Tool Pro version 2.3 we can now access the wells folders using the .well_folders property. This will retrun all the well folders from the project in a dictionary where the keys represent the path of the well folder within the Petrel input tree and the value represents the name of the folder.

ptp.well_folders
WellFolders({'Input/Wells/wellTops': WellFolder(petrel_name="wellTops"), 'Input/Wells/LAS import': WellFolder(petrel_name="LAS import"), 'Input/Wells/Gullfaks wells/Producers': WellFolder(petrel_name="Producers"), 'Input/Wells': WellFolder(petrel_name="Wells"), 'Input/Wells/Pseudowells': WellFolder(petrel_name="Pseudowells"), 'Input/Wells/Volve VS log prediction': WellFolder(petrel_name="Volve VS log prediction"), 'Input/Wells/Gullfaks wells/Injectors': WellFolder(petrel_name="Injectors"), 'Input/Wells/VelocityAnisotropy': WellFolder(petrel_name="VelocityAnisotropy"), 'Input/Wells/Gullfaks wells': WellFolder(petrel_name="Gullfaks wells")})
We can retrieve the Producers folder using a list comprehension which iterates over each well folder (el) returned by the .well_folders property. The condition el .petrel_name == ‘Producers’ checks if the petrel_name of the folder is equal to ‘Producers’. If the condition is true (i.e., the well folder has a petrel_name equal to ‘Producers’), the folder el is added to the new list wf.

well_folder=[el for el in ptp.well_folders if el.petrel_name=='Producers'][0]
well_folder
WellFolder(petrel_name="Producers")
The path of the folder can be returned using the .path property:

well_folder.path
'Input/Wells/Gullfaks wells/Producers'
The .petrel_name property returns the name of the folder:

well_folder.petrel_name
'Producers'
You .droid porperty returns the GUID of the folder:

well_folder.droid
'076c3186-156a-4d1c-903d-ca545d3d93eb'
You can retrieve the statistics of the folder using the .retrieve_stats() function:

well_folder.retrieve_stats()
{'   In this folder': '5',
 'Number of wells': '',
 'X Min': '456510.41',
 'Lat Min': '61.1630135',
 'Long Max': '2.21830902777778',
 'X Delta': '1426.81',
 'Z Delta': '2989.78',
 'Long Min': '2.19037675',
 'X Max': '457937.22',
 'Lat Max': '61.2185534166667',
 'Y Max': '6787544.54',
 'Z Min': '-2989.78',
 '   Includes sub folders': '5',
 'Number of well logs': '35',
 'Long Delta': '0.027932277777778',
 'Z Max': '0',
 'Y Delta': '6169.96999999974',
 'Y Min': '6781374.57',
 'Lat Delta': '0.0555399166666675'}
We can modify the readonly status of the folder by assigning it a True or False value. The default value is True.

well_folder.readonly=False
The .add_comment function will add a comment to the selected folder:

well_folder.add_comment('This folder has been modified by Python Tool Pro')
add_comment.png
The .comment property will return all the comments associated with the selected folder:

well_folder.comments
'This folder has been modified by Python Tool Pro'
Note: With Python Tool Pro version 2.5 or higher it is possible to retrieve the wells from a well folder object.

[i for i in well_folder.wells]
[Well(petrel_name="A10"),
 Well(petrel_name="A15"),
 Well(petrel_name="B8"),
 Well(petrel_name="A16"),
 Well(petrel_name="B9")]
The .get_wells() method can also be used to get a list of the wells in a Petrel folder. If the recursive flag is set to true, wells included in sub folders will also be included.

well_folder.get_wells(recursive=False)
[Well(petrel_name="A10"),
 Well(petrel_name="A15"),
 Well(petrel_name="B8"),
 Well(petrel_name="A16"),
 Well(petrel_name="B9")]
Note: With Python Tool Pro version 2.7 or higher it is possible to access saved searches and use them to filter a well folder

saved_search = ptp.saved_searches['Input/Wells/Saved searches/Saved search']

# Get wells in the folder that match the saved search
filtered_wells = well_folder.get_wells(recursive=True,saved_search=saved_search)
filtered_wells
[Well(petrel_name="A15"), Well(petrel_name="B8"), Well(petrel_name="B9")]
Create wells
If you want to learn more about creating wells check out the Create Well tutorial.

Main wells
Also new to the Python Tool Pro version 2.3 is the ability to create wells.

Creating a new well is a multi-step process which includes creating the well , setting the wellhead coordinates and setting the well datum.

We can create a well using the .create_well() function which takes in 2 parameters: the name of the well and the folder you want to place the well in:

new_well=ptp.create_well('New_well',well_folder)
new_well
Well(petrel_name="New_well")
We can set the wellhead coordinates of the new well using the .wellhead_coordinates property. Note that you use this property to change the wellhead coordinates on any existing well:

#Provide the X and Y values of the wellhead coordinates as a tuple (x,y)
new_well.wellhead_coordinates=(455029,6785991)
We can set the well datum of the new well using the .well_datum property and a tuple (name, offset, description). The description parameter is optional. You can use this property to change the elevation datum on any existing well. Note that each time you add a new well_datum it will add it to the list of datums in the well and set it active:

new_well.well_datum=("KB", 25, "Kelly Bushing")
The image bellow shows the settings pane of the newly created well. You can see the wellhead coordinates and the well datum which we set. Not that the well has no active survey. We’ll need to create a survey and calucate the trajectory. We’ll do that in the next section of this user guide (Working with well surveys).

new_well.png
The unique well identifier can be set using the property uwi.

Note: The ability to access unique well identifier is a feature available in Python Tool Pro version 2.5.

new_well.uwi = '10-02-2'
new_well.uwi
'10-02-2'
The spud date can be set using the property spud_date.

Note: The ability to access spud date is a feature available in Python Tool Pro version 2.6 or higher.

import datetime
new_well.spud_date=datetime.datetime(2020, 1, 1)
new_well.spud_date
datetime.datetime(2020, 1, 1, 0, 0)
The well symbol can be retrieved and set using the property well_symbol.

Note: The ability to access well symbol is a feature available in Python Tool Pro version 2.6 or higher.

new_well.well_symbol
WellSymbolDescription((0) Undefined)
ptp.available_well_symbols()
[WellSymbolDescription((0) Undefined),
 WellSymbolDescription((1) Proposed),
 WellSymbolDescription((2) Dry),
 WellSymbolDescription((3) Oil),
 WellSymbolDescription((4) Minor oil),
 WellSymbolDescription((5) Gas),
 WellSymbolDescription((6) Minor gas),
 WellSymbolDescription((7) Condensate),
 WellSymbolDescription((8) Platform),
 WellSymbolDescription((9) Abandoned oil and gas),
 WellSymbolDescription((10) Abandoned oil minor gas),
 WellSymbolDescription((11) Abandoned oil condensate),
 WellSymbolDescription((12) Abandoned gas residual oil),
 WellSymbolDescription((13) Abandoned gas condensate),
 WellSymbolDescription((14) Abandoned minor oil and gas),
 WellSymbolDescription((15) Injection water),
 WellSymbolDescription((16) Injection gas),
 WellSymbolDescription((17) Shallow borehole),
 WellSymbolDescription((18) Drilling well),
 WellSymbolDescription((19) Abandoned for techn. reasons),
 WellSymbolDescription((20) Temporarily abandoned),
 WellSymbolDescription((21) Plugged and abandoned),
 WellSymbolDescription((22) Not observed),
 WellSymbolDescription((23) Residual oil),
 WellSymbolDescription((24) Proposed platform),
 WellSymbolDescription((25) Subsea installation),
 WellSymbolDescription((26) Dry, plugged and abandoned),
 WellSymbolDescription((27) Oil, plugged and abandoned),
 WellSymbolDescription((28) Gas, plugged and abandoned),
 WellSymbolDescription((29) Condensate, plugged and abandoned),
 WellSymbolDescription((30) Oil, temp. abandoned),
 WellSymbolDescription((31) Gas, temp. abandoned),
 WellSymbolDescription((32) Gas, residual oil),
 WellSymbolDescription((33) Minor gas, residual oil),
 WellSymbolDescription((34) Dual completion oil),
 WellSymbolDescription((35) Dual completion gas),
 WellSymbolDescription((36) Dual completion oil and gas),
 WellSymbolDescription((37) Planned water injector),
 WellSymbolDescription((38) Planned gas injector),
 WellSymbolDescription((39) Minor oil, plugged and abandoned),
 WellSymbolDescription((40) Minor gas, plugged and abandoned),
 WellSymbolDescription((41) Minor oil and gas, plugged and abandoned),
 WellSymbolDescription((42) Gas condensate, plugged and abandoned),
 WellSymbolDescription((43) Gas condensate, temp. abandoned),
 WellSymbolDescription((44) Well impact),
 WellSymbolDescription((45) Closed oil producer),
 WellSymbolDescription((46) Open oil producer),
 WellSymbolDescription((47) Open water injector),
 WellSymbolDescription((48) Closed water injector),
 WellSymbolDescription((49) Surface location),
 WellSymbolDescription((50) Permitted),
 WellSymbolDescription((51) Water source),
 WellSymbolDescription((52) Oil, minor gas),
 WellSymbolDescription((53) Oil minor gas, temp. abandoned),
 WellSymbolDescription((54) Oil and gas, temp. abandoned),
 WellSymbolDescription((55) Injection steam),
 WellSymbolDescription((56) Injection LPG),
 WellSymbolDescription((57) Injection-production water),
 WellSymbolDescription((58) Injection-production steam),
 WellSymbolDescription((59) Injection-production LPG),
 WellSymbolDescription((308) Relief well)]
new_well_symbol=[i for i in ptp.available_well_symbols()][5]
new_well.well_symbol=new_well_symbol
new_well.well_symbol
WellSymbolDescription((5) Gas)
Sidetracks
Similarly, we can also use the .create_sidetrack() function on an existing well to create a sidetrack well.

Note: In Python Tool Pro 2.6 .create_sidetrack() replaces .create_lateral(). The method .create_lateral() is now deprecated and will be removed in Python Tool Pro 2.7.

Sidetrack=new_well.create_sidetrack('Sidetrack')
Sidetrack
Well(petrel_name="Sidetrack")
Note that you can not set the wellhead coordinates and well datum on lateral wells. These properties are inherited from the main well used to create the sidetrack. The image bellow shows the newly created sidetrack well in Petrel:

lateral.png
You can check if a well is a lateral well or not using the is_sidetrack property which returns a boolean value (False if the well is a main well, True if a well is a sidetrack well).

Note: In Python Tool Pro 2.6 .is_sidetrack replaces .is_lateral. THe property .is_lateral is now deprecated and will be removed in Python Tool Pro 2.7

print(new_well.is_sidetrack)
print(Sidetrack.is_sidetrack)
False
True
=================
Well logs
This section offers an overview of the different methods and attributes available for the Petrel well object subcategories.

from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection()
Working with well Logs
Python Tool Pro has 4 classes which allow users to work with well logs:

cegalprizm.pythontool.WellLog -> a class holding information about continuous well logs

cegalprizm.pythontool.DiscreteWellLog -> a class holding information about discrete well logs

cegalprizm.pythontool.GlobalWellLog -> a class holding information about global continuous well logs

cegalprizm.pythontool.DiscreteGlobalWellLog -> a class holding information about global discrete well logs

Check out the API documentation to view a detailed description of all the functions and properties available for working with well logs:

Continuous well logs

Continuous global well logs

Discrete well logs

Discrete global well logs

We can retrieve all the continuous logs belonging to all the wells using the .well_logs property which will return a dictionary where the key represents the path of the well log within the Petrel input tree and the value represents the well log name:

ptp.well_logs
WellLogs({'Input/Wells/Gullfaks wells/Producers/A10/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Gullfaks wells/Producers/B8/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-F-11 B/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Gullfaks wells/Producers/A16/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Gullfaks wells/Producers/A10/Well logs/Porosity_smooth_bartlett_80': WellLog(petrel_name="Porosity_smooth_bartlett_80"), 'Input/Wells/Volve VS log prediction/15/9-F-4/Well logs/VS': WellLog(petrel_name="VS"), 'Input/Wells/Gullfaks wells/Injectors/C6/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Gullfaks wells/Injectors/C5/Well logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Gullfaks wells/Injectors/C4/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Gullfaks wells/Producers/A10/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 SR/Well logs/Vs final brine_case': WellLog(petrel_name="Vs final brine_case"), 'Input/Wells/Volve VS log prediction/15/9-F-1 A/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Volve VS log prediction/15/9-F-15 C/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Volve VS log prediction/15/9-F-1 B/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Gullfaks wells/Injectors/C6/Well logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Gullfaks wells/Injectors/C2/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-F-5/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Volve VS log prediction/15/9-F-10/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Gullfaks wells/Producers/A15/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Gullfaks wells/Injectors/C2/Well logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Gullfaks wells/Producers/A15/Well logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Volve VS log prediction/15/9-19 A/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-19 SR/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Gullfaks wells/Injectors/C3/Well logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Volve VS log prediction/15/9-F-1 A/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 A/Well logs/VSH': WellLog(petrel_name="VSH"), 'Input/Wells/Gullfaks wells/Producers/B8/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-4/Well logs/VSH': WellLog(petrel_name="VSH"), 'Input/Wells/Volve VS log prediction/15/9-F-4/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 A/Well logs/Vp final brine_case': WellLog(petrel_name="Vp final brine_case"), 'Input/Wells/Volve VS log prediction/15/9-19 BT2/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Gullfaks wells/Producers/B8/Well logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Volve VS log prediction/15/9-19 SR/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Gullfaks wells/Producers/B9/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-F-15 C/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-F-11 A/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 SR/Well logs/Vp final brine_case': WellLog(petrel_name="Vp final brine_case"), 'Input/Wells/Gullfaks wells/Injectors/C5/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Gullfaks wells/Injectors/C5/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 A/Well logs/Rho final brine_case': WellLog(petrel_name="Rho final brine_case"), 'Input/Wells/Volve VS log prediction/15/9-F-14/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Volve VS log prediction/15/9-F-15 A/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Volve VS log prediction/15/9-F-1/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Volve VS log prediction/15/9-F-15/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-F-1 C/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-19 SR/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-4/Well logs/Vp final brine_case': WellLog(petrel_name="Vp final brine_case"), 'Input/Wells/Volve VS log prediction/15/9-F-1 A/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Gullfaks wells/Producers/A16/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Volve VS log prediction/15/9-F-15/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Gullfaks wells/Injectors/C6/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Gullfaks wells/Producers/A10/Well logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Volve VS log prediction/15/9-F-15 C/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Volve VS log prediction/15/9-F-14/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 A/Well logs/PHIE': WellLog(petrel_name="PHIE"), 'Input/Wells/Gullfaks wells/Producers/A15/Well logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Gullfaks wells/Injectors/C4/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-4/Well logs/PHIE': WellLog(petrel_name="PHIE"), 'Input/Wells/Volve VS log prediction/15/9-F-14/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Gullfaks wells/Injectors/C3/Well logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Volve VS log prediction/15/9-F-5/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Volve VS log prediction/15/9-F-12/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 SR/Well logs/Rho final brine_case': WellLog(petrel_name="Rho final brine_case"), 'Input/Wells/Volve VS log prediction/15/9-F-1 A/Well logs/VS': WellLog(petrel_name="VS"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-11 A/Well logs/Vp final brine_case': WellLog(petrel_name="Vp final brine_case"), 'Input/Wells/Volve VS log prediction/15/9-F-15 D/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Volve VS log prediction/15/9-F-1 B/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Gullfaks wells/Producers/A10/Well logs/Porosity_smooth_barthann_80': WellLog(petrel_name="Porosity_smooth_barthann_80"), 'Input/Wells/Volve VS log prediction/15/9-F-15 A/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-F-5/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-F-15 C/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Volve VS log prediction/15/9-F-12/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Gullfaks wells/Injectors/C3/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-F-1 A/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Gullfaks wells/Producers/A15/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Gullfaks wells/Injectors/C4/Well logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Gullfaks wells/Producers/A16/Well logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Volve VS log prediction/15/9-F-15 A/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Gullfaks wells/Producers/A10/Well logs/Porosity_smooth_hann_80': WellLog(petrel_name="Porosity_smooth_hann_80"), 'Input/Wells/Volve VS log prediction/15/9-F-1/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-11 A/Well logs/PHIE': WellLog(petrel_name="PHIE"), 'Input/Wells/Volve VS log prediction/15/9-F-15 B/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Gullfaks wells/Injectors/C6/Well logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Gullfaks wells/Producers/B9/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Gullfaks wells/Producers/B8/Well logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Volve VS log prediction/15/9-F-11 A/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-F-14/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Volve VS log prediction/15/9-F-14/Well logs/VS': WellLog(petrel_name="VS"), 'Input/Wells/Volve VS log prediction/15/9-F-5/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Gullfaks wells/Injectors/C5/Well logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Gullfaks wells/Producers/A16/Well logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Volve VS log prediction/15/9-F-15/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Gullfaks wells/Injectors/C2/Well logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Volve VS log prediction/15/9-F-11 A/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Volve VS log prediction/15/9-F-1 C/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-11 A/Well logs/VSH': WellLog(petrel_name="VSH"), 'Input/Wells/Volve VS log prediction/15/9-F-15/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Gullfaks wells/Injectors/C4/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-11 A/Well logs/Vs final brine_case': WellLog(petrel_name="Vs final brine_case"), 'Input/Wells/Volve VS log prediction/15/9-F-11 A/Well logs/VS': WellLog(petrel_name="VS"), 'Input/Wells/Gullfaks wells/Injectors/C3/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Gullfaks wells/Producers/A10/Well logs/Porosity_smooth_cosine_80': WellLog(petrel_name="Porosity_smooth_cosine_80"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-4/Well logs/Vs final brine_case': WellLog(petrel_name="Vs final brine_case"), 'Input/Wells/Volve VS log prediction/15/9-F-11 A/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Volve VS log prediction/15/9-F-12/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Volve VS log prediction/15/9-F-15 D/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Gullfaks wells/Producers/B9/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 SR/Well logs/PHIE': WellLog(petrel_name="PHIE"), 'Input/Wells/Volve VS log prediction/15/9-19 BT2/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Volve VS log prediction/15/9-F-15 A/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Volve VS log prediction/15/9-19 BT2/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Gullfaks wells/Producers/A10/Well logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Volve VS log prediction/15/9-F-1 C/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Volve VS log prediction/15/9-F-11 B/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Gullfaks wells/Producers/A15/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Gullfaks wells/Injectors/C5/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Gullfaks wells/Producers/A16/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Volve VS log prediction/15/9-19 SR/Well logs/VS': WellLog(petrel_name="VS"), 'Input/Wells/Volve VS log prediction/15/9-F-1/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Volve VS log prediction/15/9-F-4/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-F-12/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Gullfaks wells/Injectors/C6/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-11 A/Well logs/Rho final brine_case': WellLog(petrel_name="Rho final brine_case"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 A/Well logs/Vs final brine_case': WellLog(petrel_name="Vs final brine_case"), 'Input/Wells/Volve VS log prediction/15/9-F-15 B/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Volve VS log prediction/15/9-F-1 B/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Gullfaks wells/Producers/A10/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Gullfaks wells/Producers/B8/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Volve VS log prediction/15/9-F-1/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Volve VS log prediction/15/9-19 BT2/Well logs/VS': WellLog(petrel_name="VS"), 'Input/Wells/Volve VS log prediction/15/9-19 BT2/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Gullfaks wells/Injectors/C4/Well logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Volve VS log prediction/15/9-F-10/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 SR/Well logs/VSH': WellLog(petrel_name="VSH"), 'Input/Wells/Gullfaks wells/Producers/B9/Well logs/Perm': WellLog(petrel_name="Perm"), 'Input/Wells/Volve VS log prediction/15/9-F-4/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Volve VS log prediction/15/9-F-1 B/Well logs/VS': WellLog(petrel_name="VS"), 'Input/Wells/Volve VS log prediction/15/9-F-10/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/Volve VS log prediction/15/9-F-15 B/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Gullfaks wells/Producers/A10/Well logs/Porosity_smooth_blackman_80': WellLog(petrel_name="Porosity_smooth_blackman_80"), 'Input/Wells/Volve VS log prediction/15/9-F-15 D/Well logs/RHOB': WellLog(petrel_name="RHOB"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-4/Well logs/Rho final brine_case': WellLog(petrel_name="Rho final brine_case"), 'Input/Wells/Volve VS log prediction/15/9-F-15 B/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Gullfaks wells/Injectors/C2/Well logs/Porosity': WellLog(petrel_name="Porosity"), 'Input/Wells/Gullfaks wells/Producers/B9/Well logs/NetGross': WellLog(petrel_name="NetGross"), 'Input/Wells/Gullfaks wells/Injectors/C3/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Volve VS log prediction/15/9-F-4/Well logs/NPHI': WellLog(petrel_name="NPHI"), 'Input/Wells/Volve VS log prediction/15/9-F-11 B/Well logs/Gamma': WellLog(petrel_name="Gamma"), 'Input/Wells/Volve VS log prediction/15/9-19 SR/Well logs/VP': WellLog(petrel_name="VP"), 'Input/Wells/Gullfaks wells/Injectors/C2/Well logs/One-way time 1': WellLog(petrel_name="One-way time 1"), 'Input/Wells/Volve VS log prediction/15/9-F-1 B/Well logs/VP': WellLog(petrel_name="VP")})
We can use widgets to navigate through different wells and explore the available logs:

import ipywidgets as widgets
well_names = sorted(list(petrel.wells.keys()))
well_name_widget = widgets.Dropdown(
    options=well_names,
    value=well_names[0],
    description='Select well:',
    disabled=False,
)
display(well_name_widget)
Alternatively, we can just assign a particular well to a variable:

well_list=sorted(list(ptp.wells.keys()))
well_A10= well_list[5]
print(well_A10)
Input/Wells/Gullfaks wells/Producers/A10
We can assign all the logs available for well A10 to a variable and by using a nested list we can print out their name:

well=ptp.wells[well_A10]
logs = well.logs
print(', '.join([log.petrel_name for log in logs]))
Gamma, NetGross, Perm, Porosity, One-way time 1, Porosity_smooth_blackman_80, Porosity_smooth_cosine_80, Porosity_smooth_barthann_80, Porosity_smooth_bartlett_80, Porosity_smooth_hann_80, Facies
We can also assign all the well logs to a list:

from cegalprizm.pythontool.welllog import WellLog
A10cont_logs = [log for log in well.logs if type(log) is WellLog]
print(A10cont_logs)
[WellLog(petrel_name="Gamma"), WellLog(petrel_name="NetGross"), WellLog(petrel_name="Perm"), WellLog(petrel_name="Porosity"), WellLog(petrel_name="One-way time 1"), WellLog(petrel_name="Porosity_smooth_blackman_80"), WellLog(petrel_name="Porosity_smooth_cosine_80"), WellLog(petrel_name="Porosity_smooth_barthann_80"), WellLog(petrel_name="Porosity_smooth_bartlett_80"), WellLog(petrel_name="Porosity_smooth_hann_80")]
To determine which global well log the selected log belongs to, we can use the .global_well_log property:

A10cont_logs[1].global_well_log
GlobalWellLog(petrel_name="NetGross")
The .well property allows users to check which well the selected log belongs to:

A10cont_logs[2].well
Well(petrel_name="A10")
To check the Petrel template of a particular log, we can use the .template property:

A10cont_logs[2].template
'Permeability'
Similarly, using the .unit_symbol attribute, we can access the unit for any object associated with a certain template:

symbol=A10cont_logs[2].unit_symbol
"The unit_symbol for the log {} is {}".format(A10cont_logs[2].petrel_name,symbol)
'The unit_symbol for the log Perm is mD'
Different projects use different standard values to mark missing values. To check the value interpreted by Petrel as a ‘missing’ one we can use the .missing_value property:

A10cont_logs[2].missing_value
nan
To get all the continuous wells logs associated to well A10, interpolated at the same depth in a dataframe we can use the .logs_dataframe() function:

A10logs_df = well.logs_dataframe(A10cont_logs)

# Sets MD as index
A10logs_df = A10logs_df.set_index('MD')
A10logs_df
Gamma	NetGross	Perm	Porosity	One-way time 1	TWT	TVD
MD							
-527.621008	NaN	NaN	NaN	NaN	NaN	-510.664881	-527.621008
-527.121008	NaN	NaN	NaN	NaN	0.0	-510.180839	-527.121008
-526.621008	NaN	NaN	NaN	NaN	0.0	-509.696796	-526.621008
-526.121008	NaN	NaN	NaN	NaN	0.0	-509.212754	-526.121008
-525.621008	NaN	NaN	NaN	NaN	0.0	-508.728711	-525.621008
...	...	...	...	...	...	...	...
2413.878992	75.862561	0.0	105.309330	0.173314	NaN	2037.715005	2413.878992
2414.378992	75.399295	0.0	103.075364	0.177510	NaN	2038.055903	2414.378992
2414.878992	NaN	0.0	NaN	NaN	NaN	2038.396801	2414.878992
2415.378992	NaN	0.0	NaN	NaN	NaN	2038.737699	2415.378992
2415.878992	NaN	0.0	NaN	NaN	NaN	2039.078597	2415.878992
5888 rows × 7 columns

Note: .logs_dataframe() resamples the logs to match into one DataFrame. In cases with irregular sample intervals not all values from the log might be shown in the DataFrame.

In most use cases you will be working with multiple well logs and it is recommended to use the method .logs_dataframe() for this. But you might want to work on a specific well log. In this case you can assign a well log object to a Python variable.

single_log=[i for i in well.logs][0]
single_log
WellLog(petrel_name="Gamma")
The method .as_dataframe() on a log object creates a Pandas DataFrame without any resampling.

single_log.as_dataframe()
X	Y	Z	MD	TWT	TVDSS	TVD	Value
0	456979.0637	6782712.412	-1499.879	1499.879	1450.620034	1499.879	1499.879	NaN
1	456979.0637	6782712.412	-1500.129	1500.129	1450.861360	1500.129	1500.129	NaN
2	456979.0637	6782712.412	-1500.629	1500.629	1451.344012	1500.629	1500.629	NaN
3	456979.0637	6782712.412	-1501.129	1501.129	1451.826664	1501.129	1501.129	NaN
4	456979.0637	6782712.412	-1501.629	1501.629	1452.309315	1501.629	1501.629	78.869453
...	...	...	...	...	...	...	...	...
1830	456979.0637	6782712.412	-2414.629	2414.629	2038.226358	2414.629	2414.629	75.363716
1831	456979.0637	6782712.412	-2415.129	2415.129	2038.567256	2415.129	2415.129	NaN
1832	456979.0637	6782712.412	-2415.629	2415.629	2038.908154	2415.629	2415.629	NaN
1833	456979.0637	6782712.412	-2416.129	2416.129	2039.249052	2416.129	2416.129	NaN
1834	456979.0637	6782712.412	-2416.379	2416.379	2039.419501	2416.379	2416.379	NaN
1835 rows × 8 columns

In Python Tool Pro version 2.6 or higher it is also possible to retrieve the log values as an array or a tuple.

single_log.as_array()
array([nan, nan, nan, ..., nan, nan, nan])
single_log.as_tuple(depth_index='MD')
(array([1499.879, 1500.129, 1500.629, ..., 2415.629, 2416.129, 2416.379]),
 array([nan, nan, nan, ..., nan, nan, nan]))
As_tuple returns a tuple containing two one-dimensional NumPy arrays with the depth_index and the log values. By default the depth index is set to ‘MD’ but can be set to ‘MD’, ‘TWT’, ‘TVDSS’, ‘TVD’.

The .create_well_log() function creates a well log for a particular well and assigns this log to a specific global well log. The function takes in one parmeter which represents the well object for which the well log is to be created. The function will output an empty well log with no values assigned to it. The difference between this function and the .clone() one is that when using the .clone() function to create a new well log for a well it will also generate a new global well log which is not always ideal .

#Assign the log we want to copy to a variable

new_log=A10cont_logs[3].global_well_log
print(new_log)
GlobalWellLog(petrel_name="Porosity")
#Assign the well we want to generate the new log for to a variable

all_wells_paths=ptp.wells.keys()
paths = list(all_wells_paths)
well15 = ptp.wells[paths[8]]
print(well15)
Well(petrel_name="A15")
#Create a porosity log for well 15 and assign it to the porosity global well log

new_log.create_well_log(well15)
WellLog(petrel_name="Porosity")
The image bellow shows the output of the previous cell. A new porosity log has been created for well 15. Note that the log has no depth or porosity values and it is assigned to the porosity global well log:

createwelllog.png
All the previous examples can be reproduced with discrete logs as most of the attributes and methods are common to all the classes. Let’s select well C2:

from cegalprizm.pythontool.welllog import DiscreteWellLog


well_list=sorted(list(ptp.wells.keys()))
well_C2= well_list[0]
print(well_C2)
Input/Wells/Injectors/C2
Print out the associated discrete logs:

well=ptp.wells[well_C2]
logs = well.logs
discrete_logs = [log for log in logs if type(log) is DiscreteWellLog]
print("Well C2 has", len(discrete_logs), "discrete logs:", "\n")
print(', '.join([log.petrel_name for log in logs if type(log) is DiscreteWellLog]))

Well C2 has 1 discrete logs:

Facies
Create a DataFrame of the discrete logs in well C2:

C2Facies = well.logs_dataframe(discrete_logs[0])

# Sets MD as index
C2Facies = C2Facies.set_index('MD')
C2Facies
Facies	TWT	TVD
MD			
1923.907229	Silt	1824.370861	1924.172392
1928.714834	Sand	1827.628075	1927.607736
1932.181133	Fine Silt	1829.594166	1930.084630
1934.049920	Silt	1830.615324	1931.419999
1935.391227	Sand	1831.348252	1932.378449
...	...	...	...
2448.439087	Clay	2099.553700	2270.344903
2450.193287	Sand	2100.467339	2271.430009
2457.978592	Clay	2104.503249	2276.222562
2473.757075	UNDEF	2112.599674	2285.837806
2476.379880	UNDEF	2113.944556	2287.435320
89 rows × 3 columns

The .discrete_codes property returns a dictionary of discrete codes as keys and the associated facies as values. Changes to this dictionary will not be persisted or affect any Petrel objects:

facies_codes.png
discrete_logs[0].discrete_codes
{0: 'Clay', 1: 'Sand', 2: 'Silt', 3: 'Fine Silt'}
We can retrieve the statics of the Facies log associate with well C2 by using the .retrieve_stats() function:

Faciesstatistic.png
discrete_logs[0].retrieve_stats()
{'X Min': '454635',
 'X Max': '455033.33',
 'X Delta': '398.330000000016',
 'Y Min': '6787607.12',
 'Y Max': '6787607.12',
 'Y Delta': '0',
 'Z Min': '-2283.72',
 'Z Max': '-1924.84',
 'Z Delta': '358.88',
 'Facies Min': '0',
 'Facies Max': '3',
 'Facies Delta': 'NaN',
 'Is synthetic': 'No',
 'Start md': '1923.90722924',
 'Base md': '2476.37988030',
 'Average md increment': '6.27809831',
 'Number of defined samples': '87',
 '-----------------': '-----------------',
 'Type of data': 'Discrete',
 'Min': '0',
 'Max': '3',
 'Delta': '3',
 'Number of defined values': '1100',
 'Mean': '1',
 'Std. dev.': '1',
 'Variance': '1',
 'Sum': '970'}
To create a copy of the Facies log associated to well C2, we can use the .clone() function. The clone is placed in the same collection as the source object. A clone cannot be created with the same name as an existing Petrel object in the same collection.

discrete_logs[0].clone('newFaciesLog', copy_values=True)
DiscreteWellLog(petrel_name="newFaciesLog")
Creating Global Well Log
With the release of Python Tool Pro 2.8, a new method, create_global_well_log(), allows users to create continuous or discrete Global Well Logs. Logs can be created in the root Global Well Log Folder or in a specific subfolder by providing the folder argument. Note that support for Global Well Logs folders has also been added in Python Tool Pro 2.8.

If no name, data type, or template is provided, a continuous global well log with a default template and auto-generated name is created. The method supports both string and NumericDataTypeEnum inputs for the data_type parameter.

from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()

# Create a new continuous GWL
new_log = petrel.create_global_well_log("MyNewGlobalLog")
new_log
GlobalWellLog(petrel_name="MyNewGlobalLog")
from cegalprizm.pythontool import NumericDataTypeEnum

# Retrieve the discrete facies log
disc_template = petrel.discrete_templates.get_by_name("Facies")

# Create a new discrete GWL
new_disc = petrel.create_global_well_log(
    "MyNewDiscreteLog",
    NumericDataTypeEnum.Discrete,
    template=disc_template,
)
new_disc
DiscreteGlobalWellLog(petrel_name="MyNewDiscreteLog")
image.png
====
Well surveys
from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection()
Working with well surveys
Check out the API documentation to view a detailed description of all the functions and properties available for working with well surveys.

To return all surveys as a dictionary with names and paths we can use the .well_surveys property:

ptp.well_surveys
WellSurveys({'Input/Wells/Pseudowells/Pseudowell88/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell11/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-11 A/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/wellTops/35/9-8/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell72/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/16/7-6/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell89/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell67/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell21/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell79/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell4/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell22/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell37/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell86/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell35/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell59/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell103/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/34/3-3 A/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Volve VS log prediction/15/9-F-1 C/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell20/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell31/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell23/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-5/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell66/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell9/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-19 SR/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell102/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell57/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell50/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell45/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell81/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell0/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell73/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell119/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell85/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-15 B/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell58/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell12/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell13/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell38/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/34/3-2 S/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell109/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell56/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell83/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell24/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-15/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell62/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/17/4-1/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell14/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-19 A/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell71/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-11 B/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/wellTops/35/9-7/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell106/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell69/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell96/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell77/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell91/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell30/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell18/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell108/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell60/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell2/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell64/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell28/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/empty/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/wellTops/34/10-16 R/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/wellTops/31/2-10/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/wellTops/25/5-3/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell15/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-1 B/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell5/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/35/6-2 S/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/wellTops/15/9-14/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell3/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell101/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell63/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell87/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell93/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell115/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-15 A/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/wellTops/31/2-21 S/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell117/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell19/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell17/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-1 A/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell8/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell40/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-14/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell1/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell113/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell10/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell48/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell55/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell74/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell44/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-15 D/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell98/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell34/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell54/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell107/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/25/10-9/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell105/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-4/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Volve VS log prediction/15/9-F-10/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell78/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/15/9-23/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell111/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell68/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell99/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell104/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell49/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell33/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell70/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/25/11-24/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell29/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell53/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell51/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/34/6-1 S/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell75/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell32/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/16/2-7/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell25/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-15 C/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell110/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-19 BT2/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell76/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell47/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell116/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell46/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell90/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell27/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell43/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell39/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell36/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell65/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Volve VS log prediction/15/9-F-12/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/wellTops/29/3-1/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Volve VS log prediction/15/9-F-1/Surv': WellSurvey(petrel_name="Surv"), 'Input/Wells/Pseudowells/Pseudowell114/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell42/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell92/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell61/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell16/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell95/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell6/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/35/11-5/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell80/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell26/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell52/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell100/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell112/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell82/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell118/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell84/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell41/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell94/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/wellTops/25/10-10/NPD': WellSurvey(petrel_name="NPD"), 'Input/Wells/Pseudowells/Pseudowell97/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/Pseudowells/Pseudowell7/Pseudo surv': WellSurvey(petrel_name="Pseudo surv"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-11 A/Copy of MD Incl Azim survey 1': WellSurvey(petrel_name="Copy of MD Incl Azim survey 1"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 A/Copy of MD Incl Azim survey 2': WellSurvey(petrel_name="Copy of MD Incl Azim survey 2"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-19 SR/Copy of MD Incl Azim survey 2': WellSurvey(petrel_name="Copy of MD Incl Azim survey 2"), 'Input/Wells/Gullfaks wells/Producers/A10/NewWellSurveyName': WellSurvey(petrel_name="NewWellSurveyName"), 'Input/Wells/VelocityAnisotropy/Copy of 15/9-F-4/Copy of MD Incl Azim survey 1': WellSurvey(petrel_name="Copy of MD Incl Azim survey 1"), 'Input/Wells/Gullfaks wells/Producers/A10/Survey_A10_demo': WellSurvey(petrel_name="Survey_A10_demo"), 'Input/Wells/Gullfaks wells/Producers/B8/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Injectors/C4/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Injectors/C5/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Producers/B9/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Injectors/C6/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Injectors/C3/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Injectors/C2/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Producers/A15/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Producers/A16/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1"), 'Input/Wells/Gullfaks wells/Producers/A10/Explicit survey 1': WellSurvey(petrel_name="Explicit survey 1")})
Similarly, we can iterate trough the dictionary and return all the values of it:

for w in ptp.well_surveys:
    print(w)
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="NPD")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Pseudo surv")
WellSurvey(petrel_name="Copy of MD Incl Azim survey 1")
WellSurvey(petrel_name="Copy of MD Incl Azim survey 2")
WellSurvey(petrel_name="Copy of MD Incl Azim survey 2")
WellSurvey(petrel_name="NewWellSurveyName")
WellSurvey(petrel_name="Copy of MD Incl Azim survey 1")
WellSurvey(petrel_name="Survey_A10_demo")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
WellSurvey(petrel_name="Explicit survey 1")
Let’s select the Survey_A10_demo:

all_well_surveys = ptp.well_surveys
paths = list(all_well_surveys.keys())
well_survey = ptp.well_surveys[paths[0]]
print(well_survey)
WellSurvey(petrel_name="Pseudo surv")
Using the .azimuth_reference we can obtain the azimuth reference for well survey types of MD inclination azimuth survey and DX DY TVD survey:

well_survey.azimuth_reference
'Grid north'
The .record_count will return the amount of trajectory points as defined in Petrel trajectory spreadsheet for selected well survey:

recordcount2.png
well_survey.record_count
2
We can load the trajectory spreadsheet into a DataFrame using the .as_dataframe() method:

well_survey_df = well_survey.as_dataframe()
well_survey_df
X	Y	Z	MD	Inclination	Azimuth GN
0	456979.0637	6782712.412	-0.0	0.0	0.0	0.0
1	456979.0637	6782712.412	-1000.0	1000.0	0.0	0.0
Determine the well survey type
Petrel well surveys can be of 5 different types. They are: * ‘X Y Z survey’ * ‘X Y TVD survey’ * ‘DX DY TVD survey’ * ‘MD inclination azimuth survey’ * ‘Explicit survey’

Python Tool Pro does not differentiate different well surveys type when retrieving the list of well surveys. But once you retrieve a specific well survey, the type is checked. You can find out the survey type by using the method well_survey_type:

wellsurveytype.png
well_survey.well_survey_type
'X Y Z survey'
Since a well can have several surveys available, users can check if a survey is set as definitive and select which one to use with the .set_survey_as_definitive() function:

Note: The property is_definitive is available in Python Tool Pro version 2.6 or higher

well_survey.is_definitive
True
well_survey.set_survey_as_definitive()
Lateral well surveys will have a tie in point with another well survey. This can be printed by using the tie_in_md property:

PetrelPathToLateralWellSurvey=""
lateral_well_survey=ptp.well_surveys[PetrelPathToLateralWellSurvey]
lateral_well_survey.tie_in_md
You can create a new well survey with the clone function. Using the flag copy_values=False Python Tool Pro will create a new well survey with no trajectory:

well_survey.clone('NewWellSurveyName', copy_values=False)
WellSurvey(petrel_name="NewWellSurveyName")
The results are written back to Petrel in real time. Notice that the newly created survey has no values:

cloneSurvey.png
Creating well surveys
Note: The ability to create well surveys is a feature available Python Tool Pro version 2.3.

We can create a new well survey using the .create_well_survey property on a main well and specifing the name of the new survey and the type of the survey:

# select a well
well=[i for i in ptp.wells][0]
well.readonly=False
[i for i in well.surveys]
[WellSurvey(petrel_name="Pseudo surv")]

# create new survey
new_well_survey=well.create_well_survey('New Survey','X Y Z survey' )
new_well_survey
WellSurvey(petrel_name="New Survey")
In Python Tool Pro version 2.6 or higher it is possible to retrieve the well survey object by name.

well.surveys["New Survey"]
WellSurvey(petrel_name="New Survey")
The image bellow shows the newly created survey in Petrel. Note the trajectory calculation failed as the survey has no records:

failed_trajectory.png
We can set some values to the survey and calculate the trajectory. First we set the readonly status of the new well survey to false so we can modify it.

We can select the algorithm used in the trajectory calculation using the .algorithm property. The avialabe algorithms are : Minimum Curvature and Linearization.

Next we set the values to the survey using the .set() function and provide lists of x and y and z values. In the example bellow we are using the X and Y values from the wellhead coordinates to add 2 points in the survey record. As both values of X and Y are identical the well will be straight.

Lastly, we set this survey as the active one using the .set_survey_as_definitive() function.

new_well_survey.readonly=False
new_well_survey.algorithm='Minimum curvature'
new_well_survey.set(xs=[new_well.wellhead_coordinates[0],new_well.wellhead_coordinates[0]], ys=[new_well.wellhead_coordinates[1],new_well.wellhead_coordinates[1]], zs=[0,-2500])
new_well_survey.set_survey_as_definitive()
The image bellow shows the trajectory calculation of the new well survey in Petrel :

calculation_ok.png
To create a survey for lateral wells we need to use the .create_sidetrack_well_survey() function and besides the survey name and type we also need to provide the well survey of the main well and the kick-off point.

Note: In Python Tool Pro 2.6 .create_lateral_well_survey() is replaced with .create_sidetrack_well_survey(). The method .create_lateral_well_survey() is now deprecated and will be removed in Python Tool Pro 2.7.

sidetrack_well=ptp.wells['Input/Wells/Producers/Sidetrack']
new_s=sidetrack_well.create_sidetrack_well_survey('sidetrack_survey','X Y Z survey',new_well.surveys[0],1500)
We can now set the survey values just how we did it for the main well:

new_s.readonly=False
new_s.algorithm='Minimum curvature'
new_s.set(xs=[455044.36],ys=[6785316.41],zs=[-1960])
new_s.set_survey_as_definitive()
The image bellow shows the trajectory calculation the lateral well:

lateral_traj.png
==================
Well Attributes
Note: Support for working with well attributes was introduced in Python Tool Pro 2.7.

This guide explains how to access, create, and modify well attributes in Python Tool Pro. Check out the API documentation to view a detailed description of all the functions and properties available for working with well attributes.

Important:

Well attribute support is currently an experimental feature. You must create your Petrel connection with allow_experimental=True.

Connect to a Petrel project
from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection(allow_experimental=True)
Accessing Well Attributes
You can access all available well attributes in the project using the .well_attributes property on the Petrel connection. The keys of the dictionary represents the path to the attribute in the Petrel input tree and the value represents the attribute object.

attributes = petrel.well_attributes
attributes
WellAttributes({'Input/Wells/Well Attributes/Completed date': WellAttribute(petrel_name="Completed date"), 'Input/Wells/Well Attributes/Drilling structure': WellAttribute(petrel_name="Drilling structure"), 'Input/Wells/Well Attributes/TWT auto': WellAttribute(petrel_name="TWT auto"), 'Input/Wells/Well Attributes/UWI': WellAttribute(petrel_name="UWI"), 'Input/Wells/Well Attributes/Max inc': WellAttribute(petrel_name="Max inc"), 'Input/Wells/Well Attributes/Z': WellAttribute(petrel_name="Z"), 'Input/Wells/Well Attributes/Well datum value': WellAttribute(petrel_name="Well datum value"), 'Input/Wells/Well Attributes/Uncertainty radius': WellAttribute(petrel_name="Uncertainty radius"), 'Input/Wells/Well Attributes/Subsea': WellAttribute(petrel_name="Subsea"), 'Input/Wells/Well Attributes/Simulation name': WellAttribute(petrel_name="Simulation name"), 'Input/Wells/Well Attributes/Production licence': WellAttribute(petrel_name="Production licence"), 'Input/Wells/Well Attributes/Cost': WellAttribute(petrel_name="Cost"), 'Input/Wells/Well Attributes/Bottom hole Y': WellAttribute(petrel_name="Bottom hole Y"), 'Input/Wells/Well Attributes/Operator': WellAttribute(petrel_name="Operator"), 'Input/Wells/Well Attributes/Uncertainty standard deviation factor': WellAttribute(petrel_name="Uncertainty standard deviation factor"), 'Input/Wells/Well Attributes/Content': WellAttribute(petrel_name="Content"), 'Input/Wells/Well Attributes/Spud date': WellAttribute(petrel_name="Spud date"), 'Input/Wells/Well Attributes/Longitude': WellAttribute(petrel_name="Longitude"), 'Input/Wells/Well Attributes/Ambient temperature': WellAttribute(petrel_name="Ambient temperature"), 'Input/Wells/Well Attributes/TD (TVDSS)': WellAttribute(petrel_name="TD (TVDSS)"), 'Input/Wells/Well Attributes/Type': WellAttribute(petrel_name="Type"), 'Input/Wells/Well Attributes/Field': WellAttribute(petrel_name="Field"), 'Input/Wells/Well Attributes/Simulation export date': WellAttribute(petrel_name="Simulation export date"), 'Input/Wells/Well Attributes/Latitude': WellAttribute(petrel_name="Latitude"), 'Input/Wells/Well Attributes/Surface X': WellAttribute(petrel_name="Surface X"), 'Input/Wells/Well Attributes/TD (MD)': WellAttribute(petrel_name="TD (MD)"), 'Input/Wells/Well Attributes/Status': WellAttribute(petrel_name="Status"), 'Input/Wells/Well Attributes/Well datum description': WellAttribute(petrel_name="Well datum description"), 'Input/Wells/Well Attributes/Predrilled completion date': WellAttribute(petrel_name="Predrilled completion date"), 'Input/Wells/Well Attributes/Name': WellAttribute(petrel_name="Name"), 'Input/Wells/Well Attributes/Heat transfer coefficient': WellAttribute(petrel_name="Heat transfer coefficient"), 'Input/Wells/Well Attributes/Surface Y': WellAttribute(petrel_name="Surface Y"), 'Input/Wells/Well Attributes/Predrilled entry date': WellAttribute(petrel_name="Predrilled entry date"), 'Input/Wells/Well Attributes/Well symbol': WellAttribute(petrel_name="Well symbol"), 'Input/Wells/Well Attributes/Bottom hole X': WellAttribute(petrel_name="Bottom hole X"), 'Input/Wells/Well Attributes/Drill permit': WellAttribute(petrel_name="Drill permit"), 'Input/Wells/Well Attributes/Well datum name': WellAttribute(petrel_name="Well datum name"), 'Input/Wells/Well Attributes/Uncertainty ground level': WellAttribute(petrel_name="Uncertainty ground level"), 'Input/Wells/Well Attributes/Purpose': WellAttribute(petrel_name="Purpose")})
Alternatively, you can get a list of all WellAttribute objects using a list comprehension:

attributes_list = [i for i in petrel.well_attributes]
attributes_list
[WellAttribute(petrel_name="Simulation export date"),
 WellAttribute(petrel_name="Latitude"),
 WellAttribute(petrel_name="Well datum value"),
 WellAttribute(petrel_name="Subsea"),
 WellAttribute(petrel_name="UWI"),
 WellAttribute(petrel_name="Uncertainty radius"),
 WellAttribute(petrel_name="Production licence"),
 WellAttribute(petrel_name="Surface Y"),
 WellAttribute(petrel_name="Predrilled entry date"),
 WellAttribute(petrel_name="Predrilled completion date"),
 WellAttribute(petrel_name="Uncertainty standard deviation factor"),
 WellAttribute(petrel_name="Content"),
 WellAttribute(petrel_name="Longitude"),
 WellAttribute(petrel_name="Uncertainty ground level"),
 WellAttribute(petrel_name="Completed date"),
 WellAttribute(petrel_name="TD (TVDSS)"),
 WellAttribute(petrel_name="Spud date"),
 WellAttribute(petrel_name="Bottom hole X"),
 WellAttribute(petrel_name="Field"),
 WellAttribute(petrel_name="Ambient temperature"),
 WellAttribute(petrel_name="TWT auto"),
 WellAttribute(petrel_name="Well datum name"),
 WellAttribute(petrel_name="Purpose"),
 WellAttribute(petrel_name="Z"),
 WellAttribute(petrel_name="TD (MD)"),
 WellAttribute(petrel_name="Simulation name"),
 WellAttribute(petrel_name="Well datum description"),
 WellAttribute(petrel_name="Max inc"),
 WellAttribute(petrel_name="Bottom hole Y"),
 WellAttribute(petrel_name="Surface X"),
 WellAttribute(petrel_name="Status"),
 WellAttribute(petrel_name="Cost"),
 WellAttribute(petrel_name="Heat transfer coefficient"),
 WellAttribute(petrel_name="Well symbol"),
 WellAttribute(petrel_name="Drill permit"),
 WellAttribute(petrel_name="Name"),
 WellAttribute(petrel_name="Operator"),
 WellAttribute(petrel_name="Type"),
 WellAttribute(petrel_name="Drilling structure")]
To get a specific well attribute, you can either use the .well_attributes property with the full Petrel path or use a list comprehension to retrieve the attribute by name:

operator_attribute = petrel.well_attributes["Input/Wells/Well Attributes/Operator"]
#or
operator_attribute = [i for i in petrel.well_attributes if i.petrel_name == "Operator"][0]
operator_attribute
WellAttribute(petrel_name="Operator")
Attribute properties
The .petrel_name property returns the name of the attribute as shown in Petrel.

operator_attribute.petrel_name
'Operator'
The .path property returns the path of the attribute in the Petrel input tree.

operator_attribute.path
'Input/Wells/Well Attributes/Operator'
The .readonly property indicates whether the attribute is read-only; set it to False to enable editing.

operator_attribute.readonly
True
The .droid property returns the Petrel Droid (unique object ID or GUID).

operator_attribute.droid
'80362ab3-aadb-4c76-99b6-0ee50817bd61'
The .template property returns the Petrel template name as a string.

operator_attribute.template
'Strings'
The .comments property returns any comments on the attribute as a string (or an empty string if none).

operator_attribute.comments
''
The .is_supported property indicates whether the WellAttribute is fully supported by the Ocean API. Some attributes available in Petrel may not be fully supported; unsupported attributes cannot have their values retrieved or modified, but the attributes themselves will still be visible and listed in Python Tool Pro.

operator_attribute.is_supported
True
The .is_writable property checks whether the attribute value can be changed.

operator_attribute.is_writable
True
Attribute functions
The .add_comment() method adds a comment to the attribute’s existing comments or replaces them. Use add_comment(“Comment text”, overwrite=False) to append, or set overwrite=True to replace all existing comments.

# set the readonly status to false so the attribute can be edited
operator_attribute.readonly = False
# Add a comment
operator_attribute.add_comment('Comment added by Python Tool Pro',overwrite=False)
# Returns the added comment
operator_attribute.comments
'Comment added by Python Tool Pro'
The .get_template() method returns the Petrel template assigned to the attribute as a Template or DiscreteTemplate object.

operator_attribute.get_template()
DiscreteTemplate(petrel_name="Strings")
The .set_petrel_name() method sets or changes the name of this attribute in Petrel. Note that not the default Petrel attributes can not be renamed.

# set the readonly status to false so the attribute can be edited
operator_attribute.readonly = False
# change the attribute name from 'Operator' to 'Operator name'
operator_attribute.set_petrel_name('Operator Name')
Retrieving the Value of an Attribute
You can get the value of an attribute for a specific well using the .get_value() method:

# retrieve a well
well = petrel.wells['Input/Wells/Gullfaks/34/10-C-8 A']
value = operator_attribute.get_value(well)
print("Operator:", value)
Operator: Statoil Petroleum AS
Setting the Value of an Attribute
You can set the value of an attribute using the .set_value() method by passing in the well you want to change the attribute for and the new value of the attribute:

# retrieve a well
well = petrel.wells['Input/Wells/Gullfaks/34/10-C-8 A']
# set the readonly status to false so the attribute can be edited
operator_attribute.readonly = False
# change the attribute value from Statoil Petroleum AS to Equinor
operator_attribute.set_value(well, "Equinor")
# print the new value
print(operator_attribute.get_value(well))
Equinor
Accessing Attributes via the Well Object
Attributes can also be accessed directly from a well object using the .attributes property, which returns an iterable collection of all attributes associated with that well.

well = petrel.wells['Input/Wells/Gullfaks/34/10-C-8 A']
well_attributes = well.attributes
well_attributes
Attributes(Well="34/10-C-8 A")
# List all attributes and the values for this well
for attr in well.attributes:
    # check if the attribute value can be retrieved
    if attr.is_supported:
        print(attr.petrel_name, attr.value)
    else:
        pass
TD (MD) 3182.1
Production licence 050
Spud date 2015-10-09 00:00:00
Ambient temperature nan
Heat transfer coefficient nan
Max inc 0.0
Latitude 61.2151833007596
Surface X 461003.11
Well datum value 84.1
Drill permit 3958-P
Bottom hole X 461003.11
Purpose PRODUCTION
Type DEVELOPMENT
Simulation export date NaT
Status PLUGGED
Name 34/10-C-8 A
Subsea False
Cost nan
Predrilled entry date
Operator Equinor
TD (TVDSS) 3098.0
Surface Y 6787133.71
Field GULLFAKS
Content OIL
UWI 7825
Longitude 2.27409166058953
Simulation name
Completed date 2015-10-21 00:00:00
Bottom hole Y 6787133.71
Predrilled completion date
TWT auto nan
Z 0.0
You can retrieve a dataframe of all the attributes available for a well using the .as_dataframe() method on the attribute collection :

well = petrel.wells['Input/Wells/Gullfaks/34/10-C-8 A']
well_attributes = well.attributes
well_attributes.as_dataframe()
Name	Surface X	Surface Y	Latitude	Longitude	Well datum value	TD (TVDSS)	TD (MD)	Max inc	Cost	...	Type	Production licence	Purpose	Status	Content	Subsea	Predrilled entry date	Predrilled completion date	Field	Drill permit
0	34/10-C-8 A	461003.11	6787133.71	61.215183	2.274092	84.1	3098.0	3182.1	0.0	NaN	...	DEVELOPMENT	050	PRODUCTION	PLUGGED	OIL	False			GULLFAKS	3958-P
1 rows × 32 columns

The dataframe can be filtered to show different attributes types. The current supported ones are All attributes, User attributes and Default attributes:

attributeTypes.png
well_attributes.as_dataframe(attribute_filter=['All'])
Name	Surface X	Surface Y	Latitude	Longitude	Well datum value	TD (TVDSS)	TD (MD)	Max inc	Cost	...	Type	Production licence	Purpose	Status	Content	Subsea	Predrilled entry date	Predrilled completion date	Field	Drill permit
0	34/10-C-8 A	461003.11	6787133.71	61.215183	2.274092	84.1	3098.0	3182.1	0.0	NaN	...	DEVELOPMENT	050	Injection	PLUGGED	OIL	False			GULLFAKS	3958-P
1 rows × 32 columns

well_attributes.as_dataframe(attribute_filter=['User'])
Name	Ambient temperature	Heat transfer coefficient	Completed date	Type	Production licence	Purpose	Status	Content	Subsea	Predrilled entry date	Predrilled completion date	Field	Drill permit
0	34/10-C-8 A	NaN	NaN	2015-10-21	DEVELOPMENT	050	Injection	PLUGGED	OIL	False			GULLFAKS	3958-P
well_attributes.as_dataframe(attribute_filter=['Default'])
Name	Surface X	Surface Y	Latitude	Longitude	Well datum value	TD (TVDSS)	TD (MD)	Max inc	Cost	Spud date	Simulation export date	Z	TWT auto	Bottom hole X	Bottom hole Y	UWI	Simulation name	Operator
0	34/10-C-8 A	461003.11	6787133.71	61.215183	2.274092	84.1	3098.0	3182.1	0.0	NaN	2015-10-09	NaT	0.0	NaN	461003.11	6787133.71	7825		Equinor
Alternatively, the dataframe can be filtered using the WellAttributeFilterEnum enum:

from cegalprizm.pythontool import WellAttributeFilterEnum
well_attributes.as_dataframe(attribute_filter=[WellAttributeFilterEnum.User])
Name	Ambient temperature	Heat transfer coefficient	Completed date	Type	Production licence	Purpose	Status	Content	Subsea	Predrilled entry date	Predrilled completion date	Field	Drill permit
0	34/10-C-8 A	NaN	NaN	2015-10-21	DEVELOPMENT	050	Injection	PLUGGED	OIL	False			GULLFAKS	3958-P
You can also access a specific attribute by name. The value of the attribute can then be returned using the .value property :

# Get the "Operator" attribute for this well
operator_attr_instance = well.attributes["Operator"]
print("Operator:", operator_attr_instance.value)
Operator: Equinor
Note: When you access an attribute through a well (using .attributes), you get a WellAttributeInstance, which represents the value of that attribute for that specific well.

In contrast, when you access attributes via petrel.well_attributes, you get a WellAttribute object (can be thought of as the global attribute definition you see in the Petrel input tree).

# Global attribute definition
operator_attribute = petrel.well_attributes["Input/Wells/Well Attributes/Operator"]
type(operator_attribute)
cegalprizm.pythontool.wellattribute.WellAttribute
# Attribute instance for a specific well
operator_attr_instance = well.attributes["Operator"]
type(operator_attr_instance)
cegalprizm.pythontool.wellattribute.WellAttributeInstance
You can get the WellAttribute associated with a WellAttributeInstance using the .get_well_attribute() method:

operator_attr_instance.get_well_attribute()
WellAttribute(petrel_name="Operator")
Setting Attributes via the Well Object
well = petrel.wells['Input/Wells/Gullfaks/34/10-C-8 A']

purpose_attr_instance = well.attributes["Purpose"]
purpose_attr_instance.value
'PRODUCTION'
On the well object, the value of a Well Attribute can be edited directly using the .value property:

# set the readonly status to false so the attribute can be edited
purpose_attr_instance.readonly = False
# Change the value of the attribute from PRODUCTION to Injection
purpose_attr_instance.value = 'Injection'
print(purpose_attr_instance.value)
Injection
Creating a New Well Attributes
New attributes can be created using the .create_well_attribute() method on the PetrelConnection object.

Provide the name of the attribute, the type of the attribute (“continuous”, “discrete”, “string”, “boolean”, or “datetime”), and optionally the template to use.

For continuous attributes, pass a Template object. For discrete attributes, use a DiscreteTemplate. If you don’t specify a template (None), the default template will be applied automatically.

Attributes you create will automatically be categorized as WellAttributeEnum.User.

# Create a continuous attribute
petrel.create_well_attribute(name="my_attribute_cont", attribute_type="Continuous")

# Create a discrete attribute
petrel.create_well_attribute(name="my_attribute_discrete", attribute_type="Discrete")

# Create a string attribute
petrel.create_well_attribute(name="my_attribute_str", attribute_type="String")

# Create a boolean attribute
petrel.create_well_attribute(name="my_attribute_bool", attribute_type="Boolean")

# Create a datetime attribute
petrel.create_well_attribute(name="my_attribute_date", attribute_type="Datetime")

newAttributes.png
Creating and setting New Well Attributes using a dataframe
Well attributes can be created or updated in bulk using the .set_well_attributes_from_dataframe() method on the PetrelConnection object.

You provide a Pandas DataFrame where:

Each row represents a well.

Each column represents an attribute.

The well_name_column identifies which column contains the well names (default: “Name”).

If an attribute in the DataFrame does not already exist in Petrel, it will be created automatically (if create_if_missing=True).

If ignore_duplicates is True, all wells and attributes with the same name will be updated with the same attribute values. If ignore_duplicates is False (the default), any duplicates will be skipped to avoid ambiguity.

When creating new attributes, the data type is inferred from the column values:

Pandas Data Type

Petrel Attribute Type

float64

Continuous

Int32

Discrete

object

String

boolean

Boolean

datetime

Datetime

For continuous attributes, you can optionally pass a Template object. For discrete attributes, use a DiscreteTemplate. If you don’t specify templates (template_definitions=None), the default templates are applied automatically.

Below is an example creating a DataFrame and importing the attributes:

import pandas as pd

# Create a sample DataFrame with well names and attribute values
df = pd.DataFrame({
    "Name": [
        "34/10-6",
        "34/10-34",
        "34/10-1"
    ],
    "Purpose": [
        "Production",
        "Injection",
        "Production"
    ],
    "Custom String Attribute": [
        "Test A",
        "Test B",
        "Test C"
    ],
    "Custom Numeric Attribute": [
        42.0,
        36.5,
        58.2
    ],
    "Custom Boolean Attribute": [
        True,
        False,
        True
    ],
    "Spud Date": pd.to_datetime([
        "2020-01-01",
        "2021-06-15",
        "2019-09-30"
    ])
})

df
Name	Purpose	Custom String Attribute	Custom Numeric Attribute	Custom Boolean Attribute	Spud Date
0	34/10-6	Production	Test A	42.0	True	2020-01-01
1	34/10-34	Injection	Test B	36.5	False	2021-06-15
2	34/10-1	Production	Test C	58.2	True	2019-09-30
# Import the DataFrame into Petrel
petrel.set_well_attributes_from_dataframe(
    df,
    well_name_column="Name",
    create_if_missing=True,
    ignore_duplicates=False
)
dfCreation.png
Retrieving All Well Attributes as a DataFrame
You can retrieve all well attributes in the current Petrel project as a Pandas DataFrame using the .get_well_attributes_as_dataframe() method.

When you call this method:

Each row in the DataFrame represents a well.

Each column represents an attribute.

You can filter which attributes and wells to include.

You can control which attributes and wells are included with the attribute_filter and wells_filter arguments:

attribute_filter lets you choose which attributes to include. Valid options are “All” (default), “Default” (only default attributes), and “User” (only user-defined attributes). You can pass either strings or WellAttributeFilterEnum values.

wells_filter lets you specify a WellFolder or SavedSearch to limit the wells included in the DataFrame.

df = petrel.get_well_attributes_as_dataframe(attribute_filter=[WellAttributeFilterEnum.All])
df
Name	Surface X	Surface Y	Latitude	Longitude	Well datum value	TD (TVDSS)	TD (MD)	Max inc	Cost	...	Subsea	Predrilled entry date	Predrilled completion date	Field	Drill permit	my_attribute_discrete	my_attribute_str	my_attribute_bool	Custom String Attribute	Custom Boolean Attribute
0	34/10-3	456946.80	6787020.80	61.213744	2.198619	25.0	2802.0	2827.0	0.0	NaN	...	False			GULLFAKS	211-L	<NA>		False		False
1	34/10-7	461016.27	6785858.02	61.203733	2.274600	25.0	2250.0	2275.0	0.0	NaN	...	False			GULLFAKS	237-L	<NA>		False		False
2	34/10-34 R	453515.53	6787519.76	61.217831	2.134636	23.0	2410.0	2433.0	0.0	NaN	...	False			GULLFAKS	672-L2	<NA>		False		False
3	34/10-46 S	456420.11	6782830.47	61.176072	2.189783	82.2	5568.0	5650.2	0.0	NaN	...	False			GULLFAKS	1030-L	<NA>		False		False
4	34/10-34	453515.53	6787519.76	61.217831	2.134636	23.0	2410.0	2433.0	0.0	NaN	...	False			GULLFAKS	672-L	<NA>		False	Test B	False
5	34/10-C-8 A	461003.11	6787133.71	61.215183	2.274092	84.1	3098.0	3182.1	0.0	NaN	...	False			GULLFAKS	3958-P	<NA>		False	Test A	True
6	34/10-45 B	457094.51	6785795.10	61.202758	2.201647	81.0	7928.0	8009.0	0.0	NaN	...	False			GULLFAKS	1068-L	<NA>		False		False
7	34/10-1	457626.92	6783217.39	61.179678	2.212131	25.0	2460.0	2485.0	0.0	NaN	...	False			GULLFAKS	197-L	<NA>		False	Test C	True
8	34/10-9	459717.06	6787169.27	61.215372	2.250147	25.0	2200.0	2225.0	0.0	NaN	...	False			GULLFAKS	248-L	<NA>		False		False
9	34/10-4	458739.12	6785952.41	61.204347	2.232211	25.0	2600.0	2625.0	0.0	NaN	...	False			GULLFAKS	222-L	<NA>		False		False
10	34/10-6	458607.45	6790330.87	61.243636	2.228800	25.0	2363.0	2388.0	0.0	NaN	...	False			GULLFAKS	231-L	<NA>		False	Test A	True
11	34/10-45 S	457094.51	6785795.10	61.202758	2.201647	81.0	7594.0	7675.0	0.0	NaN	...	False			GULLFAKS	1027-L	<NA>		False		False
12	34/10-5	455546.36	6784434.79	61.190375	2.173164	25.0	2780.0	2805.0	0.0	NaN	...	False			GULLFAKS	228-L	<NA>		False		False
13	34/10-14	460013.70	6789182.27	61.233472	2.255242	25.0	2647.0	2672.0	0.0	NaN	...	False			GULLFAKS	312-L	<NA>		False		False
14	34/10-46 A	456420.11	6782830.47	61.176072	2.189783	82.2	6860.0	6942.2	0.0	NaN	...	False			GULLFAKS	1032-L	<NA>		False		False
15 rows × 41 columns
==================
Saved Searches
Note: Support for working with saved searches was introduced in Python Tool Pro 2.7.

This guide explains how to access saved searches in Python Tool Pro. Check out the API documentation to view a detailed description of all the functions and properties available for working with saved searches.

Connect to a Petrel project
from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()
Accessing Saved Searches
You can access all available saved searches in the project using the .saved_searches property on the Petrel connection. The keys of the dictionary represents the path to the saved search in the Petrel input tree and the value represents the saved search object.

petrel.saved_searches
SavedSearches({'Input/Wells/Saved searches/Dynamic saved search': SavedSearch(petrel_name="Dynamic saved search"), 'Input/Wells/Saved searches/Saved search': SavedSearch(petrel_name="Saved search")})
Alternatively, you can get a list of all SavedSearches objects using a list comprehension:

saved_searches_list = [i for i in petrel.saved_searches]
saved_searches_list
[SavedSearch(petrel_name="Dynamic saved search"),
 SavedSearch(petrel_name="Saved search")]
To get a specific well attribute, you can either use the .saved_searches property with the full Petrel path or use a list comprehension to retrieve the attribute by name:

saved_search = petrel.saved_searches["Input/Wells/Saved searches/Saved search"]
#or
saved_search = [i for i in petrel.saved_searches if i.petrel_name == "Saved search"][0]
saved_search
SavedSearch(petrel_name="Saved search")
Saved Searches properties and methods
The .petrel_name property returns the name of the saved search as shown in Petrel.

saved_search.petrel_name
'Saved search'
The .path property returns the path of the saved search in the Petrel input tree.

saved_search.path
'Input/Wells/Saved searches/Saved search'
The .readonly property indicates whether the saved search is read-only; set it to False to enable editing.

saved_search.readonly
True
The .droid property returns the Petrel Droid (unique object ID or GUID).

saved_search.droid
'e506ad14-ffc5-4006-96aa-e328b322a400'
The .comments property returns any comments on the saved search as a string (or an empty string if none).

saved_search.comments
''
The .add_comment() method adds a comment to the saved search existing comments or replaces them. Use add_comment(“Comment text”, overwrite=False) to append, or set overwrite=True to replace all existing comments.

# set the readonly status to false so the saved search can be edited
saved_search.readonly = False

# Add a comment
saved_search.add_comment('Comment added by Python Tool Pro',overwrite=False)
Dynamic (extended) saved searches automatically update their contents. You can check if a saved search is dynamic using .is_extended property which return a boolean (True if the saved search is dynamic, False otherwise):

saved_search.is_dynamic
False
Getting Wells from a Saved Search
Use .get_wells() to get a list of all wells included in the saved search.

saved_search.get_wells()
[Well(petrel_name="A15"),
 Well(petrel_name="B8"),
 Well(petrel_name="B9"),
 Well(petrel_name="C2"),
 Well(petrel_name="C4"),
 Well(petrel_name="C5"),
 Well(petrel_name="C6"),
 Well(petrel_name="C3")]

====

Observed data
This notebook provides examples on how to use Python Tool Pro to access observed data. With the release of Python Tool Pro version 2.2 users can now access and manipulte the Global Observerd Datasets as well.

Check out the API documentation to view a detailed description of all the functions and properties available for Observed Data sets.

Connect to a Petrel project
from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection(allow_experimental=True)
Global observed data
Check out the API documentation to view a detailed description of all the functions and properties available for Global observed data.

The .predefined_global_observed_data property returns a dictionary of all the predefined global observed data in the Petrel project, where the keys represent the name of the predifined global observed data and the values represent the IDs used to identify them:

petrel.predefined_global_observed_data
{'Gas mass injection cumulative': 'INJECTION_MASS_CUML_GAS',
 'Gas mass rate': 'MASS_RATE_GAS',
 'Water mass cumulative': 'MASS_CUML_WATER',
 'Liquid phase PI': 'PHASE_PI_LIQUID',
 'Oil injection cumulative': 'INJECTION_CUML_OIL',
 'Tracer production rate': 'PRODUCTION_RATE_TRACER',
 'Liquid production rate': 'PRODUCTION_RATE_LIQUID',
 'Alkali production concentration': 'PRODUCTION_CONCENTRATION_ALKALI',
 'Well block average pressure': 'WELL_BLOCK_AVERAGE_PRESSURE',
 'Pressure average (4-point)': 'PRESSURE_4_POINT',
 'Pressure average (5-point)': 'PRESSURE_5_POINT',
 'Clean fluid cumulative': 'CLEAN_FLUID_CUML',
 'Uptime fraction': 'UPTIME_FRACTION',
 'Pressure average (9-point)': 'PRESSURE_9_POINT',
 'Oil injection rate': 'INJECTION_RATE_OIL',
 'Oil-liquid ratio': 'OIL_LIQUID_RATIO',
 'Oil formation volume factor': 'FORMATION_VOLUME_FACTOR_OIL',
 'Oil mass cumulative': 'MASS_CUML_OIL',
 'Methane production cumulative': 'PRODUCTION_CUML_METHANE',
 'Alkali injection concentration': 'INJECTION_CONCENTRATION_ALKALI',
 'Surfactant production cumulative': 'PRODUCTION_CUML_SURFACTANT',
 'Gas phase PI': 'PHASE_PI_GAS',
 'Gas lift injection cumulative': 'INJECTION_CUML_LIFTGAS',
 'Tracer injection rate (Solution)': 'INJECTION_RATE_TRACER_SOLUTION',
 'Water phase PI': 'PHASE_PI_WATER',
 'Tracer production concentration (Free)': 'PRODUCTION_CONCENTRATION_TRACER_FREE',
 'Polymer injection concentration': 'INJECTION_CONCENTRATION_POLYMER',
 'Gas density': 'DENSITY_GAS',
 'Bottom hole pressure': 'BOTTOM_HOLE_PRESSURE',
 'Surfactant production rate': 'PRODUCTION_RATE_SURFACTANT',
 'Polymer injection rate': 'INJECTION_RATE_POLYMER',
 'Oil viscosity compressibility': 'VISCOSITY_COMPRESSIBILITY_OIL',
 'Reservoir volume production rate': 'RES_VOLUME_PRODUCTION_RATE',
 'Liquid production cumulative': 'PRODUCTION_CUML_LIQUID',
 'Oil mass injection cumulative': 'INJECTION_MASS_CUML_OIL',
 'Pressure': 'PRESSURE',
 'Liquid-gas ratio': 'LIQUID_GAS_RATIO',
 'Tracer injection concentration (Solution)': 'INJECTION_CONCENTRATION_TRACER_SOLUTION',
 'Tracer production concentration': 'PRODUCTION_CONCENTRATION_TRACER',
 'Gas mass cumulative': 'MASS_CUML_GAS',
 'Water injection rate weighting': 'INJECTION_RATE_WATER_WEIGHTING',
 'Gas lift injection rate': 'INJECTION_RATE_LIFTGAS',
 'Gas production rate': 'PRODUCTION_RATE_GAS',
 'Oil mass production cumulative': 'PRODUCTION_MASS_CUML_OIL',
 'Bottom hole proppant concentration': 'BOTTOM_HOLE_PROPPANT_CONCENTRATION',
 'Tracer production rate (Free)': 'PRODUCTION_RATE_TRACER_FREE',
 'Oil-water ratio': 'OIL_WATER_RATIO',
 'Water cut': 'WATER_CUT',
 'Oil mass injection rate': 'INJECTION_MASS_RATE_OIL',
 'Oil production cumulative': 'PRODUCTION_CUML_OIL',
 'Proppant concentration': 'PROPPANT_CONCENTRATION',
 'Oil production rate weighting': 'PRODUCTION_RATE_OIL_WEIGHTING',
 'Bottom hole pressure weighting': 'BOTTOM_HOLE_PRESSURE_WEIGHTING',
 'Instantaneous water production rate': 'PRODUCTION_INSTRATE_WATER',
 'Tracer injection rate (Free)': 'INJECTION_RATE_TRACER_FREE',
 'Salt injection concentration': 'INJECTION_CONCENTRATION_BRINE',
 'Liquid-oil ratio': 'LIQUID_OIL_RATIO',
 'Oil compressibility': 'COMPRESSIBILITY_OIL',
 'Tubing head pressure': 'TUBING_HEAD_PRESSURE',
 'Polymer production rate': 'PRODUCTION_RATE_POLYMER',
 'Gas-oil ratio': 'GAS_OIL_RATIO',
 'Tracer injection rate': 'INJECTION_RATE_TRACER',
 'Tracer production rate (Solution)': 'PRODUCTION_RATE_TRACER_SOLUTION',
 'Reservoir volume production cumulative': 'RES_VOLUME_PRODUCTION_CUML',
 'Tracer injection cumulative (Free)': 'INJECTION_CUML_TRACER_FREE',
 'Instantaneous oil injection rate': 'INJECTION_INSTRATE_OIL',
 'Oil injection rate weighting': 'INJECTION_RATE_OIL_WEIGHTING',
 'Instantaneous gas injection rate': 'INJECTION_INSTRATE_GAS',
 'Instantaneous water injection rate': 'INJECTION_INSTRATE_WATER',
 'Tracer injection concentration (Free)': 'INJECTION_CONCENTRATION_TRACER_FREE',
 'Instantaneous oil production rate': 'PRODUCTION_INSTRATE_OIL',
 'Oil production rate': 'PRODUCTION_RATE_OIL',
 'Oil density': 'DENSITY_OIL',
 'Oil phase PI': 'PHASE_PI_OIL',
 'Water mass rate': 'MASS_RATE_WATER',
 'Slurry cumulative': 'SLURRY_CUML',
 'Reservoir volume production rate weighting': 'RES_VOLUME_PRODUCTION_RATE_WEIGHTING',
 'Methane injection rate': 'INJECTION_RATE_METHANE',
 'Temperature': 'TEMPERATURE',
 'Water formation volume factor': 'FORMATION_VOLUME_FACTOR_WATER',
 'Water mass injection rate': 'INJECTION_MASS_RATE_WATER',
 'Methane injection cumulative': 'INJECTION_CUML_METHANE',
 'Oil-gas ratio': 'OIL_GAS_RATIO',
 'Artificial lift quantity': 'ALQ_VALUE',
 'Water-gas ratio': 'WATER_GAS_RATIO',
 'Injected solution gas-oil ratio': 'SOLUTION_GAS_OIL_RATIO_INJ',
 'Gas production cumulative': 'PRODUCTION_CUML_GAS',
 'Tracer production cumulative (Solution)': 'PRODUCTION_CUML_TRACER_SOLUTION',
 'Water production rate': 'PRODUCTION_RATE_WATER',
 'Gas-liquid ratio': 'GAS_LIQUID_RATIO',
 'Tracer production concentration (Solution)': 'PRODUCTION_CONCENTRATION_TRACER_SOLUTION',
 'Gas injection rate': 'INJECTION_RATE_GAS',
 'Surfactant injection cumulative': 'INJECTION_CUML_SURFACTANT',
 'Salt production concentration': 'PRODUCTION_CONCENTRATION_BRINE',
 'Oil injection uptime fraction': 'UPTIME_FRACTION_OIL',
 'Slurry rate': 'SLURRY_RATE',
 'Wet gas production rate': 'PRODUCTION_RATE_WET_GAS',
 'Oil mass production rate': 'PRODUCTION_MASS_RATE_OIL',
 'Tubing head temperature for producer wells': 'TUBING_HEAD_TEMPERATURE',
 'Oil thermal expansivity': 'THERMAL_EXPANSIVITY_OIL',
 'Bottom hole treating pressure': 'BOTTOM_HOLE_TREATMENT_PRESSURE',
 'Gas mass production cumulative': 'PRODUCTION_MASS_CUML_GAS',
 'Oil API gravity': 'API_GRAVITY_OIL',
 'Water mass injection cumulative': 'INJECTION_MASS_CUML_WATER',
 'Tracer injection concentration': 'INJECTION_CONCENTRATION_TRACER',
 'Injected vaporized oil-gas ratio': 'VAPOR_OIL_GAS_RATIO_INJ',
 'Gas formation volume factor': 'FORMATION_VOLUME_FACTOR_GAS',
 'Gas production rate weighting': 'PRODUCTION_RATE_GAS_WEIGHTING',
 'Liquid production rate weighting': 'PRODUCTION_RATE_LIQUID_WEIGHTING',
 'Water injection cumulative': 'INJECTION_CUML_WATER',
 'Water thermal expansivity': 'THERMAL_EXPANSIVITY_WATER',
 'Water production rate weighting': 'PRODUCTION_RATE_WATER_WEIGHTING',
 'Tracer injection cumulative (Solution)': 'INJECTION_CUML_TRACER_SOLUTION',
 'Liquid-water ratio': 'LIQUID_WATER_RATIO',
 'Polymer production cumulative': 'PRODUCTION_CUML_POLYMER',
 'Surfactant injection rate': 'INJECTION_RATE_SURFACTANT',
 'Water mass production cumulative': 'PRODUCTION_MASS_CUML_WATER',
 'Oil mass rate': 'MASS_RATE_OIL',
 'Gas injection cumulative': 'INJECTION_CUML_GAS',
 'Water production cumulative': 'PRODUCTION_CUML_WATER',
 'Tracer injection cumulative': 'INJECTION_CUML_TRACER',
 'Water injection uptime fraction': 'UPTIME_FRACTION_WATER',
 'Tracer production cumulative': 'PRODUCTION_CUML_TRACER',
 'Gas-water ratio': 'GAS_WATER_RATIO',
 'Clean fluid rate': 'CLEAN_FLUID_RATE',
 'Water injection rate': 'INJECTION_RATE_WATER',
 'Water mass production rate': 'PRODUCTION_MASS_RATE_WATER',
 'Gas injection uptime fraction': 'UPTIME_FRACTION_GAS',
 'Water cut in a chemical four phase system': 'WATER_CUT4',
 'Methane production rate': 'PRODUCTION_RATE_METHANE',
 'Polymer production concentration': 'PRODUCTION_CONCENTRATION_POLYMER',
 'Instantaneous gas production rate': 'PRODUCTION_INSTRATE_GAS',
 'Treating pressure': 'TREATING_PRESSURE',
 'Gas injection rate weighting': 'INJECTION_RATE_GAS_WEIGHTING',
 'Polymer injection cumulative': 'INJECTION_CUML_POLYMER',
 'Productivity index': 'PRODUCTIVITY_INDEX',
 'Proppant cumulative': 'PROPPANT_CUML',
 'Bottom hole temperature': 'BOTTOM_HOLE_TEMPERATURE',
 'Tracer production cumulative (Free)': 'PRODUCTION_CUML_TRACER_FREE',
 'Instantaneous liquid production rate': 'PRODUCTION_INSTRATE_LIQUID'}
You can access all the Global observed data sets using the .global_observed_data_sets property which will return a dictionary where the key represents the path of the global observed data sets within the Petrel input tree and the value represents the name of the global observed data set.

global_observed = petrel.global_observed_data_sets
global_observed
GlobalObservedDataSets({'Input/Wells/Global observed data/Observed data sets/Production Observed data - PE': GlobalObservedDataSet(petrel_name="Production Observed data - PE"), 'Input/Wells/Global observed data/Observed data sets/PTP_ObservedData': GlobalObservedDataSet(petrel_name="PTP_ObservedData"), 'Input/Wells/Global observed data/Observed data sets/Observed 3': GlobalObservedDataSet(petrel_name="Observed 3"), 'Input/Wells/Global observed data/Observed data sets/Observed 1': GlobalObservedDataSet(petrel_name="Observed 1")})
image-6.png
We can access a particular Global observed data set by saving the paths of all global observed data sets to a list and then use slicing to assign it to a variable. Alternatively, you can access a particular global data set by providing it’s path as an argument.

# Get all the global observed data sets paths from the dictionary keys and save them in a list
global_observed_path=list(global_observed.keys())

#Slice the list to get a specific global data set
global_observed_dataset=global_observed[global_observed_path[0]]
print(global_observed_dataset)

#Alternative way to access a specific global observed data set
global_observed_dataset_alternative=global_observed["Input/Wells/Global observed data/Observed data sets/Observed 1"]
print(global_observed_dataset_alternative)
GlobalObservedDataSet(petrel_name="Observed 1")
GlobalObservedDataSet(petrel_name="Observed 1")
To return the name of the selected global observed data set we can use the .petrel_name property:

global_observed_dataset.petrel_name
'Observed 1'
The path of the object can be accessed using the .path property:

global_observed_dataset.path
'Input/Wells/Global observed data/Observed data sets/Observed 1'
The .droid property returns the object id or guid which represents the Petrel filename in the project directory:

global_observed_dataset.droid
'e2bb0067-99a5-4c2d-8506-2d70298f9180'
The .retrieve_history() function will return the Petrel history of the object as a dataframe.

global_observed_dataset.retrieve_history()
Date	User	Action	Description
0	Jun 22 2011 16:24	YGuilarte	Import Well observed data (ASCII)	From: C:\Users\YGuilarte\Desktop\observedhist.vol
You can add a comment to the selected global observed data set using the .add_comment() function which takes in two parameters: new_comment , a string which represents the comment you want to add and overwrite , a boolean value which indicates if you want to add a new comment (overwrite=False) or overwrite the existing one (overwrite=True). The overwrite paramater defaults to False if not specified.

By default the selected global observed data set is set to readonly meaning you can not modify any of its attributes. To allow modifications you can use the .readonly property and set it to false:

global_observed_dataset.readonly=False
global_observed_dataset.add_comment(new_comment="Edited by user with Python Tool Pro",overwrite=False)
You can access the existing comments of a completion element using the .comments property which will return a string:

global_observed_dataset.comments
'Edited by user with Python Tool Pro'
We can create a copy of the selected global observed data set using the .clone() function and providing it a string which represents the name of the new global observed data set:

clone.png
global_observed_dataset.clone("PTP_ObservedData")
GlobalObservedDataSet(petrel_name="PTP_ObservedData")
We can create an observed data set for a specific well and assign it to the newly created global observed data set. To that we first assign the PTP_ObservedData global observed data set to a variable and also select a specific well and assign that to a variable. Then we apply the .create_observed_data_set() function to the PTP_ObservedData variable and pass the selected well as an input parameter :

create_obs_data.png
PTP_ObservedData=global_observed["Input/Wells/Global observed data/Observed data sets/PTP_ObservedData"]
well15 = petrel.wells["Input/Wells/A Wells/A15"]

PTP_ObservedData_WellA15= PTP_ObservedData.create_observed_data_set(well15)
Observed data
Check out the API documentation to view a detailed description of all the functions and properties available for Observed data.

You can access all the observed data sets using the .observed_data_sets property which will return a dictionary where the key represents the path of the observed data set within the Petrel input tree and the value represents the name of the observed data set:

obs_dataset.png
observed_data=petrel.observed_data_sets
observed_data
ObservedDataSets({'Input/Wells/A Wells/A15/PTP_ObservedData': ObservedDataSet(petrel_name="PTP_ObservedData"), 'Input/Wells/A Wells/A16/Production Observed data - PE': ObservedDataSet(petrel_name="Production Observed data - PE"), 'Input/Wells/B Wells/B8/Observed 3': ObservedDataSet(petrel_name="Observed 3"), 'Input/Wells/B Wells/B8/Production Observed data - PE': ObservedDataSet(petrel_name="Production Observed data - PE"), 'Input/Wells/B Wells/B9/Observed 3': ObservedDataSet(petrel_name="Observed 3"), 'Input/Wells/B Wells/B8/Observed 1': ObservedDataSet(petrel_name="Observed 1"), 'Input/Wells/A Wells/A15/Observed 3': ObservedDataSet(petrel_name="Observed 3"), 'Input/Wells/A Wells/A16/Observed 3': ObservedDataSet(petrel_name="Observed 3"), 'Input/Wells/A Wells/A15/Observed 1': ObservedDataSet(petrel_name="Observed 1"), 'Input/Wells/B Wells/B9/Observed 1': ObservedDataSet(petrel_name="Observed 1"), 'Input/Wells/B Wells/B9/Production Observed data - PE': ObservedDataSet(petrel_name="Production Observed data - PE"), 'Input/Wells/A Wells/A16/Observed 1': ObservedDataSet(petrel_name="Observed 1"), 'Input/Wells/A Wells/A15/Production Observed data - PE': ObservedDataSet(petrel_name="Production Observed data - PE")})
We can access a particular observed data set by saving the paths of all observed data sets to a list and then use slicing to assign it to a variable. Alternatively, you can access a particular observed data set by providing it’s path as an argument:

# Get all the observed data sets paths from the dictionary keys and save them in a list
observed_data_path=list(observed_data.keys())

#Slice the list to get the "Observed 1" dataset from well A15
observed1_wellA15=observed_data[observed_data_path[8]]
print(observed1_wellA15)

#Alternative way to access a specific observed data set
observed1_wellA15_alternative=observed_data["Input/Wells/A Wells/A15/Observed 1"]
print(observed1_wellA15_alternative)
ObservedDataSet(petrel_name="Observed 1")
ObservedDataSet(petrel_name="Observed 1")
You can check that you selected the observed data set for the correct well using the .well property which will return the well associated to the selected observed data set.

observed1_wellA15.well
Well(petrel_name="A15")
To return the name of the selected observed data set we can use the .petrel_name property:

observed1_wellA15.petrel_name
'Observed 1'
The path of the object can be accessed using the .path property:

observed1_wellA15.path
'Input/Wells/A Wells/A15/Observed 1'
The .droid property returns the object id or guid which represents the Petrel filename in the project directory:

observed1_wellA15.droid
'://1d9a2dd1-dd1d-4676-a92e-6057e64d33c2/6b5a07a9-695c-4340-b3b3-e5f24c61da85://1d9a2dd1-dd1d-4676-a92e-6057e64d33c2/e2bb0067-99a5-4c2d-8506-2d70298f9180'
The .retrieve_history() function will return the Petrel history of the object as a dataframe.

observed1_wellA15.retrieve_history()
Date	User	Action	Description
0	Jun 22 2011 16:24	YGuilarte	Import Well observed data (ASCII)	From: C:\Users\YGuilarte\Desktop\observedhist.vol
1	Aug 04 2015 08:26	JDulibeako	Synchronized from	G:\Petrel2013_2 demo project.pet
2	Aug 05 2015 12:32	JDulibeako	Synchronized from	C:\Gulfaks DEMO\Petrel 2015.1\BACKUPS\06 Geolo...
3	Feb 03 2020 14:43	brucech	Synchronized from	C:\PythonToolDemoProject\Gullfaks_2018_demo\Gu...
To access the observe data contained in the observe dataset in a dataframe we can use the .as_dataframe() function:

as_dataframe.png
df=observed1_wellA15.as_dataframe()
df
Date	Bottom hole pressure	Gas-oil ratio	Gas production rate	Oil production rate
0	1995-01-01	139.0	125.0	497356.0	4226.0
1	1995-02-01	123.0	122.0	447211.0	3912.0
2	1995-03-01	117.0	122.0	393576.0	3427.0
3	1995-04-01	104.0	119.0	420678.0	3448.0
4	1995-05-01	102.0	121.0	406746.0	3349.0
...	...	...	...	...	...
115	2004-08-01	92.0	105.0	195791.0	1875.0
116	2004-09-01	85.0	106.0	225573.0	2086.0
117	2004-10-01	84.0	106.0	232164.0	2036.0
118	2004-11-01	97.0	101.0	214420.0	1957.0
119	2004-12-01	98.0	108.0	212024.0	2062.0
120 rows × 5 columns

The .observed_data property will generate an iterable collection of the observed data objects contained in the selected observe dataset

data_collection=observed1_wellA15.observed_data
data_collection
WellObservedData(observed_data_set="ObservedDataSet(petrel_name="Observed 1")")
We can now iterate through the data collection and print out each available observed data or alternatively we can generate a list of all the observed data:

for data in data_collection:
    print(data)

A15_observed_data=list(data_collection)
A15_observed_data
ObservedData(petrel_name="Bottom hole pressure")
ObservedData(petrel_name="Gas-oil ratio")
ObservedData(petrel_name="Gas production rate")
ObservedData(petrel_name="Oil production rate")
[ObservedData(petrel_name="Bottom hole pressure"),
 ObservedData(petrel_name="Gas-oil ratio"),
 ObservedData(petrel_name="Gas production rate"),
 ObservedData(petrel_name="Oil production rate")]
We can also add a new observed data to the selected observed data set. We can do that using the .add_observed_data() function which takes in the following two arguments: * global_observed_data_id - this value is obtained by using the .predefined_global_observed_data property which returns a dictionary of all the availabe global observed data types in Petrel as keys and their ID as value (to see the output of this property check the second cell of this notbook).

observed_data_values - a list of observed data_values to set. In the example bellow we used a randomly generated list to populate the values of the new property.

# Generate a list of 120 random numbers
import random
random_numbers = [random.randint(1, 100) for i in range(120)]

# generate a Gas Density date set
observed1_wellA15.add_observed_data(global_observed_data_id='DENSITY_GAS', observed_data_values=random_numbers)
ObservedData(petrel_name="Gas density")
Running the cell above will add a Gas density observed data in the Observed 1 data set for well A15. We can view the values of the new data in the Petrel spreadsheet or by using the .as_dataframe() function:

gas_density.png
df=observed1_wellA15.as_dataframe()
df
Date	Bottom hole pressure	Gas-oil ratio	Gas production rate	Oil production rate	Gas density
0	1995-01-01	139.0	125.0	497356.0	4226.0	65000.0
1	1995-02-01	123.0	122.0	447211.0	3912.0	13000.0
2	1995-03-01	117.0	122.0	393576.0	3427.0	83000.0
3	1995-04-01	104.0	119.0	420678.0	3448.0	75000.0
4	1995-05-01	102.0	121.0	406746.0	3349.0	75000.0
...	...	...	...	...	...	...
115	2004-08-01	92.0	105.0	195791.0	1875.0	84000.0
116	2004-09-01	85.0	106.0	225573.0	2086.0	52000.0
117	2004-10-01	84.0	106.0	232164.0	2036.0	21000.0
118	2004-11-01	97.0	101.0	214420.0	1957.0	95000.0
119	2004-12-01	98.0	108.0	212024.0	2062.0	16000.0
120 rows × 6 columns

We can also append a new row to the observed dataset spreadsheet. To do that we can use the .append_row() function which has 3 arguments: * date: the next date to append, new date must be greater than the the last date entry. We can make use of the datetime library to assign a date to a variable (i.e date=datetime(2022,3,8,9,0,0) ) * observed_data: the order of the observed data in the observed data set for the new observed_data_values * observed_data_values: values to use for the new entry, order must match observed_data input

image-3.png
new_date = datetime(2022,3,8,9,0,0)
observed_data = list(observed1_wellA15.observed_data)

observed1_wellA15.append_row(date=date_vld2, observed_data=observed_data, observed_data_values=[1,1,1,1,1])
We can now view the newly appended row in the Petrel spreadsheet or by using the .as_dateframe() function:

image.png
df=observed1_wellA15.as_dataframe()
df
Date	Bottom hole pressure	Gas-oil ratio	Gas production rate	Oil production rate	Gas density
0	1995-01-01 00:00:00	139.0	125.0	497356.0	4226.0	65000.0
1	1995-02-01 00:00:00	123.0	122.0	447211.0	3912.0	13000.0
2	1995-03-01 00:00:00	117.0	122.0	393576.0	3427.0	83000.0
3	1995-04-01 00:00:00	104.0	119.0	420678.0	3448.0	75000.0
4	1995-05-01 00:00:00	102.0	121.0	406746.0	3349.0	75000.0
...	...	...	...	...	...	...
116	2004-09-01 00:00:00	85.0	106.0	225573.0	2086.0	52000.0
117	2004-10-01 00:00:00	84.0	106.0	232164.0	2036.0	21000.0
118	2004-11-01 00:00:00	97.0	101.0	214420.0	1957.0	95000.0
119	2004-12-01 00:00:00	98.0	108.0	212024.0	2062.0	16000.0
120	2022-03-08 09:00:00	1.0	1.0	1.0	1.0	1.0
121 rows × 6 columns

You can also access individual observe data from the observed data set. To to that you can save the observed data in a list and use slicing to assign it to a variable:

#Get a list of the observed data in the Observe 1 data set
observed_data = list(observed1_wellA15.observed_data)

#Assign the Gas production rate to a variable
observed1_wellA15_GPR=observed_data[2]
observed1_wellA15_GPR
ObservedData(petrel_name="Gas production rate")
You can access the selected observed dataset in a dataframe we can use the .as_dataframe() function:

observed1_wellA15_GPR.as_dataframe()
Date	Gas production rate
0	1995-01-01 00:00:00	497356.0
1	1995-02-01 00:00:00	447211.0
2	1995-03-01 00:00:00	393576.0
3	1995-04-01 00:00:00	420678.0
4	1995-05-01 00:00:00	406746.0
...	...	...
116	2004-09-01 00:00:00	225573.0
117	2004-10-01 00:00:00	232164.0
118	2004-11-01 00:00:00	214420.0
119	2004-12-01 00:00:00	212024.0
120	2022-03-08 09:00:00	1.0
121 rows × 2 columns

To return the path of the selected observed data we can use the .petrel_name property:

observed1_wellA15_GPR.path
'Input/Wells/A Wells/A15/Observed 1/Gas production rate'
To return the name of the selected observed data we can use the .petrel_name property:

observed1_wellA15_GPR.petrel_name
'Gas production rate'
The .droid property returns the object id or guid which represents the Petrel filename in the project directory:

observed1_wellA15_GPR.droid
'92db541c-2dbb-4cb1-96de-42f3a179f20b'
Using the .unit_symbol property we can access the unit for any object associated with a certain template:

observed1_wellA15_GPR.unit_symbol
'sm3/d'
You can access the values of the selected observed data using the .values property which will return a list of all the values. In the example bellow, we are only returning the first 5 values ([0:5]):

observed1_wellA15_GPR.values[0:5]
[497355.9999999999,
 447210.99999999994,
 393575.9999999999,
 420677.99999999994,
 406745.9999999999]
You can modify the values of the selected observed data using the .set_values() function which replaces all the values with the supplied values. To that we need to provide as argument a list of values, one per date in the observed data set. In the example bellow we use a randomly generate list of values:

# Generate a list of 121 random numbers
import random
random_numbers = [random.randint(1, 100) for i in range(121)]

observed1_wellA15_GPR.set_values(random_numbers)
You can now see that values have been changed by accessing the selected observed dataset in a dataframe:

observed1_wellA15_GPR.as_dataframe()
Date	Gas production rate
0	1995-01-01 00:00:00	48.0
1	1995-02-01 00:00:00	88.0
2	1995-03-01 00:00:00	53.0
3	1995-04-01 00:00:00	39.0
4	1995-05-01 00:00:00	76.0
...	...	...
116	2004-09-01 00:00:00	69.0
117	2004-10-01 00:00:00	69.0
118	2004-11-01 00:00:00	41.0
119	2004-12-01 00:00:00	61.0
120	2022-03-08 09:00:00	96.0
121 rows × 2 columns
===
Completions
Python Tool Pro version 2.2 added support for Completions. This notebook offers an overview of the different functions and properties available for working with Casing and Perforation data. For a more detailed description of all the functions and properties, check out the API documentation.

Connect to a Petrel project
from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection(allow_experimental=True)
print('Connected to {}'.format(petrel.get_current_project_name()))
Connected to Gullfaks_dataset3.pet
Assign the completions data to a variable
In order to start working with completions data we first need to select a well and assign it to a variable. For more information on working with wells check out the Wells, well survey and well logs userguide.

Then using the .completions_set property we obtain an iterable collection of the available compelitions data for the selected well:

wellA15 = petrel.wells['Input/Wells/Producers/A15']
completions = wellA15.completions_set
completions
CompletionsSet(well_petrel_name="A15")
To access the completions data in a dataframe we can use the .as_dataframe() function:

df = completions.as_dataframe()
df
Well name	UWI	Category	Type	Name	Top MD	Bottom MD	Outer Diameter	Inner Diameter	Start Date	Is Valid
0	A15		Casing	Casing string	Casing 1	1808.89	1900.0	NaN	NaN	1980-01-01	True
1	A15		Casing	Casing part	Casing 1:1	1808.89	1900.0	9.84252	9.84252	1980-01-01	True
2	A15		Casing	Casing string	Casing 2	1808.89	1992.0	NaN	NaN	1980-01-01	True
3	A15		Casing	Casing part	Casing 2:1	1808.89	1992.0	8.62500	8.09700	1980-01-01	True
4	A15		Workovers	Perforation	Perforation 1	1922.00	1992.0	NaN	NaN	1980-01-01	True
5	A15		Workovers	Perforation	Perforation 2	1879.00	1906.0	NaN	NaN	1980-01-01	True
Casing data
Check out the API documentation to view a detailed description of all the functions and properties available for Casings.

You can assign the casing strings to a variable using the .casing property which will return an iterable collection of the avaialbe casing strings for the selected well :

casings = completions.casings
casings
CasingStrings(CompletionsSet="CompletionsSet(well_petrel_name="A15")")
Using a for loop we can iterate through the casings and assign one to a variable:

for c in casings:
    print(c)
    selected_casing = c
CasingString("Casing 1")
CasingString("Casing 2")
selected_casing
CasingString("Casing 2")
To return the name of the casing we can use the .petrel_name property:

selected_casing.petrel_name
'Casing 2'
The path of the object represents it’s location in the Petrel input tree and can be accessed using the .path property:

selected_casing.path
'Input/Wells/Producers/A15/Completions/Casing 2'
The .droid property returns the object id or guid which represents the Petrel filename in the project directory:

selected_casing.droid
'30a18f16-0840-458d-b7c2-0c8be5bfb32d'
We can retrieve the statistics of the casing associated to the selected well using the .retrieve_stats() function which outputs a dictionary:

selected_casing.retrieve_stats()
{'X Min': '456645.06',
 'X Max': '456676.11',
 'Y Delta': '-169.080000000075',
 'Y Min': '6781579.73',
 'Z Delta': '-148.39',
 'Z Min': '-1808.89',
 'X Delta': '31.0499999999884',
 'Type of completion': 'Casing',
 'Z Max': '-1957.28',
 'Y Max': '6781410.65'}
The statistics are a snapshot of the information in the Statistics located in Settings panel of the object.

statistics.png
The .retrieve_history() function will return the Petrel history of the object as a dataframe.

selected_casing.retrieve_history()
Date	User	Action	Description
To access the equipment associated with the casings you can use the .available_equipment() function which will return a list of all the equipment IDs:

completions.available_casing_equipment()
['CS_EQ1', 'C-API-4.500/J-55/9.50', 'C-API-4.500/C-95/11.60', 'C-API-5.000/J-55/11.50', 'C-API-5.000/C-95/15.00', 'C-API-5.500/J-55/14.00', 'C-API-5.500/C-95/17.00', 'C-API-6.625/J-55/20.00', 'C-API-6.625/C-95/24.00', 'C-API-7.000/J-55/20.00', 'C-API-7.000/C-95/23.00', 'C-API-7.625/J-55/26.40', 'C-API-7.625/C-95/47.10', 'C-API-8.625/J-55/24.00', 'C-API-8.625/C-95/36.00', 'C-API-9.625/J-55/36.00', 'C-API-9.625/C-95/40.00', 'C-API-10.750/J-55/40.50', 'C-API-10.750/C-95/51.00', 'C-API-11.750/J-55/47.00', 'C-API-11.750/C-95/60.00', 'C-API-13.375/J-55/54.50', 'C-API-13.375/C-95/68.00', 'C-API-16.000/J-55/75.00', 'C-API-18.625/J-55/87.50', 'C-API-20.000/J-55/94.00']
In Petrel, the association between the completion and the equipment can be view in the Completion manager:

equipment.png
You can add a comment to the casing element using the .add_comment() function which takes in two parameters: new_comment , a string which represents the comment you want to add and overwrite , a boolean value which indicates if you want to add a new comment (overwrite=False) or overwrite the existing one (overwrite=True). The overwrite paramater defaults to False if not specified.

By default the casing object is set to readonly meaning you can not modify any of its attribute. To allow modifications you can use the .readonly property and set it to false:

selected_casing.readonly=False
selected_casing.add_comment(new_comment="Edited by user with Python Tool Pro",overwrite=False)
The code cell above will add a new comment into the Comments section in Petrel:

Ccomments.png
You can access the existing comments of a completion element using the .comments property which will return a string:

selected_casing.comments
'Edited by user with Python Tool Pro'
The .start_date property will return the start date of the casing string as a datetime object:

selected_casing.start_date
datetime.datetime(1980, 1, 1, 0, 0)
Assuming that the .readonly value of the selected object is set to false the start date of the object can be modified by assing a new date to the variable using the datetime() function which can take in the following parameters: Year, Month, Day, Hour, Minute, Second, Microsecond.

import datetime
selected_casing.start_date = datetime.datetime(2020,3,8,0,0)
selected_casing.start_date
datetime.datetime(2020, 3, 8, 0, 0)
In Petrel, the start date of the completions object can be viewed in the Completions manager:

start_date.png
The .bottom_md property returns the measured depth value of the bottom of the casing string:

selected_casing.bottom_md
2036.0
The bottom_md value can be modified by assigning it a new value. After executing the cell bellow the results will also be written to Petrel:

bottom_md.png
selected_casing.bottom_md=2000
The .parts property returns an iterable collection of the individual parts associated to the casing string:

selected_casing.parts
CasingStringParts(CasingString("Casing 2"))
New functionality in Python Tool Pro version 2.3
With the release of Python Tool Pro version 2.3 new functionality has been added to casings. Users can now add casing string and casing parts.

Add a new casing string part to the casing string using the .add_part() function and provide the MD where existing casing parts are split to insert the new part and the name of casing equipment:

selected_casing.add_part(split_md = 1998,equipment_name='C-API-5.500/C-95/17.00')
CasingStringPart(Casing 2:2 (1998.0-2000.0))
Users can add new casing string to the completions set using the add_casing. A casing string part will also be added to the casing string using the supplied equipment name:

completions.add_casing(name = 'casing 3',
                           bottom_md = 2050,
                           equipment_name = completions.available_casing_equipment()[0],
                           start_date = datetime.datetime(2020,3,8,0,0)
                          )
CasingString("casing 3")
Perforation data
Check out the API documentation to view a detailed description of all the functions and properties available for Perforations.

You can assign the casing strings to a variable using the .perforations property which will return an iterable collection of the avaialbe perforations for the selected well :

perforations = completions.perforations
perforations
Perforations(CompletionsSet="CompletionsSet(well_petrel_name="A15")")
Using a for loop we can iterate through the casings and assign one to a variable:

for p in perforations:
    print(p)
    selected_perforation = p
Perforation("Perforation 1")
Perforation("Perforation 2")
selected_perforation
Perforation("Perforation 2")
To return the name of the perforation we can use the .petrel_name property:

selected_perforation.petrel_name
'Perforation 2'
The path of the object represents it’s location in the Petrel input tree and can be accessed using the .path property:

selected_perforation.path
'Input/Wells/Producers/A15/Completions/Perforation 2'
The .droid property returns the object id or guid which represents the Petrel filename in the project directory:

selected_perforation.droid
'c4bd86c7-b008-4628-9edb-30933e52978d'
We can retrieve the statistics of the perforation associated to the selected well using the .retrieve_stats() function which outputs a dictionary:

selected_perforation.retrieve_stats()
{'X Min': '456654.64',
 'X Max': '456658.39',
 'Y Delta': '-20.1299999998882',
 'Y Min': '6781528.03',
 'Z Delta': '-17.5899999999999',
 'Z Min': '-1855.26',
 'X Delta': '3.75',
 'Type of completion': 'Perforation',
 'Z Max': '-1872.85',
 'Y Max': '6781507.9'}
The statistics are a snapshot of the information in the Statistics located in Settings panel of the object:

P_Statistics.png
The .retrieve_history() function will return the Petrel history of the object as a dataframe.

selected_perforation.retrieve_history()
Date	User	Action	Description
You can add a comment to the perforation element using the .add_comment() function which takes in two parameters: new_comment , a string which represents the comment you want to add and overwrite , a boolean value which indicates if you want to add a new comment (overwrite=False) or overwrite the existing one (overwrite=True). The overwrite paramater defaults to False if not specified.

By default the perforation object is set to readonly meaning you can not modify any of its attribute. To allow modifications you can use the .readonly property and set it to false:

selected_perforation.readonly=False
selected_perforation.add_comment(new_comment='Perforation modified using Python Tool Pro', overwrite=False)
The code cell above will add a new comment into the Comments section in Petrel:

P_comments.png
You can access the existing comments of a completion element using the .comments property which will return a string:

selected_perforation.comments
'Perforation modified using Python Tool Pro'
The .start_date property will return the start date of the perforation as a datetime object:

selected_perforation.start_date
datetime.datetime(1980, 1, 1, 0, 0)
Assuming that the .readonly value of the selected object is set to false the start date of the object can be modified by assing a new date to the variable using the datetime() function which can take in the following parameters: Year, Month, Day, Hour, Minute, Second, Microsecond.

import datetime
selected_perforation.start_date = datetime.datetime(2020,8,5,0,0)
selected_perforation.start_date
datetime.datetime(2020, 8, 5, 0, 0)
In Petrel, the start date of the completions object can be viewed in the Completions manager:

P_start_Date.png
The .skin_factor property returns skin factor of the perforation as a float value:

selected_perforation.skin_factor
0.0
The skin_factor value can be modified by assigning it a new value. After executing the cell bellow the results will also be written to Petrel:

skin_factor.png
selected_perforation.skin_factor = 1
The .bottom_md property returns the measured depth value of the bottom of the perforation and it can be modified by assigning it a new value:

selected_perforation.bottom_md
selected_perforation.bottom_md= 2100
The .start_md property returns the measured depth value of the top of the perforation and it can be modified by assigning it a new value:

selected_perforation.top_md
selected_perforation.top_md=1900
1879.0
You can add a new perforation to the completions data of the selected well by using the .add_perforation function and providing 3 input parameters : the name of the new perforation and the measured depth of top and bottom and the perforation. This is an expiremental function so make sure to set the allow_experimental flag to true when defining your Petrel connection ( i.e petrel = PetrelConnection(allow_experimental=True))

completions.add_perforation(name="New Perforation",top_md=1850,bottom_md=1870)
Perforation("New Perforation")
Plugbacks and Squeezes
Note: The ability to access Plugbacks and Squeezes is a feature available Python Tool Pro version 2.3.

Plugbacks
Check out the API documentation to view a detailed description of all the functions and properties available for Plugbacks.

You can assign the plugbacks to a variable using the .plugbacks property which will return an iterable collection of the available plugbacks strings for the selected well :

plugbacks=completions.plugbacks
plugbacks
Plugbacks(CompletionsSet="CompletionsSet(well_petrel_name="A15")")
Using a for loop we can iterate through the casings and assign one to a variable:

for p in plugbacks:
    print(p)
    selected_plugback = p
Plugback("Plugback 1")
Plubacks also allow most of the same properties and methods as other objects, such as the .petrel_name, .droid, .readonly, .path:

selected_plugback.petrel_name
'Plugback 1'
selected_plugback.droid
'f899d060-4742-4a1b-aec6-557718d77798'
selected_plugback.readonly
True
selected_plugback.path
'Input/Wells/Producers/A15/Completions/Plugback 1'
We can retrieve the statistics of the plugback associated to the selected well using the .retrieve_stats() function which outputs a dictionary:

selected_plugback.retrieve_stats()
{'Z Delta': '-89.0999999999999',
 'Type of completion': 'Plugback',
 'Z Min': '-1898.99',
 'Y Max': '6781374.57',
 'X Max': '456682.11',
 'X Delta': '17.8499999999767',
 'Y Delta': '-103.139999999665',
 'Z Max': '-1988.09',
 'X Min': '456664.26',
 'Y Min': '6781477.71'}
Plugbacks are now visible when retrieving the complentions as a dataframe using the as_dataframe() function:

completions.as_dataframe()
Well name	UWI	Category	Type	Name	Top MD	Bottom MD	Outer Diameter	Inner Diameter	Start Date	Is Valid
0	A15		Casing	Casing string	Casing 1	1808.89	1900.00	NaN	NaN	1980-01-01	True
1	A15		Casing	Casing part	Casing 1:1	1808.89	1900.00	11.750	10.772	1980-01-01	True
2	A15		Casing	Casing string	Casing 2	1808.89	2000.00	NaN	NaN	1981-01-01	True
3	A15		Casing	Casing part	Casing 2:1	1808.89	1998.00	4.500	4.000	1981-01-01	True
4	A15		Casing	Casing part	Casing 2:2	1998.00	2000.00	5.500	4.892	1981-01-01	True
5	A15		Casing	Casing string	casing 3	1808.89	1950.00	NaN	NaN	1980-01-01	True
6	A15		Casing	Casing part	casing 3:1	1808.89	1950.00	8.625	8.097	1980-01-01	True
7	A15		Workovers	Perforation	Perforation 1	1922.00	1992.00	NaN	NaN	1980-01-01	True
8	A15		Workovers	Perforation	Perforation 2	1879.00	1906.00	NaN	NaN	1980-01-01	True
9	A15		Workovers	Plugback	Plugback 1	1946.36	2083.82	NaN	NaN	1980-01-01	True
We can now also add a new plugback to the completions set using the .set function and passing in the name of the plugback, and topMD:

completions.add_plugback(name ='new plugback',
                             top_md = 1990
                            )
Plugback("new plugback")
We can see the new plugback when updating the completions dataframe:

completions.as_dataframe()
Well name	UWI	Category	Type	Name	Top MD	Bottom MD	Outer Diameter	Inner Diameter	Start Date	Is Valid
0	A15		Casing	Casing string	Casing 1	1808.89	1900.00	NaN	NaN	1980-01-01	True
1	A15		Casing	Casing part	Casing 1:1	1808.89	1900.00	11.750	10.772	1980-01-01	True
2	A15		Casing	Casing string	Casing 2	1808.89	2000.00	NaN	NaN	1981-01-01	True
3	A15		Casing	Casing part	Casing 2:1	1808.89	1998.00	4.500	4.000	1981-01-01	True
4	A15		Casing	Casing part	Casing 2:2	1998.00	2000.00	5.500	4.892	1981-01-01	True
5	A15		Casing	Casing string	casing 3	1808.89	1950.00	NaN	NaN	1980-01-01	True
6	A15		Casing	Casing part	casing 3:1	1808.89	1950.00	8.625	8.097	1980-01-01	True
7	A15		Workovers	Perforation	Perforation 1	1922.00	1992.00	NaN	NaN	1980-01-01	True
8	A15		Workovers	Perforation	Perforation 2	1879.00	1906.00	NaN	NaN	1980-01-01	True
9	A15		Workovers	Plugback	Plugback 1	1946.36	2083.82	NaN	NaN	1980-01-01	True
10	A15		Workovers	Plugback	new plugback	1990.00	2083.82	NaN	NaN	2001-06-30	True
Squeezes
Check out the API documentation to view a detailed description of all the functions and properties available for Squeezes.

You can assign the squezees to a variable using the .squeezes property which will return an iterable collection of the available plugbacks strings for the selected well :

squeezes=completions.squeezes
squeezes
Squeezes(CompletionsSet="CompletionsSet(well_petrel_name="A15")")
Using a for loop we can iterate through the casings and assign one to a variable:

for s in squeezes:
    print(s)
    selected_squeeze = s
Squeeze("Squeeze 1")
Squeezes also allow most of the same properties and methods as other objects, such as the .petrel_name, .droid, .readonly, .path:

selected_squeeze.petrel_name
'Squeeze 1'
selected_squeeze.droid
'f8b1f513-ae68-42a6-9875-864f0c7c9258'
selected_squeeze.readonly=False
selected_squeeze.readonly
False
selected_squeeze.path
'Input/Wells/Producers/A15/Completions/Squeeze 1'
We can retrieve the statistics of the squeeze associated to the selected well using the .retrieve_stats() function which outputs a dictionary:

selected_squeeze.retrieve_stats()
{'Z Min': '-1868.95',
 'Y Max': '6781512.37',
 'Type of completion': 'Squeeze',
 'Z Max': '-1868.95',
 'Y Delta': '0',
 'X Delta': '0',
 'Z Delta': '0',
 'X Min': '456657.54',
 'Y Min': '6781512.37',
 'X Max': '456657.54'}
The start date of selected squeeze can be modified by assing a new date to the variable using the datetime() function which can take in the following parameters: Year, Month, Day, Hour, Minute, Second, Microsecond.

import datetime
selected_squeeze.start_date = datetime.datetime(2020,8,5,0,0)
selected_squeeze.start_date
datetime.datetime(2020, 8, 5, 0, 0)
The .top_md and .bottom_md properties return the measured depth value of the top and bottom of the squeeze and can be modified by assigning it a new value:

selected_squeeze.top_md=1880
selected_squeeze.bottom_md=1900
Squeezes are now visible when retrieving the complentions as a dataframe using the as_dataframe() function:

completions.as_dataframe()
Well name	UWI	Category	Type	Name	Top MD	Bottom MD	Outer Diameter	Inner Diameter	Start Date	Is Valid
0	A15		Casing	Casing string	Casing 1	1808.89	1900.00	NaN	NaN	1980-01-01	True
1	A15		Casing	Casing part	Casing 1:1	1808.89	1900.00	11.750	10.772	1980-01-01	True
2	A15		Casing	Casing string	Casing 2	1808.89	2000.00	NaN	NaN	1981-01-01	True
3	A15		Casing	Casing part	Casing 2:1	1808.89	1998.00	4.500	4.000	1981-01-01	True
4	A15		Casing	Casing part	Casing 2:2	1998.00	2000.00	5.500	4.892	1981-01-01	True
5	A15		Casing	Casing string	casing 3	1808.89	1950.00	NaN	NaN	1980-01-01	True
6	A15		Casing	Casing part	casing 3:1	1808.89	1950.00	8.625	8.097	1980-01-01	True
7	A15		Workovers	Perforation	Perforation 1	1922.00	1992.00	NaN	NaN	1980-01-01	True
8	A15		Workovers	Perforation	Perforation 2	1879.00	1906.00	NaN	NaN	1980-01-01	True
9	A15		Workovers	Plugback	Plugback 1	1946.36	2083.82	NaN	NaN	1980-01-01	True
10	A15		Workovers	Plugback	new plugback	1990.00	2083.82	NaN	NaN	2001-06-30	True
11	A15		Workovers	Squeeze	Squeeze 1	1880.00	1900.00	NaN	NaN	2020-08-05	True
We can now also add a new squeeze to the completions set using the .set function and passing in the name of the squeeze, and topMD:

completions.add_squeeze(name = 'new squeeze',
                           top_md=1910,
                           bottom_md=1930
                           )
Squeeze("new squeeze")
We can see the new squeeze when updating the completions dataframe:

completions.as_dataframe()
Well name	UWI	Category	Type	Name	Top MD	Bottom MD	Outer Diameter	Inner Diameter	Start Date	Is Valid
0	A15		Casing	Casing string	Casing 1	1808.89	1900.00	NaN	NaN	1980-01-01	True
1	A15		Casing	Casing part	Casing 1:1	1808.89	1900.00	11.750	10.772	1980-01-01	True
2	A15		Casing	Casing string	Casing 2	1808.89	2000.00	NaN	NaN	1981-01-01	True
3	A15		Casing	Casing part	Casing 2:1	1808.89	1998.00	4.500	4.000	1981-01-01	True
4	A15		Casing	Casing part	Casing 2:2	1998.00	2000.00	5.500	4.892	1981-01-01	True
5	A15		Casing	Casing string	casing 3	1808.89	1950.00	NaN	NaN	1980-01-01	True
6	A15		Casing	Casing part	casing 3:1	1808.89	1950.00	8.625	8.097	1980-01-01	True
7	A15		Workovers	Perforation	Perforation 1	1922.00	1992.00	NaN	NaN	1980-01-01	True
8	A15		Workovers	Perforation	Perforation 2	1879.00	1906.00	NaN	NaN	1980-01-01	True
9	A15		Workovers	Plugback	Plugback 1	1946.36	2083.82	NaN	NaN	1980-01-01	True
10	A15		Workovers	Plugback	new plugback	1990.00	2083.82	NaN	NaN	2001-06-30	True
11	A15		Workovers	Squeeze	Squeeze 1	1880.00	1900.00	NaN	NaN	2020-08-05	True
12	A15		Workovers	Squeeze	new squeeze	1910.00	1930.00	NaN	NaN	2001-06-30	True

Marker Collections
This section offers an overview of the different functions and properties available for the Petrel Marker collection objects.

The cells below show how a marker collection can be accessed, converted to a DataFrame and then how to do different operations including:

adding a new marker to a well

changing marker attribute values such as depths

creating a new marker attribute

All data used in this notebook comes from the FORCE wells dataset:

NPD, 2021, FORCE 2020 Lithology Machine Learning Competition Results: https://www.npd.no/en/force/Previous-events/results-of-the-FORCE-2020-lithology-competition/

import numpy as np

from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection(allow_experimental=True)
print('Connected to {}'.format(ptp.get_current_project_name()))
Connected to PWR_Demo_Project.pet
Check out the API documentation to view a detailed description of all the functions and properties available for marker collections.

To retrieve all the marker collections from our Petrel project we can use the .markercollections property. This property returns all the marker collections within the project in a dictionary where the keys represent the path of the marker collection within the Petrel input tree and the value represents the name of the marker collection.

ptp.markercollections
MarkerCollections({'Input/NPD_Update_WellTops': MarkerCollection(petrel_name="NPD_Update_WellTops"), 'Input/Gullfaks WellTops': MarkerCollection(petrel_name="Gullfaks WellTops")})
Using list comprehension, the marker collections can be viewed as a list:

marker_list = [mc for mc in ptp.markercollections]
marker_list
[MarkerCollection(petrel_name="Gullfaks WellTops"),
 MarkerCollection(petrel_name="NPD_Update_WellTops")]
Select the first marker in the marker list and get its path using the .path property:

marker_path = marker_list[0].path
marker_path
'Input/Gullfaks WellTops'
Let’s access the marker collection that is in position 0 of a list of marker collections from the path we grabbed above:

mc = ptp.markercollections[marker_path]
mc
MarkerCollection(petrel_name="Gullfaks WellTops")
Like other Petrel objects, the API lets us view the statistics for our marker collection with the .retrieve_stats() function:

mc.retrieve_stats()
Marker collection comments
We can access comments on the marker collection using the .comments property.

At first we have no comments. The marker collection attribute comments therefore returns an empty string ‘ ‘

mc.comments
We can add a comment using the add_comment() function. It is important to set the .readonly property on the marker collection as False:

mc.readonly = False
mc.add_comment(new_comment = 'Formation data from NPD')
Checking the comments attribute again we can see that the comment has been added:

mc.comments
Convert to a DataFrame
Marker collections can also be converted to a DataFrame using the .as_dataframe() function.

mc_df = mc.as_dataframe()
mc_df.head(10)
[col for col in mc_df.columns]
Marker stratigraphies
We can get a marker stratigraphy by using the .stratigraphies property. We can use list comprehension and slicing to view the first ten stratigraphies:

stratigraphies = [strat for strat in mc.stratigraphies]
stratigraphies[0:10]
[MarkerStratigraphy("Surface"),
 MarkerStratigraphy("Base Cretaceous"),
 MarkerStratigraphy("Top Tarbert"),
 MarkerStratigraphy("Tarbert2"),
 MarkerStratigraphy("Tarbert1"),
 MarkerStratigraphy("Top Ness"),
 MarkerStratigraphy("Ness1"),
 MarkerStratigraphy("Top Etive")]
strat=mc.stratigraphies[3]
strat
MarkerStratigraphy("Tarbert2")
print(strat.petrel_name)
print(strat.path)
print(strat.droid)
print(strat.comments)
print(strat.template)
Tarbert2
Input/Gullfaks WellTops/Stratigraphy/Tarbert2
fe4b3e69-8cda-4071-be79-49dd1421b2cc


strat
MarkerStratigraphy("Tarbert2")
Marker attributes
We can access the attributes for the marker collection using the .attributes property. We can use list comprehension and slicing to view the first ten attributes:

attributes = [attr for attr in mc.attributes]
attributes[0:10]
depth = mc.attributes["MD"]
We can then pick up the MD attribute and then convert it to a DataFrame using the .as_dataframe() function:

depth_df = depth.as_dataframe()
depth_df.head()
Filter options on as_dataframe() - New in Python Tool Pro 2.3
To allow a more targeted retrieval of well markers and to improve performance various filter options are available. Supported Filter Options: * Well objects * Stratigraphy objects * Marker attributes Further it is possible to exclude the Petrel index from the DataFrame.

Well filter
my_well = [i for i in ptp.wells][0]
my_well2= [i for i in ptp.wells][1]
df = mc.as_dataframe(wells_filter=[my_well,my_well2])
df
Stratigraphy filter
strats = stratigraphies[0:3]
df = mc.as_dataframe(marker_stratigraphies_filter=strats)
df
Attribute filter
attr_ls = attributes[-3:-1]
df = mc.as_dataframe(marker_attributes_filter=attr_ls)
df
Exclude Petrel index
df = mc.as_dataframe(include_petrel_index=False)
df
Changing the value of an attribute
We can change the value of an attribute by using the set_value() function. When changing the value of one marker the set_value() function takes in a data array of the new value to be set, the marker stratigraphy and a wellbore object.

Lets take the first marker from the depth_df DataFrame above by selecting the Surface value from the first row. By adding an if clause in the list comprehension we can find the right stratigraphy from all of the available marker stratigraphies:

strat = [i for i in mc.stratigraphies if depth_df.loc[0]['Surface'] in str(i)][0]
strat
Now we can pick up the well value for the first row of the depth_df DataFrame and select its wellbore object from Petrel:

well = [i for i in petrel.wells if depth_df.loc[0]['Well identifier (Well name)'] in i.petrel_name][0]
well
We can grab the original depth value from the DataFrame we created from the MD attribute above by selecting the Value column from the first row of the depth_df DataFrame, which returns a float. The set_values() function takes in an array, so we convert this single depth value to a numpy array using the np.array() function.

In the set_values() method we can pass in the original depth + 1, the marker stratigraphy and the wellbore:

original_depth = np.array([depth_df.loc[0].Value])
original_depth
depth.set_values(data = original_depth+1,
                 include_unconnected_markers = True,
                 marker_stratigraphy = strat,
                 well = well
                )
To check that the value has changed, we can create a new marker collection object, pick up the MD attribute and then get a DataFrame. The depth value has now increased by 1.

mc2 = petrel.markercollections[marker_path]
depth2 = mc2.attributes["MD"]
depth2.as_dataframe().head()
When changing the values for every marker in the marker collection, an array of values can be passed to the data parameter in the set_values() function. The array must be the same length as the original marker collection, otherwise the marker stratigraphy and well values must be specified.

In this example we take the original depth values and simply add 10.

Note that when we access all the values in the depth_df DataFrame, it already returns an array.

depth.set_values(data = depth_df.Value.values+10,
                 include_unconnected_markers = True
                )
To check that this worked as expected, we pick up the marker collection again and convert to a DataFrame:

mc_plus10 = ptp.markercollections[marker_path]
depth_plus10 = mc_plus10.attributes["MD"].as_dataframe()
depth_plus10.head()
Adding a new attribute to a marker collection
Using the .add_attribute() function we can add a new attribute to the marker collection. This function takes in the data that we want to add, the name of the attribute nad the data type (continuous or false). Furthermore, we can provide a MarkerStratigraphy to include only markers for one specified stratigraphy. Lastly, we can also provide a well to include only markers for a specified well:

mc_plus10.readonly = False
mc_plus10.add_attribute(depth_plus10.Value.values/1000, 'kms', 'continuous' )
mc_add_attr = ptp.markercollections[marker_path]
[i for i in mc_add_attr.attributes if 'kms' in i.petrel_name]
mc_plus10.attributes['kms'].as_dataframe().head()
Adding a marker to a marker collection
We can add a new marker to a marker collection by using the add_marker() function which takes in three parameters

well: a wellbore petrel object of type cegalprizm.pythontool.borehole.Well

marker_stratigraphy: a marker stratigraphy of type cegalprizm.pythontool.markerstratigraphy.MarkerStratigraphy

measured_depth

First we can grab a Well object using petrel.wells for the well that occurs first in our marker collection (first row):

well_name = depth_df.loc[0]['Well identifier (Well name)']
well = ptp.wells[[i.path for i in ptp.wells if well_name in i.petrel_name][0]]
well
type(well)
Lets take a look at the existing markers for this well.

mc_df.loc[mc_df['Well identifier (Well name)']==well.petrel_name][['Well identifier (Well name)',
                                                                   'Surface',
                                                                   'MD',]]
We can find which stratigraphies that do not exist in this well and select the first one

all_stratigraphies = [i for i in mc.stratigraphies]
well_stratigraphies = [i for i in mc_df.Surface]
stratigraphy = list(set(all_stratigraphies)-set(well_stratigraphies))[0]
stratigraphy
A new marker can be added for the well, using the add_marker() function and passing in the wellbore object for the well, the marker_stratigraphy we want to add and a measured depth:

mc.readonly=False
mc.add_marker(well=well, marker_stratigraphy=stratigraphy, measured_depth=50)
To check if the new marker has been added, the marker collection can be picked up again as a DataFrame and then filtered down to the well of interest

mc_added_marker = petrel.markercollections[marker_path]
mc_df_added_marker = mc_added_marker.as_dataframe()
mc_df_added_marker.loc[mc_df_added_marker['Well identifier (Well name)']==well.petrel_name][['Well identifier (Well name)',
                                                                   'Surface',
                                                                   'MD',]]
API enhancments in Python Tool Pro 2.7
Note: With the release of Python Tool Pro version 2.7 the MarkerCollection API has been enhanced to support the creation of new marker collections and the addition of new markers.

Create a new well tops folder (MarkerCollection)
The method create_markercollection() has been added to the PetrelConnection class, allowing users to create new marker collections (well tops folders):

from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()

# Create a new marker collection in the project
new_marker_collection = petrel.create_markercollection("My New Well Tops Folder")
The image below shows the newly create WellTops folder in the Petrel input tree:

mc.png
Access to Stratigraphy Zones
Stratigraphy zones are now a supported domain object. This includes the ability to access existing zones and create new ones programmatically.

zones.png
Zones can be retrieved from well tops folders using the .zones property, which returns an iterable collection of all zones defined in the folder.

welltop_folder = petrel.markercollections["Input/WellTops"]
stratigraphy_zones = welltop_folder.zones
stratigraphy_zones
StratigraphyZones(marker collection="MarkerCollection(petrel_name="WellTops")")
You can list all available zones by iterating over them and printing their names:

for zn in stratigraphy_zones:
    print(zn.petrel_name)
Zone 1
Zone 1.1
Zone 1.2
Zone 2
You can access a zone by its index in the collection:

stratigraphy_zones[0]
StratigraphyZone("Zone 1")
You can also retrieve a specific zone by name using dictionary-style indexing:

zone1 = stratigraphy_zones["Zone 1"]
zone1
StratigraphyZone("Zone 1")
zone1_1 = stratigraphy_zones["Zone 1.1"]
zone1_1
StratigraphyZone("Zone 1.1")
Methods and properties available for stratigraphy zones
The .petrel_name property returns the name of the zone as shown in Petrel.

zone1.petrel_name
'Zone 1'
The .path property returns the path of the zone in the Petrel input tree.

zone1.path
'Input/WellTops/Stratigraphy/Zone 1'
The .droid property returns the Petrel Droid (unique object ID or GUID).

zone1.droid
'188f686e-b0f5-4374-8825-eecd7044ffd1'
The .readonly property indicates whether the zone is read-only; set it to False to enable editing.

zone1.readonly
True
The .add_comment() method adds a comment to the zone’s existing comments or replaces them. Use add_comment(“Comment text”, overwrite=False) to append, or set overwrite=True to replace all existing comments.

# set the readonly status to false so the zone can be edited
zone1.readonly = False

# Add a comment
zone1.add_comment('Comment added by Python Tool Pro',overwrite=False)
The .comments property returns any comments on the zone as a string (or an empty string if none).

zone1.comments
'Comment added by Python Tool Pro'
The .retrieve_stats() method returns a dictionary summarizing the statistics for the object:

zone1.retrieve_stats()
{'Number of points in the filter': '0',
 'Z Delta': 'NaN',
 'X Delta': 'NaN',
 'TWT auto Delta': 'NaN',
 'Long Min': 'NaN',
 'X Max': 'NaN',
 'Lat Min': 'NaN',
 'Y Min': 'NaN',
 'TWT auto Max': 'NaN',
 'Y Max': 'NaN',
 'Y Delta': 'NaN',
 'TWT auto Min': 'NaN',
 'X Min': 'NaN',
 'Long Delta': 'NaN',
 'MD Delta': 'NaN',
 'Lat Max': 'NaN',
 'Original CRS': 'ED50-UTM31 ("MENTOR:ED50-UTM31:European 1950 Based UTM, Zone 31 North, Meter") [SIS,501080]',
 'Lat Delta': 'NaN',
 'Long Max': 'NaN',
 'MD Min': 'NaN',
 'MD Max': 'NaN',
 'TWT picked Delta': 'NaN',
 'TWT picked Max': 'NaN',
 'TWT picked Min': 'NaN',
 'Z Max': 'NaN',
 'Z Min': 'NaN'}
You can use the .markercollection property to get the parent marker collection that contains the zone:

zone1.markercollection
MarkerCollection(petrel_name="WellTops")
The .children property returns the immediate children of a zone. Children can be either StratigraphyZone objects (sub-zones) or MarkerStratigraphy objects (horizons).

zone1.children
[StratigraphyZone("Zone 1.1"),
 MarkerStratigraphy("Horizon 1.1"),
 StratigraphyZone("Zone 1.2")]
You can use the .parent_zone property to access the parent zone of a StratigraphyZone:

zone1_1.parent_zone
StratigraphyZone("Zone 1")
You can rename a stratigraphy zone in Petrel using the .set_petrel_name() method:

# set the readonly status to false so the zone can be edited
zone1.readonly = False
zone1.set_petrel_name("New Name")
New MarkerCollection Properties
Use the .horizons property to get only the horizons in the marker collection, skipping any non-horizon objects.

welltop_folder = petrel.markercollections["Input/WellTops"]
# Retrieve all horizons
horizons = welltop_folder.horizons
horizons
StratigraphyHorizons(marker collection="MarkerCollection(petrel_name="WellTops")")
Horizons can be iterated over or accessed by index or name:

# Iterate through all horizons
for h in horizons:
    print(h.petrel_name)

# Access by index
first_horizon = horizons[0]

# Access by name
horizon_by_name = horizons["Horizon 1"]

Horizon 1
Horizon 1.1
Horizon 2
Horizon 3
Use .stratigraphy_hierarchy to get the full hierarchy of zones and horizons in the marker collection. The order matches what you see in Petrel’s Stratigraphy folder, with all nodes expanded.

welltop_folder.stratigraphy_hierarchy()
[MarkerStratigraphy("Horizon 1"),
 StratigraphyZone("Zone 1"),
 StratigraphyZone("Zone 1.1"),
 MarkerStratigraphy("Horizon 1.1"),
 StratigraphyZone("Zone 1.2"),
 MarkerStratigraphy("Horizon 2"),
 StratigraphyZone("Zone 2"),
 MarkerStratigraphy("Horizon 3")]
To print a formatted view of the hierarchy in the console, use print_hierarchy=True:

welltop_folder.stratigraphy_hierarchy(print_hierarchy=True)
├── Horizon 1
├── Zone 1
│   ├── Zone 1.1
│   ├── Horizon 1.1
│   └── Zone 1.2
├── Horizon 2
├── Zone 2
└── Horizon 3
[MarkerStratigraphy("Horizon 1"),
 StratigraphyZone("Zone 1"),
 StratigraphyZone("Zone 1.1"),
 MarkerStratigraphy("Horizon 1.1"),
 StratigraphyZone("Zone 1.2"),
 MarkerStratigraphy("Horizon 2"),
 StratigraphyZone("Zone 2"),
 MarkerStratigraphy("Horizon 3")]
If you only want top-level objects, set include_subzones=False:

welltop_folder.stratigraphy_hierarchy(include_subzones=False)
[MarkerStratigraphy("Horizon 1"),
 StratigraphyZone("Zone 1"),
 MarkerStratigraphy("Horizon 2"),
 StratigraphyZone("Zone 2"),
 MarkerStratigraphy("Horizon 3")]
New MarkerStratigraphy Properties
welltop_folder = petrel.markercollections["Input/WellTops"]
stratigraphies = welltop_folder.stratigraphies
stratigraphies
MarkerStratigraphies(marker collection="MarkerCollection(petrel_name="WellTops")")
List of the stratigraphies objects availbale in the WellTops marker collection:

[el for el in stratigraphies]
[MarkerStratigraphy("Horizon 1"),
 MarkerStratigraphy("Horizon 1.1"),
 MarkerStratigraphy("Horizon 2"),
 MarkerStratigraphy("Horizon 3")]
The horizon_type property returns the type of the horizon as a string, matching the Horizon type dropdown in Petrel.

horType.png
hor1 = stratigraphies['Horizon 1']
print("Horizon type:", hor1.horizon_type)
Horizon type: Conformable
You can set a new horizon type using a string:

hor1.readonly=False
hor1.horizon_type = "Erosional"

print(hor1.horizon_type)
Erosional
Or using the HorizonTypeEnum:

from cegalprizm.pythontool import HorizonTypeEnum

hor1.readonly=False
hor1.horizon_type = HorizonTypeEnum.Discontinuous

print(hor1.horizon_type)
Discontinuous
Use the is_horizon property to see whether the object is a horizon:

hor1.is_horizon
True
The parent_zone property returns the StratigraphyZone the horizon belongs to:

hor1_1 = stratigraphies['Horizon 1.1']

hor1_1.parent_zone
StratigraphyZone("Zone 1")
Create new Stratigraphies
Python Tool Pro provides four ways to create horizons and stratigraphy zones in a marker collection.

These methods replicate the same functionality you see in Petrel when you right-click and select Insert zone/horizon, as shown in the image below:

image.png
Available creation methods:

create_zone_and_horizon() Creates the first horizon if none exists, or appends a new zone and horizon at the bottom.

create_zone_and_horizon_above() Inserts a zone and horizon above a reference horizon or zone.

create_zone_and_horizon_below() Inserts a zone and horizon below a reference horizon or zone.

create_zones_and_horizon_inside() Creates two nested zones and a horizon inside a reference zone.

These options allow you to build stratigraphy hierarchies programmatically in the same way you would do manually in Petrel.

Example
In this example, we’ll create a new wellTops folder and build a stratigraphy structure identical to the image shown below.

image.png
1. Create a New Marker Collection
welltop_folder = petrel.create_markercollection("New WellTop Folder")

# set its readonly status to false so we can modify it
welltop_folder.readonly=False

welltop_folder
MarkerCollection(petrel_name="New WellTop Folder")
2. Create the first horizon
To create the first horizon we use the create_zone_and_horizon() method.

This method creates either the first horizon in a MarkerCollection or, if a horizon already exists, create a new zone and horizon at the bottom of the stratigraphy.

The type of the horizon can be set using the optional horizon_type argument. If not provided, the type will be set to “Conformable”.

first_hor = welltop_folder.create_zone_and_horizon(horizon_name="First horizon",horizon_type="Conformable")
print("First horizon:", first_hor.petrel_name)
First horizon: First horizon
We now have the new welltop folder and our fist horizon:

image.png
3. Create the second horizon and the first zone
We can now create a second horizon below the first one and a new zone between the two horizons. To do that we can use the .create_zone_and_horizon_below() method.

This method creates a new zone and horizon below the given reference object. The reference object can be either a Zone or a Horizon. If the reference object is a Zone, the new horizon will be created directly below the reference zone, and the new zone will be created below the newly created horizon.

If the reference object is a horizon the new zone will be created below the reference horizon, and the new horizon will be created below the newly created zone.

first_zone, second_hor = welltop_folder.create_zone_and_horizon_below(
    reference_object=first_hor,
    zone_name="First Zone",
    horizon_name="Second Horizon",
    horizon_type="Conformable"
)

print("Zone:", first_zone.petrel_name)
print("Horizon:", second_hor.petrel_name)
Zone: First Zone
Horizon: Second Horizon
We’ve now created the second horizon and our first zone:

image.png
4. Create the third horizon and the second zone
To create the third horizon and the second zone we can use the .create_zone_and_horizon_below() method again and this time refernce the second horizon :

second_zone, third_hor = welltop_folder.create_zone_and_horizon_below(
    reference_object=second_hor,
    zone_name="Second Zone",
    horizon_name="Third Horizon",
    horizon_type="Conformable"
)

print("Zone:", second_zone.petrel_name)
print("Horizon:", third_hor.petrel_name)
Zone: Second Zone
Horizon: Third Horizon
image.png
5. Create the nested horizon and zones
To create a horizon inside of an existing zone we need to use the .create_zones_and_horizon_inside() method:

This method creates two new zones and a new horizon inside the given reference zone. The new zones will be created above and below the new horizon. The reference zone must be a Zone object.

nested_zone_bottom, nested_horizon, nested_zone_top = welltop_folder.create_zones_and_horizon_inside(
    reference_zone=second_zone,
    zone_name_bottom="Nested Zone Bottom",
    horizon_name="Nested Horizon",
    zone_name_top="Nested Zone Top",
    horizon_type="Base"
)

print("Bottom zone:", nested_zone_bottom.petrel_name)
print("Nested horizon:", nested_horizon.petrel_name)
print("Top zone:", nested_zone_top.petrel_name)
Bottom zone: Nested Zone Bottom
Nested horizon: Nested Horizon
Top zone: Nested Zone Top
Done! We have now created the nested zones and horizons and succesfully replicated the initial folder structure.

image.png

===================
Seismic data - 3D cubes, 2D lines,
This section offers an overview of the different functions and properties available for the Petrel Seismic object subcategories.

Seismic Cube
Check out the API documentation to view a detailed description of all the functions and properties available for Seismic Cubes.

To retrieve all the seismic cubes from our Petrel project we can use the .seismic_cubes property. This property returns all the seismic cubes within the project in a dictionary where the keys represent the path of the cube within the Petrel input tree and the value represents the name of the cube:

from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection()

all_cubes = ptp.seismic_cubes
print(all_cubes)
{'Input/Seismic/Gullfaks Seismic/Smooth Gullfaks': Seismic(petrel_name="Smooth Gullfaks"), 'Input/Seismic/Asterix Seismic/SeismicSegmenting_TraceAveraging [Crop] 1 [Realized] 1': Seismic(petrel_name="SeismicSegmenting_TraceAveraging [Crop] 1 [Realized] 1"), 'Input/Seismic/Asterix Seismic/Near3-15': Seismic(petrel_name="Near3-15"), 'Input/Seismic/Asterix Seismic/Far23-35': Seismic(petrel_name="Far23-35"), 'Input/Seismic/Asterix Seismic/Mid13-25': Seismic(petrel_name="Mid13-25"), 'Input/Seismic/Asterix Seismic/Fault_Demo_Input': Seismic(petrel_name="Fault_Demo_Input")}
Using a for loop, we can iterate through the dictionary and print out all the seismic cubes names:

for cube in ptp.seismic_cubes:
    print(cube.petrel_name)
ST8511r92 [General depth conversion]
Demo_Cube
ST8511r92 [StructSmooth] 1 [Realized] 1
Let’s select the Demo_Cube seismic cube. First, we save all the paths of the cubes to a list, the we can slice through the list and assign the selected value to the Demo_Cube variable:

cube_path = list(all_cubes.keys())
Demo_Cube_path = cube_path[1]
Demo_Cube=ptp.seismic_cubes[Demo_Cube_path]
print(Demo_Cube.petrel_name)
Demo_Cube
We can obtain the size of the grid by using the .extent property, which will return the number of nodes in the i, j and k directions. Seismic traces are indexed by i and j, with k specifying the sample number in a trace:

extent = Demo_Cube.extent
print(extent)
Extent(i=375, j=301, k=227)
With the release of Python Tool Pro 2.8 , a new domain property is now available for SeismicCube objects and returns the domain of the object as a string (e.g., Elevation Time, Elevation Depth). If no domain is available, an empty string is returned.

Demo_Cube.domain
The .coords_extent returns the extent of the seismic cube in world-coordinates (Xmin, Xmax, Ymin, Ymax, Zmin, Zmax):

coord_extent = Demo_Cube.coords_extent
print(f'x: {coord_extent.x_axis}')
print(f'y: {coord_extent.y_axis}')
print(f'z: {coord_extent.z_axis}')
x: AxisExtent(min=451187.180000, max=458842.610000)
y: AxisExtent(min=6780245.450000, max=6789707.300000)
z: AxisExtent(min=-2304.720000, max=-1396.000000)
The .has_same_parent() function checks if two cubes belong to the same parent collection and returns a boolean value. In the example below, we assign the other two cubes in our dictionary to the variables Cube0 and Cube1:

Cube0 = ptp.seismic_cubes[cube_path[0]]
Cube1 = ptp.seismic_cubes[cube_path[2]]
print(f'{Cube1} and {Demo_Cube} has same parent: {Cube1.has_same_parent(Demo_Cube)}')
print(f'{Cube0} and {Demo_Cube} has same parent: {Cube0.has_same_parent(Demo_Cube)}')

Seismic(petrel_name="ST8511r92 [StructSmooth] 1 [Realized] 1") and Seismic(petrel_name="Demo_Cube") has same parent: True
Seismic(petrel_name="ST8511r92 [General depth conversion]") and Seismic(petrel_name="Demo_Cube") has same parent: True
Using the .indices() and .position() functions we can obtain the centre of a seismic node with its coresponding indices. First, we assign the indices of a seismic node to the node_indices variable. For the indices parameters, we are using the i,j,k extents of the node and then use floor division to get the i,j,k of centre of the node. Once we have the i,j,k of the centre, we can then use the .position() function to get the XYZ position of the node centre based on the provided i,j,k parameters:

from cegalprizm.pythontool.primitives import Indices
from cegalprizm.pythontool.primitives import Point

node_indices = Indices(i = extent.i//2, j = extent.j//2, k = extent.k//3)
node_center_position = Demo_Cube.position(node_indices.i, node_indices.j, node_indices.k)
print(f'{node_indices}: {node_center_position}')
Indices(i=187, j=150, k=75): Point(x=455014.90, y=6784976.38, z=-1698.24)
Alternatively, we can obtain the indices of a seismic node at a specified XYZ position:

pos = node_center_position
node_indices_at_pos = Demo_Cube.indices(pos.x, pos.y, pos.z)
print(f'{pos}: {node_indices_at_pos}')
Point(x=455014.90, y=6784976.38, z=-1698.24): Indices(i=187, j=150, k=75)
The .annotation() function returns the annotations for seismic indices with inline, xline and sample of the given index(i,j,k directions, k-defaults to 0):

Demo_Cube.annotation(30,60)
Annotation(inline=212, xline=270, sample=1)
Similarly, the .annotation_indices() function returns the i,j and k index of a particular inline, crossline and sample number(defaults to 1):

Demo_Cube.annotation_indices(212,260)
Indices(i=30, j=55, k=0)
We can create a chunk that contains all the values in the entire seismic cube by using the .all() function. This can be an expensive operation in time and memory depending on the size of cube. To learn more about chunks please view the Working with chunks subchapter of the User Guide.

Demo_Cube.all()
Alternatively, we can create a chunk containing values in the ranges specified by using the .chunk() function:

cube_chunk = cube.chunk((0,1), (1,3), (0,3))
print(cube_chunk)
Chunk(backing_object=Seismic(petrel_name="ST8511r92 [StructSmooth] 1 [Realized] 1"), i=(0, 1), j=(1, 3), k=(0, 3))
Using the .clone() function, we can create a copy of the seismic cube. The copy_values parameter is optional and requires a boolean value. If the copy_values parameter is set to True, the values of the cube will be copied into the clone. By default, the copy_values is set to False, and the values are not copied to the clone. The cloned cube is placed in the same collection as the source object. A clone cannot be created with the same name as an existing Petrel object in the same collection:

cloneCube.png
Demo_Cube.clone('Demo_Cube_Copy',copy_values=True)
Seismic(petrel_name="Demo_Cube_Copy")
With the release of Python Tool Pro 2.8, the clone() method for SeismicCube objects has been extended with a new realize_path argument, allowing users to specify the filesystem location where the cloned cube will be realized. Previously, cloned seismic cubes were always realized inside the Petrel project data folder.

The updated clone() signature is: clone(name_of_clone, copy_values=False, template=None, realize_path='')

new_clone = Demo_Cube.clone(
    "MyClone",
    realize_path=r"C:\Seismic\CloneFolder"
)
Python Tool Pro 2.8 also introduced a new property, default_seismic_directory to the PetrelConnection. This allows retrieving the default seismic file directory defined in the Petrel system settings (System Settings → Seismic settings).

image.png
default_dir = ptp.default_seismic_directory
default_dir
'D:\\Petrel\\'
This path can be used when cloning a seismic volume

new_clone = Demo_Cube.clone(
    "MyClone",
    realize_path=default_dir
)
The set_value() function sets the values of the entire seismic cube to the value provided. This is useful to set all values to zero, but any value can be provided. The following example sets the value of the cloned cube (Demo_Cube_Copy) to 0:

amplitude_range.png
# Select the Demo_Cube_Copy:

all_cubes = ptp.seismic_cubes
cube_path = list(all_cubes.keys())
Copy_Demo_Cube_path = cube_path[3]
Copy_Demo_Cube=ptp.seismic_cubes[Copy_Demo_Cube_path]

# Set the readonly value of the cube to False so we can modify its values
Copy_Demo_Cube.readonly=False

#set all the values to 0
Copy_Demo_Cube.set_value(0)
True
Using .columns() function we can set all the amplitude values to a specific values across a range of i and j-slices. In the following example we replaced all the amplitudes values within the i-slices i=10 through i=19 with the 0 value. Before it we’ve set the readonly value of the seismic cube to false so we can modify the values. If we don’t specify the range it will replace all values. The results are written to Petrel in real time:

seismiccolumn.png
Demo_Cube.readonly=False
for col in Copy_Demo_Cube.columns(range(10, 20), jrange=None):
    col.set(0)
The .reconnect() function reconnects a 3D seismic object to the given file path.The file path has to be written with 2 backslashes. This method only works on external seismic objects with broken links:

reconnect.png
#select disconnected cube

lost_cube_path = list(all_cubes.keys())
reconnect_cube_path = lost_cube_path[2]
reconnect_cube=ptp.seismic_cubes[reconnect_cube_path]
print(reconnect_cube.petrel_name)
ST0202ZDC12-PZ-PSDM-KIRCH-FAR-T.MIG_FIN.POST_STACK.3D.JS-017534
#Use the .reconnect() function and provide the path to the seismic as an argument

reconnect_cube.reconnect("C:\\Users\\vladro\\OneDrive - Cegal AS\\Desktop\\ST0202ZDC12-PZ-PSDM-KIRCH-FAR-T.MIG_FIN.POST_STACK.3D.JS-017534.segy")
Seismic Lines
Check out the API documentation to view a detailed description of all the functions and properties available for 2D seismic lines.

To retrieve all the seismic cubes from our Petrel project we can use the .seismic_lines property. This property returns all the 2D seismic lines within the project in a dictionary where the keys represent the path of the 2D line within the Petrel input tree and the value represents the name of the 2D line:

all_lines=ptp.seismic_lines
print(all_lines)
{'Input/Seismic/Gullfaks 2D lines/2D_line166': SeismicLine(petrel_name="2D_line166"), 'Input/Seismic/Gullfaks 2D lines/2D_line482': SeismicLine(petrel_name="2D_line482"), 'Input/Seismic/Gullfaks 2D lines/2D_line450': SeismicLine(petrel_name="2D_line450")}
Using a for loop, we can iterate through the dictionary and print out all of the 2D line names:

for line in ptp.seismic_lines:
    print(line.petrel_name)
2D_line166
2D_line450
2D_line482
To assign the 2D line to a variable, we save all the paths of the lines to a list, we slice through it and assign the selected value to the seis_line variable:

seis_line_path = list(all_lines.keys())
seis_line_path = seis_line_path[2]
seis_line=petrel.seismic_lines[seis_line_path]
print(seis_line.petrel_name)
2D_line450
In the code block below we call the function retrieve_stats() which return the statistics of the 2D line. The statistics are a snapshot of the information in the Statistics page of the object in the Petrel input tree:

2dseisstats.png
seis_line.retrieve_stats()
{'Y Delta': '9331.75999999978',
 'Seismic (template) Max': '9216',
 'Seismic (template) Min': '-12032',
 'Seismic type': '2D',
 'Number of cells total': '85125',
 'Bulk has native multires': 'No',
 'X Max': '455080.09',
 'Number of traces': '375',
 'Line id': 'M00002 "C:\\Users\\vladro\\AppData\\Local\\Temp\\d91c302c-bc50-4df0-8061-b3cb5dad4e8b.segy"',
 'Geometry line name': 'Demo_Cube XLine 450 [2D Converted] 1',
 'Compression': 'None',
 'Bytes consumed by samples': '332.5 KB',
 'X Min': '454949.7',
 'Geometry line id': 'm00002 "C:\\Users\\vladro\\AppData\\Local\\Temp\\d91c302c-bc50-4df0-8061-b3cb5dad4e8b.segy"',
 'Is storage OK?': 'Yes',
 'Time Min': '-2304.68',
 'Time Max': '-1396',
 'Number of 2D lines': '1',
 'Original CRS': 'ED50-UTM31 ("MENTOR:ED50-UTM31:European 1950 Based UTM, Zone 31 North, Meter") [SIS,501080]',
 'Vintage': 'Seismic Time 1',
 'Number of samples per trace': '227',
 'Sample interval': '4.003',
 'Y Max': '6789642.26',
 'Absolute shift': '0.00',
 'Bulk value format': 'Floating point 32 bit',
 'File path': 'D:\\PetrelProjects\\CegalPrizm\\PWR_Demo_Project\\PWR_Demo_Project.ptd\\45e71b2f-ba65-46a3-a86d-c4595f29940f.raw',
 'Y Min': '6780310.5',
 'Line unique id': '36b47d09-e7d3-42bb-aa68-c56413ae49bb',
 'Original SRD': 'SRD Z=0.0 RV=1480.0',
 'Seismic (template) Delta': '21248',
 'Storage type': 'Petrel internal raw format',
 'Volume value format': 'Floating point 32 bit',
 'X Delta': '130.390000000014',
 'Target SRD': 'SRD Z=0.0 RV=1480.0',
 'Time Delta': '908.68',
 'Geometry unique id': '1cd901aa-fa18-4242-ad29-4cfcb5a65e10'}
With the release of Python Tool Pro 2.8 , a new domain property is now available for SeismicLine objects and returns the domain of the object as a string (e.g., Elevation Time, Elevation Depth). If no domain is available, an empty string is returned.

seis_line.domnain
In Python Tool Pro version 2.6 or higher it is possible to create chunks of the seismic 2D line. This introduces support to retrieve all values as an array or as an DataFrame.

chunk=seis_line.all()
chunk
<cegalprizm.pythontool.chunk.Chunk at 0x24cf5ea6bc0>
chunk.as_array()
array([[[-2560., -2560., -1536., ...,   256.,   768.,  1280.],
        [-1536.,  -768.,  -768., ...,  2816.,  3328.,  3328.],
        [-1280.,  -768.,  -768., ...,  2816.,  2816.,  2816.],
        ...,
        [-1024., -2048., -1792., ..., -1536., -2304., -2048.],
        [ -512.,  -512.,     0., ..., -2816., -4352., -4096.],
        [-2560., -2304.,  -768., ..., -3072., -4352., -4352.]]],
      dtype=float32)
chunk.as_dataframe()
I	J	K	Value
0	None	0	0	-2560.0
1	None	0	1	-2560.0
2	None	0	2	-1536.0
3	None	0	3	512.0
4	None	0	4	2816.0
...	...	...	...	...
85120	None	374	222	1792.0
85121	None	374	223	-768.0
85122	None	374	224	-3072.0
85123	None	374	225	-4352.0
85124	None	374	226	-4352.0
85125 rows × 4 columns
======
Seismic horizon interpretations and seismic fault interpretation
This notebook shows the API to access seismic horizon interpratations and fault interpretations. Cegal Prizm Python Tool Pro version 2.5 or higher is required.

#Connect to a Petrel project
from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection()
Horizon interpretation
Check out the API documentation to view a detailed description of all the functions and methods available for the Horizon objects.

To retrieve all the horizon interpretations from our Petrel project we can use the .horizonInterpretation3d property. This property returns all the horizon interpretations within the project in a dictionary where the keys represent the path of the interpretation within the Petrel input tree and the values represent the name of the interpretation:

all_horizons = ptp.horizon_interpretation_3ds
print(all_horizons)
{'Input/Seismic/Gullfaks horizon interpretations/Horizons for Wshop/Tabert outliers/Seismic Data': HorizonInterpretation3D(petrel_name="Seismic Data"), 'Input/Seismic/Gullfaks horizon interpretations/Horizons for Wshop/Top Etive/Gullfaks Seismic': HorizonInterpretation3D(petrel_name="Gullfaks Seismic"), 'Input/Seismic/Gullfaks horizon interpretations/Horizons for Wshop/Top Tarbert/Gullfaks Seismic': HorizonInterpretation3D(petrel_name="Gullfaks Seismic"), 'Input/Seismic/Gullfaks horizon interpretations/Horizons for Wshop/Top Ness/Gullfaks Seismic': HorizonInterpretation3D(petrel_name="Gullfaks Seismic"), 'Input/Seismic/Gullfaks horizon interpretations/Horizons for Wshop/Base Cretaceous/Gullfaks Seismic': HorizonInterpretation3D(petrel_name="Gullfaks Seismic")}
Using a for loop, we can iterate through the dictionary and print out all of the horizon interpretation names:

for hor in ptp.horizon_interpretation_3ds:
    print(hor.petrel_name)
Seismic Data
Gullfaks Seismic
Gullfaks Seismic
Gullfaks Seismic
Gullfaks Seismic
Let’s select the Top Etive interpretation. First, we save all the paths of the horizons to a list, then we slice through the list and assign the selected value to the Top_Etive_Hor variable:

hor_path = list(all_horizons.keys())
Top_Etive_Hor_path = hor_path[0]
Top_Etive_Hor=ptp.horizon_interpretation_3ds[Top_Etive_Hor_path]
print(Top_Etive_Hor.petrel_name)
Seismic Data
The .horizon_interpretation property returns the parent 3d horizon interpretation of the horizon property:

parent_inter.png
Top_Etive_Hor.horizon_interpretation
HorizonInterpretation(petrel_name="Tabert outliers")
Using the .horizon_property_3ds property we can return an iterable collection of the 3d horizon interpretation properties for the 3d horizon interpretation grid:

for prop in Top_Etive_Hor.horizon_property_3ds:
    print(prop.petrel_name)
TWT
Interpretation attribute
Edge detection: pre-smooth method, combo average
Seismic signature bidirectional, sample type: constant sample window = 10
Combined confidence map
Surface stability index
RMS of seismic cube
Influential data: Clamped to P5, P95
Anomaly data
We can obtain the number of samples contained in the Horizon Interpretation 3d object using the .sample_count property:

Top_Etive_Hor.sample_count
32444
We can obtain the size of the grid using the .extent property which will return the number of nodes in the i and j directions:

Top_Etive_Hor.extent
Extent(i=375, j=301, k=1)
With the release of Python Tool Pro 2.8 , a new annotations() method is available on HorizonInterpretation3D objects, allowing users to retrieve inline and xline information for specific horizon grid indices. The method converts horizon i, j indices into real-world coordinates and matches them to the geometry of a reference SeismicCube.

The method accepts either single integer indices or lists of indices and returns:

a single Annotation object for scalar inputs

list of Annotation objects for list inputs

None if the requested position falls outside the bounds of the horizon or the seismic cube

# retrieve sesimic cube
seismic_cube = ptp.seismic_cubes['Input/Seismic/Seismic Data/Demo_Cube']

# convert the i=1,j=1 to inline and xline
Top_Etive_Hor.annotations(1,1,seismic_cube)
Annotation(inline=154, xline=152, sample=None)
annotations = Top_Etive_Hor.annotations(
    i=[2, 6, 10],
    j=[33, 25, 17],
    reference_cube=seismic_cube
)
annotations
[Annotation(inline=156, xline=216, sample=None),
 Annotation(inline=164, xline=200, sample=None),
 Annotation(inline=172, xline=184, sample=None)]
With the release of Python Tool Pro 2.8 , a new domain property is now available for HorizonInterpretation objects and returns the domain of the object as a string (e.g., Elevation Time, Elevation Depth). If no domain is available, an empty string is returned.

Top_Etive_Hor.horizon_interpretation.domain
'Elevation time'
We can create a chunk that contains all the values in the entire horizon interpretation by using the .all() function. To learn more about chunks, please view the Working with chunks subchapter of the User Guide:

Top_Etive_Hor.all()
<cegalprizm.pythontool.chunk.Chunk at 0x27db90e3f40>
Alternatively, we can create a chunk containing values in the specified ranges by using the .chunk method:

hor_chunk = Top_Etive_Hor.chunk((0,1), (1,3))
print(hor_chunk)
Chunk(backing_object=HorizonInterpretation3D(petrel_name="Seismic Data"), i=(0, 1), j=(1, 3), k=None)
Using the .position() function we can retrieve the x,y,z position of the interpretation node by specifying the i and j-index of the surface node:

Top_Etive_Hor.position(12,5)
Point(x=451329.0330604219, y=6780660.558162178, z=-1985.7900390625)
Similarly, using the .indices() function, we can retrieve the indices of the interpretation node nearest the specified point. Note that the node indices are 0-based, but in the Petrel UI they are 1-based:

Top_Etive_Hor.indices(451329,6780660)
Indices(i=12, j=5, k=None)
Using the .clone() function we can create a copy of the horizon interpretation. The copy_values parameter is optional and requires a boolean value. If set to True the values of the interpretation shall be copied into the clone. It defaults to false. The cloned horizon interpretation is placed in the same collection as the source object. A clone cannot be created with the same name as an existing Petrel object in the same collection:

cloned_interp.png
Top_Etive_Hor.clone('New_horizon', copy_values=True)
HorizonInterpretation3D(petrel_name="New_horizon")
Horizon properties
Check out the API documentation to view a detailed description of all the functions and methods available for the Horizon properties.

To retrieve all the horizon properties from our Petrel project we can use the .horizon_properties property. It returns all the horizon properties within the project in a dictionary where the keys represent the path of the property within the Petrel input tree and the value represents the name of the property:

all_prop=ptp.horizon_properties
print(all_prop)
{}
Using a for loop we can iterate through the dictionary and print out all the horizon properties names. The results are duplicated because we cloned a horizon interpretation together with the associated properties in a previous cell (In [35]) :

for hor_prop in ptp.horizon_properties:
    print(hor_prop.petrel_name)
Let’s select the first Edge detection property. First, we save all the paths of the properties to a list, then we slice through the list and assign the selected value to the Top_Etive_Edge_Det variable:

hor_prop_path = list(all_prop.keys())
Top_Etive_Edge_Det_path = hor_prop_path[8]
Top_Etive_Edge_Det=ptp.horizon_properties[Top_Etive_Edge_Det_path]
The .template property returns the Petrel template for the object as a string. If no template is available, it will return an empty string. In Petrel, for the horizon property example the template can be found by accessing the setting of a property. Similarly, using the .unit_symbol attribute we can access the unit for any object associated with a certain template. In Petrel you can access this data by propping up the global settings for the selected property template:

templateHorprop.png
Top_Etive_Edge_Det.template
'Edge surface'
Top_Etive_Edge_Det.unit_symbol
'%'
The .is_undef_value() function checks whether the provided value is the ‘undefined value’ for the attribute. Petrel represents some undefined values by MAX_INT, others by NaN. A comparison with NaN will always return False (e.g. float.nan != float.nan) so it is preferable to always use this method to test for undefined values:

Top_Etive_Edge_Det.is_undef_value(0)
False
Fault interpretation
Note: The ability to access fault interpretations is a feature available in Python Tool Pro version 2.5 or higher.

Check out the API documentation to view a detailed description of all the functions and methods available for the seismic fault interpretation object.

To retrieve all the fault interpretations from our Petrel project we can use the .faultinterpretations property. This property returns all the horizon interpretations within the project in a dictionary where the keys represent the path of the interpretation within the Petrel input tree and the values represent the name of the interpretation:

all_faults = ptp.faultinterpretations
print(all_faults)
{'Input/Seismic/Gullfaks horizon interpretations/Faults/Fault_copy': FaultInterpretation(petrel_name="Fault_copy"), 'Input/Seismic/Gullfaks horizon interpretations/Faults/Fault interpretation 1': FaultInterpretation(petrel_name="Fault interpretation 1")}
An alternative way to retrieve the fault interpretation is by using list comprehenision. This returns a list with all the fault interpretation objects.

fault_list=[i for i in ptp.faultinterpretations]
fault_list
[FaultInterpretation(petrel_name="Fault_copy"),
 FaultInterpretation(petrel_name="Fault interpretation 1")]
Let’s select the first fault interpretation.

fault_interpretation=fault_list[1]
print(fault_interpretation.petrel_name)
Fault interpretation 1
Fault interpretations can be loaded into a Pandas DataFrame which includes the fault stick ID and the XYZ for each point in the fault stick. The Z column can be in time or depth depending on the domain of the fault interpretation.

df=fault_interpretation.as_dataframe()
df
Fault Stick ID	X	Y	Z
0	1	605329.284578	7.433316e+06	-3595.864649
1	1	604474.105977	7.432522e+06	-3801.743568
2	1	604291.871305	7.432113e+06	-3952.221653
3	2	604613.775103	7.433450e+06	-3629.567001
4	2	604529.832360	7.433262e+06	-3720.947597
5	2	604267.600971	7.432673e+06	-3894.888268
6	3	604345.209864	7.433462e+06	-3683.372178
7	3	604119.210172	7.432954e+06	-3860.841057
8	3	604006.210326	7.432700e+06	-3961.218584
9	4	603279.681706	7.434142e+06	-3638.563933
10	4	603083.097847	7.433700e+06	-3862.605161
11	4	602791.450626	7.433045e+06	-4013.083246
12	4	602791.450626	7.433045e+06	-4031.077109
13	5	602976.084244	7.434689e+06	-3661.850108
14	5	602670.087836	7.434002e+06	-3846.551813
15	5	602433.326254	7.433470e+06	-4018.551969
16	5	602425.792931	7.433453e+06	-4020.316074
The domain information can be retrieved using the property .domain

fault_interpretation.domain
'Elevation time'
Cloning the fault interpretation will always include the fault sticks of the original fault interpretation. Setting the flag ‘copy_values to False will exclude any fault interpretation attributes.

cloned_fault=fault_interpretation.clone(name_of_clone='new_fault_interpretation',copy_values=False)
cloned_fault
FaultInterpretation(petrel_name="new_fault_interpretation")
To remove points from a fault interpretation you can use the method .clear()

cloned_fault.clear()
To create a new fault interpretation object, we can use the .create_fault_interpretation() method on the Petrel connection.

We have to give the new fault interpretation a name, set the domain, and set the interpretation_folder that it will be written to.

Note: The ability to create fault interpretations is a feature available in Python Tool Pro version 2.6 or higher.

Using the .domain property on the fault interpretation selected above, it is possible to find its domain.

domain = fault_interpretation.domain
domain
'Elevation time'
The parent folder name can be found using some simple string manipulation of the fault interpretation .path property

parent_folder_name = fault_interpretation.path.split('/')[-2]
Then the parent folder can be accessed using the interpretation_folders property on the Petrel connection and matching the folder names to the parent_folder_name we created above.

folder = [i for i in ptp.interpretation_folders if i.petrel_name == parent_folder_name][0]
Now it is possible to create a new fault interpretation using by adding a name as well as the domain and interpretation_folder as inputs

new_fault = ptp.create_fault_interpretation(name = 'new_fault', domain = domain, interpretation_folder = folder)
new_fault
FaultInterpretation(petrel_name="new_fault")
Running the as_dataframe() method on the new fault interpreation returns an empty DataFrame. This is because the create_fault_interpretation() method creates an empty Petrel object.

new_fault.as_dataframe()
Fault Stick ID	X	Y	Z
To write data to the new fault interpretation, the .readonly property must be set to false, as all Petrel objects will have .readonly set to True as default.

Then the data can be written to the new fault interpreation using the set_polylines() method, which takes a DataFrame object as input. The input dataframe must have the column names Fault Stick ID, X, Y, and’Z that are present the DataFrame returned from the as_dataframe() method.

In this example, the previous fault data is used as input but cut down to the first 8 rows. This data already has the same column names.

Note: The ability to edit fault interpretations using set_polylines() is a feature available in Python Tool Pro version 2.6 or higher.

new_fault.readonly = False
new_fault.set_polylines(df.head(8))
Running the as_dataframe() method again on the new fault interpretation returns the data that was just written to it using the set_polylines() method.

new_fault.as_dataframe()
Fault Stick ID	X	Y	Z
0	1	605329.284578	7433316.0	-3595.864649
1	1	604474.105977	7432522.0	-3801.743568
2	1	604291.871305	7432113.0	-3952.221653
3	2	604613.775103	7433450.0	-3629.567001
4	2	604529.832360	7433262.0	-3720.947597
5	2	604267.600971	7432673.0	-3894.888268
6	3	604345.209864	7433462.0	-3683.372178
7	3	604119.210172	7432954.0	-3860.841057

========
Surfaces and surface attributes
This section offers an overview of the different functions and properties available for the Petrel Surface object subcategories.

Surfaces
Check out the API documentation to view a detailed description of all the functions and properties available for working with surfaces.

from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection()
The .surface property returns all the surfaces as a dictionary where the keys represent the path of the surface within the Petrel input tree and the values represent the name of each surface:

ptp.surfaces
Surfaces({'Input/Gullfaks surfaces/Depth surfaces/Top Tarbert (Depth 1)': Surface(petrel_name="Top Tarbert (Depth 1)"), 'Input/Gullfaks surfaces/Gullfaks Surfaces (Time)/Base Cretaceous': Surface(petrel_name="Base Cretaceous"), 'Input/Gullfaks surfaces/Gullfaks Surfaces (Time)/Top Tarbert': Surface(petrel_name="Top Tarbert"), 'Input/Gullfaks surfaces/Gullfaks Surfaces (Time)/Top Etive': Surface(petrel_name="Top Etive"), 'Input/Gullfaks surfaces/Depth surfaces/Top Ness (Depth 1)': Surface(petrel_name="Top Ness (Depth 1)"), 'Input/Gullfaks surfaces/Depth surfaces/Top Etive (Depth 1)': Surface(petrel_name="Top Etive (Depth 1)"), 'Input/Gullfaks surfaces/Gullfaks Surfaces (Time)/Top Ness': Surface(petrel_name="Top Ness"), 'Input/Gullfaks surfaces/Depth surfaces/Base Cretaceous (Depth 1)': Surface(petrel_name="Base Cretaceous (Depth 1)"), 'Input/Gullfaks surfaces/Gullfaks Surfaces (Time)/Seabed': Surface(petrel_name="Seabed")})
We can iterate over all the surfaces within the dictionary and print out their names:

for s in ptp.surfaces:
    print(s.petrel_name)
Top Etive (Depth 1)
Base Cretaceous (Depth 1)
Base Cretaceous
Top Ness (Depth 1)
Top Tarbert (Depth 1)
Top Ness
Top Etive
Seabed
Top Tarbert
To select the Top Etive surface, we can create a list of paths for all of the surfaces and then use list slicing to access the surface we want. The argument paths[2], selects the third item from the list you get from paths = list(all_surfaces.keys()):

all_surfaces = ptp.surfaces
paths = list(all_surfaces.keys())
Top_Etive = ptp.surfaces[paths[2]]
print(Top_Etive)
Surface(petrel_name="Top Ness (Depth 1)")
To determine the size of the surface we can use the .extent property, which returns the number of surface nodes in the i and j directions:

extent = Top_Etive.extent
print(extent)
Extent(i=236, j=268, k=1)
The .coords_extent returns the extent of the surface in world-coordinates (Xmin, Xmax, Ymin, Ymax, Zmin, Zmax):

coord_extent = Top_Etive.coords_extent
print(coord_extent, '\n')
print(f'x: {coord_extent.x_axis}')
print(f'y: {coord_extent.y_axis}')
print(f'z: {coord_extent.z_axis}')
print()

CoordinatesExtent(x_axis=AxisExtent(min=450800.000000, max=459080.000000), y_axis=AxisExtent(min=6780240.000000, max=6790240.000000), z_axis=AxisExtent(min=-2528.730000, max=-1717.650000))

x: AxisExtent(min=450800.000000, max=459080.000000)
y: AxisExtent(min=6780240.000000, max=6790240.000000)
z: AxisExtent(min=-2528.730000, max=-1717.650000)

The returned results of the .extent and .coords_extent properties can also be visualized in Petrel by accessing the Statistics of the selected surface:

surface_extend.png
Using the .position() function we can retrieve the x,y,z position of the surface node by specifying the i and j-index of the surface node:

i = 11
j = 20
pos = Top_Etive.position(i, j)
print(f' {i}, {j}: {pos}')
 11, 20: Point(x=451000.00, y=6781040.00, z=nan)
Similarly, using the .indices() function we can retrieve the indices of the surface node nearest the specified point. Note that the node indices are 0-based, but in the Petrel UI they are 1-based:

inds = Top_Etive.indices(pos.x, pos.y)
print(f'{pos}: {inds.i}, {inds.j}')
Point(x=451000.00, y=6781040.00, z=nan): 11, 20
With Python Tool Pro version 2.5 or higher it is possible to retrieve all XYZ positions together with the I and J nodes as a DataFrame.

df=Top_Etive.as_dataframe()
df
I	J	X	Y	Z
0	0	0	450560.0	6780240.0	NaN
1	0	1	450560.0	6780280.0	NaN
2	0	2	450560.0	6780320.0	NaN
3	0	3	450560.0	6780360.0	NaN
4	0	4	450560.0	6780400.0	NaN
...	...	...	...	...	...
63243	235	263	459960.0	6790760.0	NaN
63244	235	264	459960.0	6790800.0	NaN
63245	235	265	459960.0	6790840.0	NaN
63246	235	266	459960.0	6790880.0	NaN
63247	235	267	459960.0	6790920.0	NaN
63248 rows × 5 columns

Note: surface.as_dataframe() prints out all I and Js of a regular 2-dimensional grid covering the extent of the surface. This means many Z-values might show up as NaN because no Z value is defined in Petrel.

To create a dataframe without NaN values use the Pandas functionality .dropna()

df.dropna(subset='Z')
I	J	X	Y	Z
1650	6	42	450800.0	6781920.0	-2480.268311
1651	6	43	450800.0	6781960.0	-2478.273438
1652	6	44	450800.0	6782000.0	-2478.109375
1653	6	45	450800.0	6782040.0	-2478.184570
1654	6	46	450800.0	6782080.0	-2482.144043
...	...	...	...	...	...
57301	213	217	459080.0	6788920.0	-2025.493652
57302	213	218	459080.0	6788960.0	-2022.538330
57303	213	219	459080.0	6789000.0	-2021.124756
57304	213	220	459080.0	6789040.0	-2034.180786
57305	213	221	459080.0	6789080.0	-2042.240112
39539 rows × 5 columns

In Python Tool Pro version 2.6 or higher you can use the flag dropna in the .as_dataframe(dropna=True) method to directly create a dataframe with only defined values.

df_lean=Top_Etive.as_dataframe(dropna=True)
df_lean
I	J	X	Y	Z
0	6	42	450800.0	6781920.0	-2480.268311
1	6	43	450800.0	6781960.0	-2478.273438
2	6	44	450800.0	6782000.0	-2478.109375
3	6	45	450800.0	6782040.0	-2478.184570
4	6	46	450800.0	6782080.0	-2482.144043
...	...	...	...	...	...
39534	213	217	459080.0	6788920.0	-2025.493652
39535	213	218	459080.0	6788960.0	-2022.538330
39536	213	219	459080.0	6789000.0	-2021.124756
39537	213	220	459080.0	6789040.0	-2034.180786
39538	213	221	459080.0	6789080.0	-2042.240112
39539 rows × 5 columns

The .parent_collection property will return the selected surface and all its siblings in the Petrel Input Tree:

parentcol.png
sibling_surfaces = Top_Etive.parent_collection
for Top_Etive in sibling_surfaces:
    print(f'\t{Top_Etive.extent}\t{Top_Etive.petrel_name}')
        Extent(i=286, j=180, k=1)       Seabed
        Extent(i=238, j=291, k=1)       Base Cretaceous
        Extent(i=237, j=269, k=1)       Top Tarbert
        Extent(i=235, j=269, k=1)       Top Ness
        Extent(i=236, j=268, k=1)       Top Etive
To check the available surface attributes for the selected surface we can use the .surface_attributes property:

for atr in Top_Etive.surface_attributes:
    print(atr)
SurfaceAttribute(petrel_name="TWT")
SurfaceAttribute(petrel_name="Depth 1")
Surface attributes
Check out the API documentation to view a detailed description of all the functions and properties available for working with surface attributes:

Continuous attributes

Discrete attributes

The .surface_attributes property returns all the continuous surface attributes as a dictionary where the keys represent the path of the surface attribute within the Petrel input tree and the value represents its name:

ptp.surface_attributes
SurfaceAttributes({'Input/Surfaces (Time)/Base Cretaceous/Depth 1': SurfaceAttribute(petrel_name="Depth 1"), 'Input/Surfaces (Time)/Top Tarbert/TWT': SurfaceAttribute(petrel_name="TWT"), 'Input/Surfaces (Time)/Top Ness/Depth 1': SurfaceAttribute(petrel_name="Depth 1"), 'Input/Surfaces (Time)/Top Etive/TWT': SurfaceAttribute(petrel_name="TWT"), 'Input/Surfaces (Time)/Top Tarbert/Depth 1': SurfaceAttribute(petrel_name="Depth 1"), 'Input/Surfaces (Time)/Top Etive/Depth 1': SurfaceAttribute(petrel_name="Depth 1"), 'Input/Surfaces (Time)/Top Ness/TWT': SurfaceAttribute(petrel_name="TWT"), 'Input/Surfaces (Time)/Base Cretaceous/TWT': SurfaceAttribute(petrel_name="TWT")})
Similarly, we can retrieve a dictionary of all the discrete surface attributes by using the .surface_discrete_attributes property:

ptp.surface_discrete_attributes
SurfaceDiscreteAttributes({'Input/Surfaces (Time)/Top Etive/Facies': SurfaceDiscreteAttribute(petrel_name="Facies")})
We can iterate over all the surface attributes and return their names:

print('Continuous surface attributes:', '\n')
for sa in ptp.surface_attributes:
    print(sa.petrel_name)
print('\n','Discrete surface attributes:', '\n')
for sa in petrel.surface_discrete_attributes:
    print(sa.petrel_name)
Continous surface attributes

Depth 1
TWT
Depth 1
TWT
Depth 1
Depth 1
TWT
TWT

 Discrete surface attributes

Facies
Let’s select the depth surface attribute which belongs to the Top Etive surface:

all_surfaces_atr = ptp.surface_attributes
paths = list(all_surfaces_atr.keys())
Top_Etive_Depth = petrel.surface_attributes[paths[5]]
print(Top_Etive_Depth)
SurfaceAttribute(petrel_name="Depth 1")
We can check if the selected attribute belongs to the Top Etive surface using the .surface property:

parent_surf = Top_Etive_Depth.surface
print(parent_surf)
Surface(petrel_name="Top Etive")
To check what other attributes the selected surface has we can use the .surface_attributes property:

for attr in parent_surf.surface_attributes:
    print(f'{attr}')
SurfaceAttribute(petrel_name="TWT")
SurfaceAttribute(petrel_name="Depth 1")
SurfaceDiscreteAttribute(petrel_name="Facies")
Petrel represents some undefined values by MAX_INT, and others by NaN. The undef value of the surface attribute can be returned using the .undef_value property:

print(Top_Etive_Depth.undef_value)
nan
The .template property returns the Petrel template for the surface as a string. If no template is available, it will return an empty string. Similarly, using the .unit_symbol property, we can access the unit for any object associated with a certain template. In Petrel, you can access this data by opening the global settings for the selected property template.

unitsurf.png
print('Template:', Top_Etive_Depth.template)
print('\n')
print('Unit:',Top_Etive_Depth.unit_symbol)
Template: Elevation depth


Unit: m
The .has_same_parent() function checks if two attributes belong to the same parent surface. In the example, below we assign two different surface attributes to the variables attr0 and attr1. The .has_same_parent() checks if the two belong to the Top Etive surface and returns a boolean value:

attr0 = ptp.surface_attributes[paths[0]]
attr1 = ptp.surface_attributes[paths[3]]
print(f'{attr1} and {Top_Etive} has same parent: {attr1.has_same_parent(Top_Etive_Depth)}')
print(f'{attr0} and {Top_Etive} has same parent: {attr0.has_same_parent(Top_Etive_Depth)}')

SurfaceAttribute(petrel_name="TWT") and Surface(petrel_name="Top Etive") has same parent: True
SurfaceAttribute(petrel_name="Depth 1") and Surface(petrel_name="Top Etive") has same parent: False
We can create a chunk that contains all the values for the attribute by using the .all() function. To learn more about chunks please view the Working with chunks subchapter of the User Guide.

Top_Etive_Depth.all()
<cegalprizm.pythontool.chunk.Chunk at 0x1fc8683f040>
Alternatively, using the .chunk() function, we can select only a range of the surface attribute that we want to convert into a chunk:

i = (11, 25)
j = (20, 40)
Top_Etive_Depth.chunk(i,j)
<cegalprizm.pythontool.chunk.Chunk at 0x1fc7a0d4070>
For the discrete surface attributes, we can return a dictionary of the discrete codes and values using the .discrete_codes property:

SURFACE_DISCRETE.png
all_surfaces_atr = ptp.surface_discrete_attributes
paths = list(all_surfaces_atr.keys())
Top_Etive_Facies = ptp.surface_discrete_attributes[paths[0]]

Top_Etive_Facies.discrete_codes
{0: 'Clay', 1: 'Sand', 2: 'Silt', 3: 'Fine Silt'}
Creation of new surface objects
In Python Tool Pro 2.6 or higher is is possible to create new regular height surface objects.

The method create_surface takes as input the name of the new surface object, the domain, the folder (currently limited to interpration folders), the origin point, the next corner point in the i direction, the next corner point in the j direction and an array with depth values. The number of values in the depth array will determine the spacing of the surface grid.

ptp.create_surface(name='new_name',domain='Elevation depth',folder=Interpretation_folder,origin_corner=p0,i_corner=p1,j_corner=p2,array=depth_points)
Determine the extend of the surface
The first step is to define the coordinate extend of the new surface.

xmin=450800
xmax=459080
ymin=6780200
ymax=6790240
Next define the origin point “p0”, the corner point in i-direction “p1”, and the corner point in j-direction “p2”.

Note: “p0”, “p1”, and “p2” are example names and can be changed

p0=(xmin,ymin)
p1=(xmax, ymin)
p2=(xmin, ymax)
Make sure that the line between p0 and p2 is perpendicular to the line between p0 and p1.

import matplotlib.pyplot as plt
plt.plot([xmin,xmax],[ymin,ymin],c="blue")
plt.plot([xmin,xmin],[ymin,ymax],c="green")
plt.scatter(xmin,ymin,label="Origin point p0",c="red")
plt.scatter(xmax, ymin,label="Corner point i-drection p1",c="blue")
plt.scatter(xmin, ymax,label="Corner point i-drection p2",c="green")
plt.legend()
plt.show()
../../../../_images/products_python-tool-pro_PythonToolProWorkbooks_UserGuide_Surfaces_nb_65_0.png
Create a surface with a spacing of 25x25 meters
The array with the depth points determines the grid spacing of the new surface object. If you want a spacing of 25x25 meters in the above example you need to use an input array of shape (331,401). Devide the distance between xmin and xmax and the distance betweeen ymin and ymax by the desired grid spacing to get the shape

xspacing=int((xmax-xmin)/25)
yspacing=int((ymax-ymin)/25)
print(xspacing)
print(yspacing)

331
401
import numpy as np
arr_25 = np.zeros(shape=(331, 401))
print('Shape of array is '+str(arr_25.shape))
arr_25
Shape of array is (331, 401)
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])
New surface objects can only be created into exisiting interpretation folders. Using the code snippet below we will select a random interpretation folder for this example.

folder = next(iter(ptp.interpretation_folders.values()))
folder.petrel_name
'Gullfaks horizon interpretations'
Now you can create a new surface using the inputs defined above.

ptp.create_surface(name='new_surface_25',domain='Elevation depth',folder=folder,origin_corner=p0,i_corner=p1,j_corner=p2,array=arr_25)
Surface(petrel_name="new_surface_25")
Create a surface with a different spacing of 250x150 meters
Repeat the above steps, but change the calculation of the array to match the spacing of 250x150 meters.

xspacing=int((xmax-xmin)/250)
yspacing=int((ymax-ymin)/150)
print(xspacing)
print(yspacing)
33
66
import numpy as np
arr_250_150 = np.zeros(shape=(33, 66))
print('Shape of array is '+str(arr_250_150.shape))
arr_250_150
Shape of array is (33, 66)
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])
Now you can create a new surface using the inputs defined above with the wider spacing.

ptp.create_surface(name='new_surface_100_50',domain='Elevation depth',folder=folder,origin_corner=p0,i_corner=p1,j_corner=p2,array=arr_250_150)
Surface(petrel_name="new_surface_100_50")
Troubleshooting creation of surfaces
Let’s see what happens if you do not have the correct input data.

I-direction and j-direction not perpendicular
We will use the same desired coordinate extent.

xmin=450800
xmax=459080
ymin=6780200
ymax=6790240
But when creating the corner points we will make the line between p0 and p2 not perpendicular to the line between p0 and p1

p0=(xmin,ymin)
p1=(xmax, ymin)
p2_bad=(xmin+2000, ymax)
Make sure that the line between p0 and p2 is perpendicular to the line between p0 and p1.

import matplotlib.pyplot as plt
plt.plot([xmin,xmax],[ymin,ymin],c="blue")
plt.plot([xmin,xmin+2000],[ymin,ymax],c="green")
plt.scatter(xmin,ymin,label="Origin point p0",c="red")
plt.scatter(xmax, ymin,label="Corner point i-drection p1",c="blue")
plt.scatter(xmin+2000, ymax,label="Corner point i-drection p2",c="green")
plt.legend()
plt.show()
../../../../_images/products_python-tool-pro_PythonToolProWorkbooks_UserGuide_Surfaces_nb_88_0.png
**Now create a new surface object, but using the p2_bad as input for the j_corner.

ptp.create_surface(name='new_surface_bad_input',domain='Elevation depth',folder=folder,origin_corner=p0,i_corner=p1,j_corner=p2_bad,array=arr_250_150)
---------------------------------------------------------------------------
UserErrorException                        Traceback (most recent call last)
Cell In[59], line 1
----> 1 ptp.create_surface(name='new_surface_bad_input',domain='Elevation depth',folder=folder,origin_corner=p0,i_corner=p1,j_corner=p2_bad,array=arr_250_150)

File C:\python\envs\ptp_dev\lib\site-packages\cegalprizm\pythontool\petrelconnection.py:651, in PetrelConnection.create_surface(self, name, domain, folder, origin_corner, i_corner, j_corner, array)
    636         flattened_array[j*array.shape[0]+i] = array[i,j]
    638 requests = (
    639     petrelinterface_pb2.CreateSurface_Request(
    640         SurfaceName = name,
   (...)
    648         Samples = chunk)
    649     for chunk in chunks(flattened_array, 1024))
--> 651 reply = self._service_surface.CreateSurface(requests)
    652 if reply.guid:
    653     petrel_object_link = SurfaceGrpc(reply.guid, self)

File C:\python\envs\ptp_dev\lib\site-packages\cegalprizm\pythontool\oophub\surface_hub.py:22, in SurfaceHub.CreateSurface(self, iterable_requests)
     21 def CreateSurface(self, iterable_requests) -> PetrelObjectGuid:
---> 22     return self._client_streaming_wrapper("cegal.pythontool.CreateSurface", PetrelObjectGuid, iterable_requests)

File C:\python\envs\ptp_dev\lib\site-packages\cegalprizm\pythontool\oophub\base_hub.py:112, in BaseHub._client_streaming_wrapper(self, wkt, out_type, iterable_requests)
    110     unpacked_response = out_type()
    111     packed_response.Unpack(unpacked_response)
--> 112     if _handle_petrel_error(unpacked_response):
    113         return unpacked_response
    114 else:

File C:\python\envs\ptp_dev\lib\site-packages\cegalprizm\pythontool\oophub\base_hub.py:20, in _handle_petrel_error(response)
     18     return True
     19 elif petrel_error.type == ErrorType.UserError:
---> 20     raise UserErrorException(petrel_error.message, petrel_error.stack_trace)
     21 elif petrel_error.type == ErrorType.UnexpectedError:
     22     raise UnexpectedErrorException(petrel_error.message, petrel_error.stack_trace)

UserErrorException: Lattice must be orthogonal.
Creation of surface attributes
With the release of Python Tool Pro 2.8 Surface objects now support programmatic creation of new attributes using the create_attribute() method.

If no name, data type, or template is provided, a continuous attribute with a default template and auto-generated name will be created. The data_type parameter accepts both strings (“continuous”, “discrete”) and NumericDataTypeEnum enum values.

from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()

surface = petrel.surfaces["Input/Surfaces (Time)/Seabed"]
surface
Surface(petrel_name="Seabed")
image.png
# change the readonly status of the surface so it can be edited
surface.readonly = False

# Create a new continous surface attribute
new_attr = surface.create_attribute("MyNewAttribute")
new_attr
SurfaceAttribute(petrel_name="MyNewAttribute")
image.png
from cegalprizm.pythontool import NumericDataTypeEnum

# Retrieve the discrete "Facies" template
disc_template = petrel.discrete_templates.get_by_name("Facies")

# Create a discrete surface attribute with the Facies Template
new_disc_attr = surface.create_attribute(
    "MyNewDiscreteAttribute",
    data_type=NumericDataTypeEnum.Discrete,
    template=disc_template
)
========
3D model grids and grid properties
This section offers an overview of the different methods and functions available for the Petrel Grid object subcategories.

Grids
Check out the API documentation to view a detailed description of all the functions and methods available for the Grid objects

Let’s look at an example on how to retrieve all the grids from our Petrel project by using the .grids property. This property returns all the grids from the project in a dictionary where the keys represent the path of the grid within the Petrel input tree and the value represents the name of the grid:

from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()

all_grids=petrel.grids
print(all_grids)
{'Models/Gullfaks2004/Gullfaks (Make Horizon)': Grid(petrel_name="Gullfaks (Make Horizon)"), 'Models/Final model/Training': Grid(petrel_name="Training"), 'Models/Gullfaks2004/Gullfaks Final (DC)': Grid(petrel_name="Gullfaks Final (DC)")}
Using a for loop, we can iterate through the dictionary and print out all the grid names:

for grid in petrel.grids:
    print(grid.petrel_name)
Gullfaks (Make Horizon)
Gullfaks Final (DC)
Training
Let’s select a specific grid (Gullfaks Final (DC)). Specific grids can be accessed by using the unique id or by using the path. Petrel allows equal object names, so the path is not guaranteed to be unique. In cases of equal paths, use the unique id instead of the path to look up:

a_grids_id_and_path = list(all_grids.keys())
grid_path = a_grids_id_and_path[2]
grid = petrel.grids[grid_path]
print(grid.petrel_name)
Gullfaks Final (DC)
for el in grid.segments:
    print (el)
Segment(petrel_name="Segment 1")
Segment(petrel_name="Segment 2")
Segment(petrel_name="Segment 3")
Segment(petrel_name="Segment 4")
Segment(petrel_name="Segment 5")
Segment(petrel_name="Segment 6")
Segment(petrel_name="Segment 7")
Segment(petrel_name="Segment 8")
Segment(petrel_name="Segment 9")
Segment(petrel_name="Segment 10")
Segment(petrel_name="Segment 11")
Segment(petrel_name="Segment 12")
Segment(petrel_name="Segment 13")
Segment(petrel_name="Segment 14")
Segment(petrel_name="Segment 15")
Segment(petrel_name="Segment 16")
Segment(petrel_name="Segment 17")
Segment(petrel_name="Segment 18")
Segment(petrel_name="Segment 19")
Segment(petrel_name="Segment 20")
We can obtain the size of the grid using the .extent property, which returns the number of cells in the i, j and k directions:

extent = grid.extent
print(extent)
Extent(i=85, j=88, k=88)
The .coords_extent returns the extent of the grid in world-coordinates (Xmin, Xmax, Ymin, Ymax, Zmin, Zmax):

coord_extent = grid.coords_extent
print(f'x: {coord_extent.x_axis}')
print(f'y: {coord_extent.y_axis}')
print(f'z: {coord_extent.z_axis}')
x: AxisExtent(min=450658.280000, max=459028.480000)
y: AxisExtent(min=6780231.600000, max=6790163.160000)
z: AxisExtent(min=-2366.750000, max=-1751.230000)
Using a for loop and the .properties property we can iterate through the available properties within the selected grid and print them out:

grid_prop.png
for prop in grid.properties:
    print(prop)
GridProperty(petrel_name="NG")
GridProperty(petrel_name="Porosity")
GridDiscreteProperty(petrel_name="Zones")
GridDiscreteProperty(petrel_name="Facies")
GridDiscreteProperty(petrel_name="Object modeling")
Using the .indices() and .position() functions we can obtain the centre of a cell with its coresponding indices. First, we assign the indices of a cell to the cell_indices variable. For the indices parameters, we are using the i,j,k extent of the cell and then use floor division to get i,j,k of the centre of the cell. Once we have the i,j,k of the centre, we can then use the .position() function to get the XYZ position of the cell centre based on the provided i,j,k parameters:

from cegalprizm.pythontool.primitives import Indices
from cegalprizm.pythontool.primitives import Point

cell_indices = Indices(i = extent.i//2, j = extent.j//2, k = extent.k//2)
cell_center_position = grid.position(cell_indices.i, cell_indices.j, cell_indices.k)
print(f'{cell_indices}: {cell_center_position}')
Indices(i=42, j=44, k=44): Point(x=454926.72, y=6784597.32, z=-2034.18)
Alternatively, we can obtain the indices of a cell at a specified XYZ position:

pos = cell_center_position
cell_indices_at_pos = grid.indices(pos.x, pos.y, pos.z)
print(f'{pos}: {cell_indices_at_pos}')
Point(x=454926.72, y=6784597.32, z=-2034.18): Indices(i=42, j=44, k=44)
To get the vertices position of cell at a specified ijk position, we can use the .vertices() function. Use the vertices_unchecked() function if you do not wish to spend time checking if the cell is defined. In that case, the method will return a list of undefined points.

vertices_positions = grid.vertices(cell_indices.i, cell_indices.j, cell_indices.k)
print(f'{cell_indices}: {vertices_positions} ')
Indices(i=42, j=44, k=44): [Point(x=454898.0417201763, y=6784539.240852976, z=-2045.9384765625), Point(x=454893.4293825538, y=6784646.287928432, z=-2042.516357421875), Point(x=454964.516370921, y=6784655.51934186, z=-2025.9385986328125), Point(x=454958.8456553315, y=6784548.233269478, z=-2026.3314208984375), Point(x=454893.67790898, y=6784539.2028891565, z=-2043.9384765625), Point(x=454889.500361688, y=6784646.247008894, z=-2040.516357421875), Point(x=454960.70478615444, y=6784655.546750721, z=-2023.9385986328125), Point(x=454955.02119874046, y=6784548.276951542, z=-2024.3314208984375)]
With the release of Python Tool Pro version 2.2, it is now possible to retrieve zone and segment information of a 3D grid model.

You can access the segments in your 3D grid using the .segments property which will return an iterable collection of the segments for the grid:

grid.segments
Segments(grid="Grid(petrel_name="Gullfaks Final (DC)")")
Using a for loop we can iterate through all the segments or alternatively we can generate a list of them using the .list() function:

for sg in grid.segments:
    print(sg)

segments_list = list(grid.segments)
print(segments_list)
Segment(petrel_name="Segment 1")
Segment(petrel_name="Segment 2")
Segment(petrel_name="Segment 3")
Segment(petrel_name="Segment 4")
Segment(petrel_name="Segment 5")
Segment(petrel_name="Segment 6")
Segment(petrel_name="Segment 7")
Segment(petrel_name="Segment 8")
Segment(petrel_name="Segment 9")
Segment(petrel_name="Segment 10")
Segment(petrel_name="Segment 11")
Segment(petrel_name="Segment 12")
Segment(petrel_name="Segment 13")
Segment(petrel_name="Segment 14")
Segment(petrel_name="Segment 15")
Segment(petrel_name="Segment 16")
Segment(petrel_name="Segment 17")
Segment(petrel_name="Segment 18")
Segment(petrel_name="Segment 19")
Segment(petrel_name="Segment 20")
[Segment(petrel_name="Segment 1"), Segment(petrel_name="Segment 2"), Segment(petrel_name="Segment 3"), Segment(petrel_name="Segment 4"), Segment(petrel_name="Segment 5"), Segment(petrel_name="Segment 6"), Segment(petrel_name="Segment 7"), Segment(petrel_name="Segment 8"), Segment(petrel_name="Segment 9"), Segment(petrel_name="Segment 10"), Segment(petrel_name="Segment 11"), Segment(petrel_name="Segment 12"), Segment(petrel_name="Segment 13"), Segment(petrel_name="Segment 14"), Segment(petrel_name="Segment 15"), Segment(petrel_name="Segment 16"), Segment(petrel_name="Segment 17"), Segment(petrel_name="Segment 18"), Segment(petrel_name="Segment 19"), Segment(petrel_name="Segment 20")]
We can assign a segment to a variable using list slicing:

seg1=segments_list[0]
seg1
Segment(petrel_name="Segment 1")
The .cells property will return the indices of the cells belonging to this segment. In the example bellow we are only returning the first 10 values ([0:10]):

seg1.cells[0:10]
[Indices(i=5, j=47, k=None),
 Indices(i=5, j=46, k=None),
 Indices(i=5, j=45, k=None),
 Indices(i=5, j=44, k=None),
 Indices(i=6, j=48, k=None),
 Indices(i=6, j=47, k=None),
 Indices(i=6, j=46, k=None),
 Indices(i=6, j=45, k=None),
 Indices(i=6, j=44, k=None),
 Indices(i=6, j=43, k=None)]
The .is_cell_inside() function checks if a cell is inside a segment at a particular i and j position. It returns True if a cell exists and false if not :

seg1.is_cell_inside(seg1.cells[0])
True
To retrieve the statistics of a particular segment you can use the .retrieve_stats() function:

seg1.retrieve_stats()
{'Number of cells': '641',
 'Z Max': '-1882.63',
 'X Delta': '3673.54999999999',
 'Z Delta': '544.8',
 'Long Delta': '0.0696037777777776',
 'Z Min': '-2427.43',
 'Lat Delta': '0.0454362500000016',
 'Long Min': '2.08947588888889',
 'Y Max': '6788807.26',
 'X Max': '454780.81',
 'Lat Min': '61.1840995555556',
 'Lat Max': '61.2295358055556',
 'X Min': '451107.26',
 'Segment area': '5.32036E+6 m2',
 'Y Min': '6783794.61',
 'Long Max': '2.15907966666667',
 'Y Delta': '5012.64999999944'}
The .grid property retunrns the grid associated with the particular segment:

seg1.grid
Grid(petrel_name="Gullfaks Final (DC)")
You can access the zones in your 3D grid using the .zones property which will return an iterable collection of the zones for the grid:

grid.zones
Zones(grid="Grid(petrel_name="Gullfaks Final (DC)")")
Using a for loop we can iterate through all the zones or alternatively we can generate a list of them using the .list() function:

for zn in grid.zones:
    print(zn)

zones_list = list(grid.zones)
print(zones_list)
Zone(petrel_name="Zone 1 Sh")
Zone(petrel_name="Tarbert")
Zone(petrel_name="Ness")
[Zone(petrel_name="Zone 1 Sh"), Zone(petrel_name="Tarbert"), Zone(petrel_name="Ness")]
We can assign a segment to a variable using list slicing:

Ness=zones_list[2]
Ness
Zone(petrel_name="Ness")
The .base_k property will return the bottom geological horizon index in the 3D grid:

Ness.base_k
87
The .top_k property will return the top geological horizon index in the 3D grid:

Ness.top_k
48
To retrieve the statistics of a particular zone you can use the .retrieve_stats() function:

Ness.retrieve_stats()
{'Number of geological layers covered': '40',
 'Y Min': '6780231.6',
 'Nodes (nI x nJ)': '86 x 89',
 'Cells (nI x nJ)': '85 x 88',
 'Y Delta': '9917.8200000003',
 'Total number of 3D cells (Simbox)': '299200',
 'Lat Max': '61.2420517777778',
 'X Min': '450941.36',
 'Long Max': '2.23883397222222',
 'Z Min': '0',
 'Z Max': '189.51',
 '': '',
 'X Max': '459028.48',
 'Z Delta': '189.51',
 'Y Max': '6790149.42',
 'Total number of 2D cells': '7480',
 'Average Zinc (along pillar)': '4.40745578',
 'Bottom geological horizon index in 3D grid': '89',
 'Lat Delta': '0.0899549999999962',
 'Total number of 2D nodes': '7654',
 'Top geological horizon index in 3D grid': '49',
 'Lat Min': '61.1520967777778',
 'X Delta': '8087.12',
 'Long Min': '2.08603736111111',
 'Covers geological layers': '49 - 88',
 'Long Delta': '0.152796611111111'}
The .zones property will retrun an iterable collection of all the sub-zones associated to the selected zone: image.png

Ness.zones
Zones(zone="Zone(petrel_name="Ness")")
We can assign the sub-zone to a variable using list slicing:

Ness2=zone1.zones[0]
Ness2
Zone(petrel_name="Ness-2")
As we seen above, the IJ pairs of segments and the top and base k of zones can be accessed and retrun. They can olso be matched to the IJK values of a (grid property) chunk dataframe thus allowing users to retrieve, update or create new values for specific zones and/or segments.

Grid properties
Check out the API documentation to view a detailed description of all the functions and methods available for the Grid properties:

Continuous grid properties

Discrete grid properties

To retrieve all the grid properties from our Petrel project we can use the .grid_properties property. This property returns all the properties from all the grids within the project in a dictionary where the keys represent the path of the grid properties within the Petrel input tree and the value represents the name of the property:

all_grids_prop=petrel.grid_properties
print(all_grids_prop)
{'Models/Gullfaks2004/Gullfaks Final (DC)/Properties/NG': GridProperty(petrel_name="NG"), 'Models/Final model/Training/Properties/Conditioned porosity': GridProperty(petrel_name="Conditioned porosity"), 'Models/Final model/Training/Properties/Porosity': GridProperty(petrel_name="Porosity"), 'Models/Gullfaks2004/Gullfaks Final (DC)/Properties/Porosity': GridProperty(petrel_name="Porosity")}
Using a for loop, we can iterate through the dictionary and print out all the grid properties names. For accessing discrete properties, we have to use the .discrete_grid_properties property. Furthermore, we can also return the grid name for every property using the .grid property:

for grid_prop in petrel.grid_properties:
    print('Property name:' , grid_prop.petrel_name, "  |  Grid name:", grid_prop.grid.petrel_name)
for disc_grid_prop in petrel.discrete_grid_properties:
    print('Discrete property name:', disc_grid_prop.petrel_name, "  |  Grid name:",disc_grid_prop.grid.petrel_name )
Property name: NG   |  Grid name: Gullfaks Final (DC)
Property name: Conditioned porosity   |  Grid name: Training
Property name: Porosity   |  Grid name: Training
Property name: Porosity   |  Grid name: Gullfaks Final (DC)
Discrete property name: Facies   |  Grid name: Training
Discrete property name: Object modeling   |  Grid name: Gullfaks Final (DC)
Discrete property name: Layers   |  Grid name: Training
Discrete property name: Object modeling   |  Grid name: Training
Discrete property name: Zones   |  Grid name: Gullfaks Final (DC)
Discrete property name: Facies   |  Grid name: Gullfaks Final (DC)
Let’s select the Porosity and Facies properties from the Gullfaks Final (DC) grid. First, we save all the paths of the continuous properties to a list, then we can slice through the list and assign the selected value to the Porosity variable.

To get the Facies property we have to repeat the same process by first defining the dictionary that contains the paths and values for all the discrete properties, and then by selecting the property using list slicing on the list of paths:

grid_prop_paths = list(all_grids_prop.keys())
Porosity_prop_path = grid_prop_paths[3]
Porosity = petrel.grid_properties[Porosity_prop_path]


all_discrete_grid_prop= petrel.discrete_grid_properties
discrete_grid_prop_path=list(all_discrete_grid_prop.keys())
Facies_prop_path= discrete_grid_prop_path[5]
Facies = petrel.discrete_grid_properties[Facies_prop_path]


print(Porosity.petrel_name)
print(Facies.petrel_name)
Porosity
Facies
To get the cell indices of the values which have been upscaled, we can use the .upscaled_cells property. In the following example, we are using a counter and a for loop to return just the first ten values (as there are hundreds of cells):

c=0
for el in Porosity.upscaled_cells:
    if c<10:
        print (el)
        c+=1
Indices(i=57, j=77, k=0)
Indices(i=58, j=77, k=0)
Indices(i=7, j=74, k=0)
Indices(i=8, j=74, k=0)
Indices(i=27, j=61, k=0)
Indices(i=28, j=61, k=0)
Indices(i=72, j=46, k=0)
Indices(i=73, j=46, k=0)
Indices(i=14, j=44, k=0)
Indices(i=61, j=37, k=0)
The .template property returns the Petrel template for the object as a string. If no template is available, it will return an empty string. In Petrel, for the grid property example, the template can be found by accessing the setting of a property. Similarly, using the .unit_symbol property, we can access the unit for any object associated with a certain template. In Petrel, you can access this data by propping up the global settings for the selected property template.

templateUnitSymbol2.png
Porosity.template
'Porosity'
Porosity.unit_symbol
'm3/m3'
The .discrete_codes property returns a dictionary of discrete codes as keys and the associated facies as values. Changes to this dictionary will not be persisted or affect any Petrel objects:

facies_codes.png
Facies.discrete_codes
{0: 'Blocky', 1: 'Coarsening upwards', 2: 'Fining upwards'}
Using the .layers() function, we can set all the property values to a specific value across a range of k-slices. In the following example, we replace all the Porosity values with the value of 0.9 for k-slices between k=10 and k=19. Before iterating through each k-slice in the for loop, we set the readonly value of the Porosity property to False, so we can modify the values. If we don’t specify the range, the for loop will replace all of the values. The results are written to Petrel in real time:

setporval.png
Porosity.readonly=False
for layer in Porosity.layers(range(10,20)):
    layer.set(0.9)
Similarly, we can set specific values across a range of i and j slices using the .columns() function:

Gridirange.png
# sets to 0 all values in the i-slices i=10 through to i=19,
Porosity.readonly=False
for col in Porosity.columns(irange=range(10, 20), jrange=None):
    col.set(0.5)
Accessing and Setting Date on Grid Properties
Python Tool Pro 2.7 introduces the ability to access and set the date on grid properties. This is useful for managing time-stamped property data directly from Python.

New properties and behavior:

use_date
Boolean value indicating whether the grid property is associated with a date. This corresponds to the Date checkbox in Petrel.
Setting this property to True will enable date tracking. If no date was previously set, the current date and time will be assigned automatically.
date
The date and time recorded for the property as a datetime object. Returns None if the property is not associated with a date. When assigning a date, if use_date is False, it will automatically be set to True.
Access a Grid Property
# Connect to Petrel
from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()

# Access the grid property
grid_property = petrel.grid_properties["Models/GEO grid from SF/GEO Grid/Properties/por/Porosity1"]

# Display some basic info
print("Property name:", grid_property.petrel_name)
Property name: Porosity1
Note that, in Petrel, the Date checkbox for the selected property is not checked :

date1.png
Check and Enable Date Tracking
Check whether date tracking is already enabled. If not, set use_date to True:

# Make the property editable
grid_property.readonly = False

print("Use date:", grid_property.use_date)
Use date: False
# Enable date tracking
grid_property.use_date = True
print("Use date:", grid_property.use_date)
Use date: True
Running the cell above will check the Date box in Petrel and will assign the present date and time as no date was previously set:

date2.png
Set a Specific Date
Assign a specific date to the property using the .date property:

import datetime

# Set a specific date (e.g., July 7, 2025)
new_date = datetime.datetime(2025, 7, 7, 11, 30, 45)
grid_property.date = new_date

# verify the change
print("Grid property date:", grid_property.date)
Grid property date: 2025-07-07 11:30:45
Creating Grid Properties
With the release of Python Tool Pro 2.8, PropertyFolder are now supported objects. These objects support programmatic creation of continuous and discrete grid properties using the create_property() method.

from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()

#Select grid
grid = petrel.grids['Models/Gullfaks2004/Gullfaks Final (DC)']

#Retrieve the Properties folder
property_folder = grid.property_folder
property_folder
PropertyFolder(petrel_name="Properties")
image.png
When creating a grid properties, if no name, data type, or template is provided, a continuous property with a default template and automatically generated name will be created. The data_type parameter accepts both strings (“continuous”, “discrete”) and NumericDataTypeEnum values.

# set the readonly status of the folder to false so we can edit it
property_folder.readonly = False

# Create a new continous property in the selected folder
new_prop = property_folder.create_property("New Continuous Property")
from cegalprizm.pythontool import NumericDataTypeEnum

#retrieve facies template
facies_template = petrel.discrete_templates.get_by_name("Facies")

# create a discrete facies property
new_disc_prop = property_folder.create_property(
    "New Discrete Property",
    data_type=NumericDataTypeEnum.Discrete,
    template=facies_template
)
image.png
======
Checkshots
Note: The ability to access checkshots is a feature available Python Tool Pro version 2.3.

This notebook gives an overview of the different functions and properties available for working with checkshot data.

For a more detailed description of the function and properties, check out the API documentation.

Connect to a Petrel project
For this user guide we will be using data from the Volve field. The data is freely accessible here

from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection(allow_experimental=True)
print('Connected to {}'.format(petrel.get_current_project_name()))
Connected to volve_fluid_sub.pet
We can access the checkshot objects by using the petrel connection and typing

petrel.checkshots
This returns a dictionary where the keys represent the path of the well within the Petrel input tree.

It is often easier to pass this into a list comprehension.

[i for i in petrel.checkshots]
[CheckShot(petrel_name="159-F-5.txt"),
 CheckShot(petrel_name="159-F-9-11-A.txt"),
 CheckShot(petrel_name="159-F-1-A.txt"),
 CheckShot(petrel_name="checkshot_15_9_19A.txt"),
 CheckShot(petrel_name="159-F-15.txt"),
 CheckShot(petrel_name="159-F-1.txt"),
 CheckShot(petrel_name="159-F-1-B.txt"),
 CheckShot(petrel_name="159-F-1-C.txt"),
 CheckShot(petrel_name="159-F-15-A.txt"),
 CheckShot(petrel_name="checkshot_15_9_19BT2.txt"),
 CheckShot(petrel_name="159-9-F-4.txt"),
 CheckShot(petrel_name="159-F-10.txt"),
 CheckShot(petrel_name="159-F-12.txt"),
 CheckShot(petrel_name="checkshot_15_9_F_11T2.ASC"),
 CheckShot(petrel_name="159-F-15-D.txt"),
 CheckShot(petrel_name="159-19-A.txt"),
 CheckShot(petrel_name="159-F-15-B.txt"),
 CheckShot(petrel_name="159-F-15-C.txt"),
 CheckShot(petrel_name="159-F-19-SR.txt"),
 CheckShot(petrel_name="159-F-11-B.txt"),
 CheckShot(petrel_name="TDR"),
 CheckShot(petrel_name="checkshot_15_9_F_15A.txt"),
 CheckShot(petrel_name="159-F-14.txt"),
 CheckShot(petrel_name="checkshot_15_9_19_SR.txt"),
 CheckShot(petrel_name="159-19-BT2.txt")]
We can grab a single checkshot object by using list comprehension and matching its petrel_name with a string

checkshot = [i for i in petrel.checkshots if '15_9_F_15A' in i.petrel_name][0]
checkshot
CheckShot(petrel_name="checkshot_15_9_F_15A.txt")
Checkshot properties
Checkshots also allow most of the same properties and methods as other objects, such as the .petrel_name, .droid, .readonly, .path:

checkshot.petrel_name
'checkshot_15_9_F_15A.txt'
checkshot.droid
'3010e973-20a1-4c19-aa40-17445774440a'
checkshot.readonly
True
checkshot.path
'Input/Wells/Global well logs/checkshot_15_9_F_15A.txt'
Checkshot functions
We can access the stats using the .retrieve_stats() function:

checkshot.retrieve_stats()
{'Sum': '-418468.11',
 'Y Max': '6478481.9',
 'Lat Min': '58.4347911388889',
 '-----------------': '-----------------',
 'MD Min': '901',
 'Number of defined values': '191',
 'Long Max': '1.88782941666667',
 'Y Min': '6477823.02',
 'Std. dev.': '613.47',
 'Long Min': '1.86777647222222',
 'Y Delta': '658.88000000082',
 'Z Max': '-839.08',
 'X Min': '433898.07',
 'Number of wells': '1',
 'Z Delta': '2201.72',
 'Number of attributes': '6',
 'Delta': '2201.72',
 'Max': '-839.08',
 'Z Min': '-3040.8',
 'MD Max': '3940.1',
 'Min': '-3040.80',
 'MD Delta': '3039.1',
 'Number of points': '191',
 'Type of data': 'Continuous',
 'Mean': '-2190.93',
 'Lat Delta': '0.00609016666666662',
 'Variance': '376340.94',
 'X Max': '435058.17',
 'Lat Max': '58.4408813055556',
 'Long Delta': '0.0200529444444444',
 'X Delta': '1160.09999999998'}
You can retrieve the history of the checkshot using the .retrieve_history() function:

checkshot.retrieve_history()
Date	User	Action	Description
0	Oct 09 2018 10:31	gastonbe	Import Checkshots format (ASCII)	From: D:\Projects\VOLVE\Wells\VSP\Checkshots\c...
1	Oct 09 2018 10:31	gastonbe	Import	Imported data file D:\Projects\VOLVE\Wells\VSP...
2	Oct 09 2018 10:38	gastonbe	Spreadsheet changes	
The as_dataframe() function returns a dataframe of the checkshot data including the Petrel Index, MD, TWT, Average Velocity, Internal Velocity, Z and the Well :

checkshot_df = checkshot.as_dataframe()
checkshot_df
Petrel Index	MD	TWT	Average Velocity	Interval Velocity	Z	Well	Continuous
0	1	901.0	901.0	1862.55	1679.55	-839.08	15/9-F-15 A	54242.0
1	2	1082.4	1109.2	1828.20	2245.16	-1013.92	15/9-F-15 A	24.0
2	3	1097.5	1122.1	1832.99	2115.06	-1028.40	15/9-F-15 A	4.0
3	4	1112.2	1135.4	1836.30	2071.86	-1042.47	15/9-F-15 A	42.0
4	5	1127.4	1149.4	1839.17	2086.73	-1056.97	15/9-F-15 A	24.0
...	...	...	...	...	...	...	...	...
186	187	3879.5	2644.1	2268.11	3200.92	-2998.56	15/9-F-15 A	6.0
187	188	3894.7	2650.6	2270.40	3091.52	-3008.96	15/9-F-15 A	4.0
188	189	3909.9	2657.4	2272.50	3060.85	-3019.47	15/9-F-15 A	68.0
189	190	3925.0	2664.3	2274.54	3075.87	-3030.03	15/9-F-15 A	4.0
190	191	3940.1	2671.3	2276.64	NaN	-3040.80	15/9-F-15 A	453456.0
191 rows × 8 columns

You can filter the dataframe to only contain checkshot samples for the wells that exist in the current Petrel project using the include_unconnected_checkshots=False flag:

checkshot_df = checkshot.as_dataframe(include_unconnected_checkshots=False)
checkshot_df
Petrel Index	MD	TWT	Average Velocity	Interval Velocity	Z	Well	Continuous
0	1	901.0	901.0	1862.55	1679.55	-839.08	15/9-F-15 A	54242.0
1	2	1082.4	1109.2	1828.20	2245.16	-1013.92	15/9-F-15 A	24.0
2	3	1097.5	1122.1	1832.99	2115.06	-1028.40	15/9-F-15 A	4.0
3	4	1112.2	1135.4	1836.30	2071.86	-1042.47	15/9-F-15 A	42.0
4	5	1127.4	1149.4	1839.17	2086.73	-1056.97	15/9-F-15 A	24.0
...	...	...	...	...	...	...	...	...
186	187	3879.5	2644.1	2268.11	3200.92	-2998.56	15/9-F-15 A	6.0
187	188	3894.7	2650.6	2270.40	3091.52	-3008.96	15/9-F-15 A	4.0
188	189	3909.9	2657.4	2272.50	3060.85	-3019.47	15/9-F-15 A	68.0
189	190	3925.0	2664.3	2274.54	3075.87	-3030.03	15/9-F-15 A	4.0
190	191	3940.1	2671.3	2276.64	NaN	-3040.80	15/9-F-15 A	453456.0
191 rows × 8 columns

You can also exclude user-defined propertie from the checkshot using the include_user_defined_properties=False flag:

checkshot_df = checkshot.as_dataframe(include_user_defined_properties=False)
checkshot_df
add filter notes on the DF:

The .add_comment function will add a comment to the selected checkshot:

checkshot.readonly=False
checkshot.add_comment('This folder has been modified by Python Tool Pro')
The .comment property will return all the comments associated with the selected checkshot:

checkshot.comments
'This folder has been modified by Python Tool Pro'
=====
Templates
This Notebook provides examples on how to use Python Tool Pro to access Templates. Check out the API documentation to view a detailed description of all the functions and properties available for working with templates.

Note: The ability to access templates Templates is a feature available Python Tool Pro version 2.3.

#connect to local petrel project

from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()
print('Connected to {}'.format(petrel.get_current_project_name()))
Connected to Gullfaks_dataset_wells.pet
Continous templates
Using the .templates property, we can save all the continous templates to a dictionary where the keys represent the path of the template within the Petrel project and the value represents the name of the template .

petrel.templates
Templates({'Templates/Seismic templates/Seismic - Phase': Template(petrel_name="Seismic - Phase"), 'Templates/Petrophysical templates/Water velocity': Template(petrel_name="Water velocity"), 'Templates/Well log templates/Constant water resistivity': Template(petrel_name="Constant water resistivity"), 'Templates/Volume templates/Solution gas-oil ratio': Template(petrel_name="Solution gas-oil ratio"), 'Templates/Production templates/Reservoir production rate': Template(petrel_name="Reservoir production rate"), 'Templates/Continuous other templates/Temperature': Template(petrel_name="Temperature"), 'Templates/Geophysical templates/P-velocity': Template(petrel_name="P-velocity"), 'Templates/Well log templates/Density 1': Template(petrel_name="Density 1"), 'Templates/Geophysical templates/Vaporization heat': Template(petrel_name="Vaporization heat"), 'Templates/Geophysical templates/Inverse temperature': Template(petrel_name="Inverse temperature"), 'Templates/Production templates/Gas  mass production': Template(petrel_name="Gas  mass production"), 'Templates/Petrophysical templates/Lithology fraction': Template(petrel_name="Lithology fraction"), 'Templates/Geomechanic templates/Principal stress': Template(petrel_name="Principal stress"), 'Templates/RDR templates/Edge surface': Template(petrel_name="Edge surface"), 'Templates/Petrophysical templates/Permeability X': Template(petrel_name="Permeability X"), 'Templates/Production templates/Gas mass production rate': Template(petrel_name="Gas mass production rate"), 'Templates/Continuous fracture property templates/Fracture permeability': Template(petrel_name="Fracture permeability"), 'Templates/Well log templates/Sonic 1': Template(petrel_name="Sonic 1"), 'Templates/Well log templates/Bulk density correction': Template(petrel_name="Bulk density correction"), 'Templates/Production templates/Water cut': Template(petrel_name="Water cut"), 'Templates/Geophysical templates/V0 factor': Template(petrel_name="V0 factor"), 'Templates/Continuous other templates/Molar density': Template(petrel_name="Molar density"), 'Templates/Production templates/Liquid injection rate': Template(petrel_name="Liquid injection rate"), 'Templates/Geophysical templates/Gas phase thermal conductivity': Template(petrel_name="Gas phase thermal conductivity"), 'Templates/Well log templates/Open hole': Template(petrel_name="Open hole"), 'Templates/Petrophysical templates/Transmissibility J direction': Template(petrel_name="Transmissibility J direction"), 'Templates/Petrophysical templates/Oil velocity': Template(petrel_name="Oil velocity"), 'Templates/Geomechanic templates/Effective stress': Template(petrel_name="Effective stress"), 'Templates/Petrophysical templates/Permeability Z': Template(petrel_name="Permeability Z"), 'Templates/Geophysical templates/Heat transmissibility J': Template(petrel_name="Heat transmissibility J"), 'Templates/Well log templates/Gamma ray, thorium': Template(petrel_name="Gamma ray, thorium"), 'Templates/Production templates/Oil production rate': Template(petrel_name="Oil production rate"), 'Templates/Petrophysical templates/Gas heat capacity': Template(petrel_name="Gas heat capacity"), 'Templates/Seismic templates/Seismic - Polarity': Template(petrel_name="Seismic - Polarity"), 'Templates/Depth/thickness templates/Elevation general': Template(petrel_name="Elevation general"), 'Templates/Geophysical templates/Heat transfer coefficient': Template(petrel_name="Heat transfer coefficient"), 'Templates/Stimulation templates/Fracturing job time': Template(petrel_name="Fracturing job time"), 'Templates/Geometrical templates/Cell inside out': Template(petrel_name="Cell inside out"), 'Templates/Production templates/Water injection rate': Template(petrel_name="Water injection rate"), 'Templates/Wind energy templates/Normalised friction ratio': Template(petrel_name="Normalised friction ratio"), 'Templates/Geophysical templates/Acoustic impedance': Template(petrel_name="Acoustic impedance"), 'Templates/Petrophysical templates/Microemulsion saturation': Template(petrel_name="Microemulsion saturation"), 'Templates/Well log templates/Optical density': Template(petrel_name="Optical density"), 'Templates/Continuous other templates/Summary data': Template(petrel_name="Summary data"), 'Templates/Petrophysical templates/Water saturation': Template(petrel_name="Water saturation"), 'Templates/Continuous other templates/Mass flow rate': Template(petrel_name="Mass flow rate"), 'Templates/Depth/thickness templates/Thickness general': Template(petrel_name="Thickness general"), 'Templates/Production templates/Oil  mass production': Template(petrel_name="Oil  mass production"), 'Templates/Petrophysical templates/Saturation hydrocarbons': Template(petrel_name="Saturation hydrocarbons"), 'Templates/Continuous other templates/General': Template(petrel_name="General"), 'Templates/Continuous other templates/Lambda/Mu': Template(petrel_name="Lambda/Mu"), 'Templates/Completions templates/PI multiplier': Template(petrel_name="PI multiplier"), 'Templates/Geophysical templates/Water compressibility': Template(petrel_name="Water compressibility"), 'Templates/Petrophysical templates/Critical oil saturation': Template(petrel_name="Critical oil saturation"), 'Templates/Geometrical templates/Measured depth': Template(petrel_name="Measured depth"), 'Templates/Volume templates/Pore volume (map)': Template(petrel_name="Pore volume (map)"), 'Templates/Well log templates/Caliper': Template(petrel_name="Caliper"), 'Templates/Geomechanic templates/Friction angle': Template(petrel_name="Friction angle"), 'Templates/Wind energy templates/Corrected friction ratio': Template(petrel_name="Corrected friction ratio"), 'Templates/Continuous other templates/Erosional velocity': Template(petrel_name="Erosional velocity"), 'Templates/Geophysical templates/S-velocity': Template(petrel_name="S-velocity"), 'Templates/Geophysical templates/P/S velocity ratio': Template(petrel_name="P/S velocity ratio"), 'Templates/Geophysical templates/P-impedance': Template(petrel_name="P-impedance"), 'Templates/Volume templates/Recoverable oil (map)': Template(petrel_name="Recoverable oil (map)"), 'Templates/Drilling templates/Displacement': Template(petrel_name="Displacement"), 'Templates/Petrophysical templates/Porosity': Template(petrel_name="Porosity"), 'Templates/Seismic templates/Seismic - Gradient': Template(petrel_name="Seismic - Gradient"), 'Templates/Completions templates/Completion diameter': Template(petrel_name="Completion diameter"), 'Templates/Continuous other templates/Mass': Template(petrel_name="Mass"), 'Templates/Geometrical templates/X distance': Template(petrel_name="X distance"), 'Templates/Well log templates/Density': Template(petrel_name="Density"), 'Templates/Wind energy templates/Pore pressure behind friction sleeve': Template(petrel_name="Pore pressure behind friction sleeve"), 'Templates/Volume templates/Water formation volume factor': Template(petrel_name="Water formation volume factor"), 'Templates/Well log templates/Neutron': Template(petrel_name="Neutron"), 'Templates/Petrophysical templates/Pore volume multiplier': Template(petrel_name="Pore volume multiplier"), 'Templates/RDR templates/Confidence': Template(petrel_name="Confidence"), 'Templates/Wind energy templates/Sleeve friction resistance': Template(petrel_name="Sleeve friction resistance"), 'Templates/Stimulation templates/Clean fluid': Template(petrel_name="Clean fluid"), 'Templates/Completions templates/Completion depth': Template(petrel_name="Completion depth"), 'Templates/2D log templates/Capillary pressure': Template(petrel_name="Capillary pressure"), 'Templates/Production templates/Water  mass production': Template(petrel_name="Water  mass production"), 'Templates/Drilling templates/Inclination': Template(petrel_name="Inclination"), 'Templates/Completions templates/PI compressible fluid': Template(petrel_name="PI compressible fluid"), 'Templates/Well log templates/P-sonic': Template(petrel_name="P-sonic"), 'Templates/Geophysical templates/Thermal conductivity matrix-fracture': Template(petrel_name="Thermal conductivity matrix-fracture"), 'Templates/Completions templates/Skin': Template(petrel_name="Skin"), 'Templates/Seismic templates/Red(-) White Black(+)': Template(petrel_name="Red(-) White Black(+)"), 'Templates/Petroleum systems templates/Hydrogen index': Template(petrel_name="Hydrogen index"), 'Templates/Petrophysical templates/Permeability matrix-fracture': Template(petrel_name="Permeability matrix-fracture"), 'Templates/Continuous other templates/Motor speed': Template(petrel_name="Motor speed"), 'Templates/Petrophysical templates/Porosity - total': Template(petrel_name="Porosity - total"), 'Templates/Completions templates/ICD strength': Template(petrel_name="ICD strength"), 'Templates/Production templates/Reservoir energy density': Template(petrel_name="Reservoir energy density"), 'Templates/Continuous other templates/Water flow rate': Template(petrel_name="Water flow rate"), 'Templates/Petrophysical templates/Simulation time': Template(petrel_name="Simulation time"), 'Templates/Petrophysical templates/Mobility': Template(petrel_name="Mobility"), 'Templates/Well log templates/Resistivity, medium': Template(petrel_name="Resistivity, medium"), "Templates/Geomechanic templates/Young's modulus": Template(petrel_name="Young's modulus"), 'Templates/Continuous other templates/From facies': Template(petrel_name="From facies"), 'Templates/Well log templates/Micro resistivity': Template(petrel_name="Micro resistivity"), 'Templates/2D log templates/Relative permeability': Template(petrel_name="Relative permeability"), 'Templates/Continuous other templates/Percent': Template(petrel_name="Percent"), 'Templates/Volume templates/GIIP': Template(petrel_name="GIIP"), 'Templates/Production templates/Reservoir injection rate': Template(petrel_name="Reservoir injection rate"), 'Templates/Continuous other templates/Grain size diameter': Template(petrel_name="Grain size diameter"), 'Templates/Seismic templates/Seismic - Dip (angle)': Template(petrel_name="Seismic - Dip (angle)"), 'Templates/Petroleum systems templates/Geological time scale': Template(petrel_name="Geological time scale"), 'Templates/Petrophysical templates/Water viscosibility': Template(petrel_name="Water viscosibility"), 'Templates/Continuous other templates/Year': Template(petrel_name="Year"), 'Templates/Petrophysical templates/Net/Gross': Template(petrel_name="Net/Gross"), 'Templates/Continuous other templates/Well datum': Template(petrel_name="Well datum"), 'Templates/Seismic templates/Seismic - Dip azimuth': Template(petrel_name="Seismic - Dip azimuth"), 'Templates/Petrophysical templates/Permeability XY': Template(petrel_name="Permeability XY"), 'Templates/Continuous other templates/Second': Template(petrel_name="Second"), 'Templates/Petrophysical templates/Transmissibility K direction': Template(petrel_name="Transmissibility K direction"), 'Templates/Volume templates/Inverse oil formation volume factor, also known as InverseBoFactor': Template(petrel_name="Inverse oil formation volume factor, also known as InverseBoFactor"), 'Templates/Stimulation templates/Slurry': Template(petrel_name="Slurry"), 'Templates/Drilling templates/Hook load': Template(petrel_name="Hook load"), 'Templates/Geophysical templates/Interval velocity': Template(petrel_name="Interval velocity"), 'Templates/Volume templates/Recovery factor': Template(petrel_name="Recovery factor"), 'Templates/Stimulation templates/Clean fluid rate': Template(petrel_name="Clean fluid rate"), 'Templates/Geophysical templates/Compressional modulus': Template(petrel_name="Compressional modulus"), 'Templates/Petrophysical templates/Irr. water saturation': Template(petrel_name="Irr. water saturation"), 'Templates/Continuous other templates/Molar enthalpy': Template(petrel_name="Molar enthalpy"), 'Templates/Well log templates/Gamma ray, uranium': Template(petrel_name="Gamma ray, uranium"), 'Templates/Volume templates/Bulk volume (map)': Template(petrel_name="Bulk volume (map)"), 'Templates/Continuous fracture property templates/Linear fracture intensity': Template(petrel_name="Linear fracture intensity"), 'Templates/Volume templates/Bulk volume': Template(petrel_name="Bulk volume"), 'Templates/Completions templates/PI liquid': Template(petrel_name="PI liquid"), 'Templates/Geophysical templates/Rock compressibility': Template(petrel_name="Rock compressibility"), 'Templates/Geomechanic templates/Resis_NCT': Template(petrel_name="Resis_NCT"), 'Templates/Volume templates/GIIP (map)': Template(petrel_name="GIIP (map)"), 'Templates/Geophysical templates/Matrix-fracture coupling': Template(petrel_name="Matrix-fracture coupling"), 'Templates/Well log templates/Fracture pressure gradient as mud density': Template(petrel_name="Fracture pressure gradient as mud density"), 'Templates/Geophysical templates/Inverse temperature squared': Template(petrel_name="Inverse temperature squared"), 'Templates/Fault property templates/Fault displacement': Template(petrel_name="Fault displacement"), 'Templates/Continuous other templates/Compaction': Template(petrel_name="Compaction"), 'Templates/Continuous other templates/Molar rate': Template(petrel_name="Molar rate"), 'Templates/Geophysical templates/Rock heat capacity': Template(petrel_name="Rock heat capacity"), 'Templates/Geophysical templates/PS elastic-impedance': Template(petrel_name="PS elastic-impedance"), 'Templates/Geomechanic templates/Strain': Template(petrel_name="Strain"), 'Templates/Well log templates/Resistivity': Template(petrel_name="Resistivity"), 'Templates/Drilling templates/Penetration rate': Template(petrel_name="Penetration rate"), 'Templates/Depth/thickness templates/Elevation time': Template(petrel_name="Elevation time"), 'Templates/Volume templates/Inverse gas formation volume factor, also known as InverseBgFactor': Template(petrel_name="Inverse gas formation volume factor, also known as InverseBgFactor"), 'Templates/Petroleum systems templates/Gas generation': Template(petrel_name="Gas generation"), 'Templates/Petrophysical templates/Coal gas volume per mass': Template(petrel_name="Coal gas volume per mass"), 'Templates/Continuous other templates/Amount of substance': Template(petrel_name="Amount of substance"), 'Templates/Geophysical templates/K factor (depth)': Template(petrel_name="K factor (depth)"), 'Templates/Geophysical templates/GI': Template(petrel_name="GI"), 'Templates/Continuous other templates/Wave period time': Template(petrel_name="Wave period time"), 'Templates/Well log templates/Density, azimuth upwards': Template(petrel_name="Density, azimuth upwards"), 'Templates/Geophysical templates/K factor (time)': Template(petrel_name="K factor (time)"), 'Templates/Geomechanic templates/MudWeight': Template(petrel_name="MudWeight"), 'Templates/Well log templates/Gamma ray': Template(petrel_name="Gamma ray"), 'Templates/RDR templates/Influential surface data': Template(petrel_name="Influential surface data"), 'Templates/Geophysical templates/SI': Template(petrel_name="SI"), 'Templates/Continuous other templates/Geologic sediment velocity': Template(petrel_name="Geologic sediment velocity"), 'Templates/Wind energy templates/Normalised cone resistance': Template(petrel_name="Normalised cone resistance"), 'Templates/Geometrical templates/Dip angle': Template(petrel_name="Dip angle"), 'Templates/Drilling templates/Mud flow rate': Template(petrel_name="Mud flow rate"), 'Templates/Well log templates/Conductivity': Template(petrel_name="Conductivity"), 'Templates/Continuous other templates/Money': Template(petrel_name="Money"), 'Templates/Well log templates/Hole Size': Template(petrel_name="Hole Size"), 'Templates/Geophysical templates/Lambda': Template(petrel_name="Lambda"), 'Templates/Continuous other templates/Gas flow rate': Template(petrel_name="Gas flow rate"), 'Templates/Wind energy templates/Pore pressure behind cone': Template(petrel_name="Pore pressure behind cone"), 'Templates/Petrophysical templates/Permeability K': Template(petrel_name="Permeability K"), 'Templates/Well log templates/Constant mud resistivity': Template(petrel_name="Constant mud resistivity"), 'Templates/Geometrical templates/Oil-water contact': Template(petrel_name="Oil-water contact"), 'Templates/Petrophysical templates/Permeability IK': Template(petrel_name="Permeability IK"), 'Templates/Continuous other templates/Corrosion rate': Template(petrel_name="Corrosion rate"), 'Templates/Stimulation templates/Bottom hole proppant concentration': Template(petrel_name="Bottom hole proppant concentration"), 'Templates/Depth/thickness templates/True stratigraphic thickness': Template(petrel_name="True stratigraphic thickness"), 'Templates/Geophysical templates/Thermal resistance': Template(petrel_name="Thermal resistance"), 'Templates/Seismic templates/Seismic (default)': Template(petrel_name="Seismic (default)"), 'Templates/Volume templates/Pore volume': Template(petrel_name="Pore volume"), 'Templates/Petrophysical templates/Oil viscosity': Template(petrel_name="Oil viscosity"), 'Templates/Well log templates/Conductivity, deep': Template(petrel_name="Conductivity, deep"), 'Templates/Well log templates/Well bore radius': Template(petrel_name="Well bore radius"), 'Templates/Petrophysical templates/Irr. gas saturation': Template(petrel_name="Irr. gas saturation"), 'Templates/Continuous other templates/Hour': Template(petrel_name="Hour"), 'Templates/Volume templates/Rock volume': Template(petrel_name="Rock volume"), 'Templates/Wind energy templates/Bulk density of material': Template(petrel_name="Bulk density of material"), 'Templates/Seismic templates/Seismic - Local flatness': Template(petrel_name="Seismic - Local flatness"), 'Templates/Volume templates/STOIIP': Template(petrel_name="STOIIP"), 'Templates/Stimulation templates/Slurry rate': Template(petrel_name="Slurry rate"), 'Templates/Geometrical templates/Area': Template(petrel_name="Area"), 'Templates/Geophysical templates/Thermal conductivity of rock': Template(petrel_name="Thermal conductivity of rock"), 'Templates/Production templates/Gas-oil ratio': Template(petrel_name="Gas-oil ratio"), 'Templates/Continuous other templates/Energy': Template(petrel_name="Energy"), 'Templates/Drilling templates/Inverse penetration rate': Template(petrel_name="Inverse penetration rate"), 'Templates/Geomechanic templates/Pres_VES': Template(petrel_name="Pres_VES"), 'Templates/Continuous other templates/Principal component': Template(petrel_name="Principal component"), 'Templates/Continuous other templates/Total depth': Template(petrel_name="Total depth"), 'Templates/Continuous other templates/General integer': Template(petrel_name="General integer"), 'Templates/Continuous other templates/General derivative': Template(petrel_name="General derivative"), 'Templates/Production templates/Water-gas ratio': Template(petrel_name="Water-gas ratio"), 'Templates/Petrophysical templates/Water viscosity': Template(petrel_name="Water viscosity"), 'Templates/Geomechanic templates/Rock displacement': Template(petrel_name="Rock displacement"), 'Templates/Drilling templates/Mud density': Template(petrel_name="Mud density"), 'Templates/Petrophysical templates/Diffusivity': Template(petrel_name="Diffusivity"), 'Templates/Geomechanic templates/Vp_NCT': Template(petrel_name="Vp_NCT"), 'Templates/Geophysical templates/EI2': Template(petrel_name="EI2"), 'Templates/Wind energy templates/Corrected cone resistance': Template(petrel_name="Corrected cone resistance"), 'Templates/Well log templates/Density, azimuth downwards': Template(petrel_name="Density, azimuth downwards"), 'Templates/Well log templates/Pressure gradient': Template(petrel_name="Pressure gradient"), 'Templates/Volume templates/Oil formation volume factor': Template(petrel_name="Oil formation volume factor"), 'Templates/Geophysical templates/Matrix-fracture thermal coupling': Template(petrel_name="Matrix-fracture thermal coupling"), 'Templates/Geometrical templates/Delta time': Template(petrel_name="Delta time"), 'Templates/Petrophysical templates/Transmissibility I direction': Template(petrel_name="Transmissibility I direction"), 'Templates/Volume templates/Gas fluid-in-place': Template(petrel_name="Gas fluid-in-place"), 'Templates/Fault property templates/Transmissibility multiplier': Template(petrel_name="Transmissibility multiplier"), 'Templates/Wind energy templates/Pore pressure on cone': Template(petrel_name="Pore pressure on cone"), 'Templates/Geophysical templates/Mu*Rho': Template(petrel_name="Mu*Rho"), 'Templates/Continuous other templates/Sediment diffusion': Template(petrel_name="Sediment diffusion"), 'Templates/Production templates/Oil injection rate': Template(petrel_name="Oil injection rate"), 'Templates/2D log templates/Fractional flow': Template(petrel_name="Fractional flow"), 'Templates/Continuous other templates/Wave intensity': Template(petrel_name="Wave intensity"), 'Templates/Petroleum systems templates/Thermal gradient': Template(petrel_name="Thermal gradient"), 'Templates/Fault property templates/Shale gouge ratio': Template(petrel_name="Shale gouge ratio"), 'Templates/Geometrical templates/Cell angle': Template(petrel_name="Cell angle"), 'Templates/Geophysical templates/Bulk modulus': Template(petrel_name="Bulk modulus"), 'Templates/Petrophysical templates/Oil saturation': Template(petrel_name="Oil saturation"), 'Templates/Completions templates/Connection transmissibility': Template(petrel_name="Connection transmissibility"), 'Templates/Petrophysical templates/Saturation pressure': Template(petrel_name="Saturation pressure"), 'Templates/Seismic templates/Seismic - Attenuation': Template(petrel_name="Seismic - Attenuation"), 'Templates/Petrophysical templates/Permeability': Template(petrel_name="Permeability"), 'Templates/Well log templates/Stress as mud density': Template(petrel_name="Stress as mud density"), 'Templates/Wind energy templates/Soil moisture': Template(petrel_name="Soil moisture"), 'Templates/Geometrical templates/Gas-water contact': Template(petrel_name="Gas-water contact"), 'Templates/Stimulation templates/Gel concentration': Template(petrel_name="Gel concentration"), 'Templates/Well log templates/Caliper, mechanical': Template(petrel_name="Caliper, mechanical"), 'Templates/Production templates/Reservoir production volume': Template(petrel_name="Reservoir production volume"), 'Templates/Geophysical templates/Relative temperature': Template(petrel_name="Relative temperature"), 'Templates/Petrophysical templates/Permeability J': Template(petrel_name="Permeability J"), 'Templates/Drilling templates/Equiv. circulating density': Template(petrel_name="Equiv. circulating density"), 'Templates/Geophysical templates/Stacking velocity': Template(petrel_name="Stacking velocity"), 'Templates/Seismic templates/Seismic - Dip (ratio)': Template(petrel_name="Seismic - Dip (ratio)"), 'Templates/Completions templates/Completion area': Template(petrel_name="Completion area"), 'Templates/Geomechanic templates/Rock strength': Template(petrel_name="Rock strength"), 'Templates/Continuous other templates/Variance': Template(petrel_name="Variance"), 'Templates/Continuous other templates/Dimensionless fracture intensity': Template(petrel_name="Dimensionless fracture intensity"), 'Templates/Petroleum systems templates/Transformation ratio': Template(petrel_name="Transformation ratio"), 'Templates/Geometrical templates/Cell top depth': Template(petrel_name="Cell top depth"), 'Templates/Stimulation templates/Acidity': Template(petrel_name="Acidity"), 'Templates/Volume templates/HCPV gas': Template(petrel_name="HCPV gas"), 'Templates/Production templates/Liquid production': Template(petrel_name="Liquid production"), 'Templates/Wind energy templates/Effective cone resistance': Template(petrel_name="Effective cone resistance"), 'Templates/Well log templates/Density, compensated bulk': Template(petrel_name="Density, compensated bulk"), 'Templates/Petroleum systems templates/Heat flow': Template(petrel_name="Heat flow"), 'Templates/Geometrical templates/Compaction/dilation ratio': Template(petrel_name="Compaction/dilation ratio"), 'Templates/Well log templates/Caliper, acoustic stand-off': Template(petrel_name="Caliper, acoustic stand-off"), 'Templates/Geophysical templates/Specific heat capacity per temperature squared': Template(petrel_name="Specific heat capacity per temperature squared"), 'Templates/Production templates/Gas production rate': Template(petrel_name="Gas production rate"), 'Templates/Volume templates/HCPV gas (map)': Template(petrel_name="HCPV gas (map)"), 'Templates/Stimulation templates/Slurry density': Template(petrel_name="Slurry density"), 'Templates/Completions templates/Drainage radius': Template(petrel_name="Drainage radius"), 'Templates/Completions templates/PI gas': Template(petrel_name="PI gas"), 'Templates/Drilling templates/Average penetration rate': Template(petrel_name="Average penetration rate"), 'Templates/Geometrical templates/Cell X dimension': Template(petrel_name="Cell X dimension"), 'Templates/Wind energy templates/Corrected sleeve resistance': Template(petrel_name="Corrected sleeve resistance"), 'Templates/Seismic templates/Seismic - Correlation coefficient': Template(petrel_name="Seismic - Correlation coefficient"), 'Templates/Well log templates/Perforation connectivity': Template(petrel_name="Perforation connectivity"), 'Templates/Well log templates/Resistivity, deep': Template(petrel_name="Resistivity, deep"), 'Templates/Production templates/Energy flow rate': Template(petrel_name="Energy flow rate"), 'Templates/Geometrical templates/Cell Y dimension': Template(petrel_name="Cell Y dimension"), 'Templates/Seismic templates/Seismic - Cosine of phase': Template(petrel_name="Seismic - Cosine of phase"), 'Templates/Wind energy templates/Pore pressure ratio': Template(petrel_name="Pore pressure ratio"), 'Templates/Completions templates/Roughness': Template(petrel_name="Roughness"), 'Templates/Geometrical templates/One-way time': Template(petrel_name="One-way time"), 'Templates/Seismic templates/Surface attribute': Template(petrel_name="Surface attribute"), 'Templates/Geometrical templates/Y distance': Template(petrel_name="Y distance"), 'Templates/Well log templates/VShale': Template(petrel_name="VShale"), 'Templates/Petrophysical templates/Adsorption': Template(petrel_name="Adsorption"), 'Templates/Geomechanic templates/DExponent': Template(petrel_name="DExponent"), 'Templates/Geomechanic templates/Vs_NCT': Template(petrel_name="Vs_NCT"), 'Templates/Drilling templates/Drilling azimuth': Template(petrel_name="Drilling azimuth"), 'Templates/Depth/thickness templates/General time': Template(petrel_name="General time"), 'Templates/Geophysical templates/Heat transmissibility': Template(petrel_name="Heat transmissibility"), 'Templates/Continuous other templates/History match stepwise quantity': Template(petrel_name="History match stepwise quantity"), 'Templates/Stimulation templates/Nitrogen rate': Template(petrel_name="Nitrogen rate"), 'Templates/Continuous other templates/History match constant quantity': Template(petrel_name="History match constant quantity"), 'Templates/Geophysical templates/Thermal conductivity of rock and fluids': Template(petrel_name="Thermal conductivity of rock and fluids"), 'Templates/Wind energy templates/In situ pore pressure': Template(petrel_name="In situ pore pressure"), 'Templates/Production templates/Enthalpy flow rate': Template(petrel_name="Enthalpy flow rate"), 'Templates/Production templates/Uptime fraction': Template(petrel_name="Uptime fraction"), 'Templates/Geophysical templates/Z factor': Template(petrel_name="Z factor"), 'Templates/Geometrical templates/Gas-oil contact': Template(petrel_name="Gas-oil contact"), 'Templates/Geomechanic templates/Total stress': Template(petrel_name="Total stress"), 'Templates/Well log templates/S-sonic': Template(petrel_name="S-sonic"), 'Templates/Continuous other templates/Age': Template(petrel_name="Age"), 'Templates/Well log templates/Resistivity, shallow': Template(petrel_name="Resistivity, shallow"), 'Templates/Geophysical templates/E': Template(petrel_name="E"), 'Templates/Geometrical templates/Above contact': Template(petrel_name="Above contact"), 'Templates/Geomechanic templates/Pres_LITHO': Template(petrel_name="Pres_LITHO"), 'Templates/Fault property templates/Fault thickness': Template(petrel_name="Fault thickness"), 'Templates/Volume templates/Inverse water formation volume factor, also known as InverseBwFactor': Template(petrel_name="Inverse water formation volume factor, also known as InverseBwFactor"), 'Templates/Depth/thickness templates/Depth-depth relationship': Template(petrel_name="Depth-depth relationship"), 'Templates/Depth/thickness templates/True vertical thickness': Template(petrel_name="True vertical thickness"), 'Templates/Continuous other templates/Probability': Template(petrel_name="Probability"), 'Templates/Drilling templates/Annulus pressure': Template(petrel_name="Annulus pressure"), 'Templates/Depth/thickness templates/Elevation depth': Template(petrel_name="Elevation depth"), 'Templates/Petrophysical templates/Water saturation, residual oil': Template(petrel_name="Water saturation, residual oil"), 'Templates/Production templates/Gas production': Template(petrel_name="Gas production"), 'Templates/Production templates/Oil production': Template(petrel_name="Oil production"), 'Templates/Continuous other templates/Geologic water velocity': Template(petrel_name="Geologic water velocity"), 'Templates/Geometrical templates/Dip azimuth': Template(petrel_name="Dip azimuth"), 'Templates/Petrophysical templates/Porosity - effective': Template(petrel_name="Porosity - effective"), 'Templates/2D log templates/T2 distribution': Template(petrel_name="T2 distribution"), 'Templates/Petrophysical templates/Permeability XZ': Template(petrel_name="Permeability XZ"), 'Templates/Drilling templates/Vertical section': Template(petrel_name="Vertical section"), 'Templates/Geometrical templates/Cell height': Template(petrel_name="Cell height"), 'Templates/Petrophysical templates/Gas saturation, residual oil': Template(petrel_name="Gas saturation, residual oil"), 'Templates/Production templates/Water production': Template(petrel_name="Water production"), 'Templates/Petrophysical templates/Microemulsion viscosity': Template(petrel_name="Microemulsion viscosity"), 'Templates/Geophysical templates/Heat transmissibility I': Template(petrel_name="Heat transmissibility I"), 'Templates/Depth/thickness templates/Thickness depth': Template(petrel_name="Thickness depth"), 'Templates/Continuous other templates/Distribution frequency': Template(petrel_name="Distribution frequency"), 'Templates/Well log templates/Pore pressure gradient as mud density': Template(petrel_name="Pore pressure gradient as mud density"), 'Templates/Petroleum systems templates/Vitrinite reflectance': Template(petrel_name="Vitrinite reflectance"), 'Templates/Seismic templates/Seismic - Shape index': Template(petrel_name="Seismic - Shape index"), 'Templates/Continuous fracture property templates/Fracture aperture': Template(petrel_name="Fracture aperture"), 'Templates/Geophysical templates/Liquid density': Template(petrel_name="Liquid density"), 'Templates/Petrophysical templates/Net pay': Template(petrel_name="Net pay"), 'Templates/Seismic templates/Seismic - Consistent curvature': Template(petrel_name="Seismic - Consistent curvature"), 'Templates/Well log templates/Gamma ray, potassium': Template(petrel_name="Gamma ray, potassium"), 'Templates/Petrophysical templates/Critical water saturation': Template(petrel_name="Critical water saturation"), 'Templates/Geometrical templates/Uncertainty': Template(petrel_name="Uncertainty"), 'Templates/Continuous other templates/History match polyline quantity': Template(petrel_name="History match polyline quantity"), 'Templates/Petrophysical templates/Critical gas saturation': Template(petrel_name="Critical gas saturation"), 'Templates/Volume templates/STOIIP (map)': Template(petrel_name="STOIIP (map)"), 'Templates/Drilling templates/Weight on bit': Template(petrel_name="Weight on bit"), 'Templates/Wind energy templates/Excess pore pressure': Template(petrel_name="Excess pore pressure"), 'Templates/Petroleum systems templates/Oil generation': Template(petrel_name="Oil generation"), 'Templates/Geophysical templates/Shear modulus': Template(petrel_name="Shear modulus"), 'Templates/Continuous other templates/Acceleration': Template(petrel_name="Acceleration"), 'Templates/Petrophysical templates/Gas saturation': Template(petrel_name="Gas saturation"), 'Templates/Seismic templates/Seismic - Frequency': Template(petrel_name="Seismic - Frequency"), 'Templates/Geophysical templates/Extended elastic impedance': Template(petrel_name="Extended elastic impedance"), 'Templates/Geosteering templates/Neutron, Geosteering': Template(petrel_name="Neutron, Geosteering"), 'Templates/Geophysical templates/Water phase thermal conductivity': Template(petrel_name="Water phase thermal conductivity"), 'Templates/Volume templates/Gas formation volume factor': Template(petrel_name="Gas formation volume factor"), 'Templates/Continuous other templates/Molar mass': Template(petrel_name="Molar mass"), 'Templates/Production templates/Water production rate': Template(petrel_name="Water production rate"), 'Templates/Geomechanic templates/Rho_NCT': Template(petrel_name="Rho_NCT"), 'Templates/Drilling templates/Bit depth': Template(petrel_name="Bit depth"), 'Templates/Volume templates/Net volume (map)': Template(petrel_name="Net volume (map)"), 'Templates/Drilling templates/Torque': Template(petrel_name="Torque"), 'Templates/Geophysical templates/PP elastic-impedance': Template(petrel_name="PP elastic-impedance"), 'Templates/Geomechanic templates/DExponent_NCT': Template(petrel_name="DExponent_NCT"), 'Templates/Continuous other templates/Fraction': Template(petrel_name="Fraction"), 'Templates/Volume templates/Water fluid-in-place': Template(petrel_name="Water fluid-in-place"), 'Templates/Volume templates/Net volume': Template(petrel_name="Net volume"), 'Templates/Petrophysical templates/Permeability IJ': Template(petrel_name="Permeability IJ"), 'Templates/Geophysical templates/Reflection coefficients': Template(petrel_name="Reflection coefficients"), 'Templates/Stimulation templates/Liquid concentration': Template(petrel_name="Liquid concentration"), 'Templates/Well log templates/General production': Template(petrel_name="General production"), 'Templates/Continuous other templates/Concentration': Template(petrel_name="Concentration"), 'Templates/Petrophysical templates/Surface tension': Template(petrel_name="Surface tension"), 'Templates/Seismic templates/Seismic - Edge': Template(petrel_name="Seismic - Edge"), 'Templates/Wind energy templates/Friction ratio': Template(petrel_name="Friction ratio"), 'Templates/Stimulation templates/Proppant concentration': Template(petrel_name="Proppant concentration"), 'Templates/Volume templates/Recoverable gas': Template(petrel_name="Recoverable gas"), 'Templates/Geophysical templates/Rock density': Template(petrel_name="Rock density"), 'Templates/Well log templates/Spontaneous potential': Template(petrel_name="Spontaneous potential"), 'Templates/Well log templates/Constant water salinity': Template(petrel_name="Constant water salinity"), 'Templates/Drilling templates/Angular velocity': Template(petrel_name="Angular velocity"), 'Templates/Continuous other templates/Point density': Template(petrel_name="Point density"), 'Templates/Volume templates/Recoverable oil': Template(petrel_name="Recoverable oil"), 'Templates/Petrophysical templates/Well Index': Template(petrel_name="Well Index"), 'Templates/Well log templates/Conductivity, medium': Template(petrel_name="Conductivity, medium"), 'Templates/Production templates/Bottom hole pressure': Template(petrel_name="Bottom hole pressure"), 'Templates/Geophysical templates/Solid phase thermal conductivity': Template(petrel_name="Solid phase thermal conductivity"), 'Templates/Continuous other templates/Plug back tot. depth': Template(petrel_name="Plug back tot. depth"), 'Templates/Volume templates/HCPV oil': Template(petrel_name="HCPV oil"), 'Templates/Petrophysical templates/Permeability I': Template(petrel_name="Permeability I"), 'Templates/Petrophysical templates/Gas viscosity': Template(petrel_name="Gas viscosity"), 'Templates/Geophysical templates/SEI2': Template(petrel_name="SEI2"), 'Templates/Petrophysical templates/Permeability Y': Template(petrel_name="Permeability Y"), 'Templates/Continuous other templates/Holdup (volume %)': Template(petrel_name="Holdup (volume %)"), 'Templates/Continuous other templates/Coal gas concentration': Template(petrel_name="Coal gas concentration"), 'Templates/Continuous fracture property templates/Fracture compressibility': Template(petrel_name="Fracture compressibility"), 'Templates/Drilling templates/Inside diameter': Template(petrel_name="Inside diameter"), 'Templates/Stimulation templates/Treating pressure': Template(petrel_name="Treating pressure"), 'Templates/Stimulation templates/Proppant': Template(petrel_name="Proppant"), 'Templates/Production templates/Oil-gas ratio': Template(petrel_name="Oil-gas ratio"), 'Templates/Petrophysical templates/Permeability YZ': Template(petrel_name="Permeability YZ"), 'Templates/Geometrical templates/Depth seabed': Template(petrel_name="Depth seabed"), 'Templates/Well log templates/Deepening': Template(petrel_name="Deepening"), 'Templates/Production templates/Oil mass production rate': Template(petrel_name="Oil mass production rate"), 'Templates/Geometrical templates/Distance': Template(petrel_name="Distance"), 'Templates/Production templates/Liquid production rate': Template(petrel_name="Liquid production rate"), 'Templates/Drilling templates/Downhole torque': Template(petrel_name="Downhole torque"), 'Templates/Petroleum systems templates/Gas content': Template(petrel_name="Gas content"), 'Templates/Stimulation templates/Carbon dioxide rate': Template(petrel_name="Carbon dioxide rate"), 'Templates/Continuous other templates/Erosion rate': Template(petrel_name="Erosion rate"), 'Templates/Geophysical templates/Absolute temperature': Template(petrel_name="Absolute temperature"), 'Templates/Geophysical templates/Specific heat capacity per temperature': Template(petrel_name="Specific heat capacity per temperature"), 'Templates/Well log templates/Happy day': Template(petrel_name="Happy day"), 'Templates/Wind energy templates/Cone resistance': Template(petrel_name="Cone resistance"), 'Templates/Production templates/Water mass production rate': Template(petrel_name="Water mass production rate"), 'Templates/Petrophysical templates/Permeability JK': Template(petrel_name="Permeability JK"), 'Templates/Petrophysical templates/Gas velocity': Template(petrel_name="Gas velocity"), 'Templates/Geophysical templates/Poissons ratio': Template(petrel_name="Poissons ratio"), 'Templates/Well log templates/Pressure gradient as mud density': Template(petrel_name="Pressure gradient as mud density"), 'Templates/Petrophysical templates/Oil heat capacity': Template(petrel_name="Oil heat capacity"), 'Templates/Geophysical templates/Differential temperature': Template(petrel_name="Differential temperature"), 'Templates/Seismic templates/Volume Rendering': Template(petrel_name="Volume Rendering"), 'Templates/Continuous other templates/History match quantitative': Template(petrel_name="History match quantitative"), 'Templates/Continuous other templates/Molar volume': Template(petrel_name="Molar volume"), 'Templates/Continuous other templates/Duration': Template(petrel_name="Duration"), 'Templates/Wind energy templates/Net cone resistance': Template(petrel_name="Net cone resistance"), 'Templates/Volume templates/Oil fluid-in-place': Template(petrel_name="Oil fluid-in-place"), 'Templates/Petrophysical templates/Pressure': Template(petrel_name="Pressure"), 'Templates/Geophysical templates/Wavelet': Template(petrel_name="Wavelet"), 'Templates/Geophysical templates/S-impedance': Template(petrel_name="S-impedance"), 'Templates/Volume templates/HCPV oil (map)': Template(petrel_name="HCPV oil (map)"), 'Templates/Geophysical templates/Mu': Template(petrel_name="Mu"), 'Templates/Fault property templates/Fault permeability': Template(petrel_name="Fault permeability"), 'Templates/Drilling templates/Standpipe pressure': Template(petrel_name="Standpipe pressure"), 'Templates/Well log templates/Dogleg severity': Template(petrel_name="Dogleg severity"), 'Templates/Geophysical templates/Heat transmissibility K': Template(petrel_name="Heat transmissibility K"), 'Templates/Geophysical templates/Average velocity': Template(petrel_name="Average velocity"), 'Templates/Geometrical templates/Two-way time': Template(petrel_name="Two-way time"), 'Templates/Seismic templates/Seismic - Ant tracking': Template(petrel_name="Seismic - Ant tracking"), 'Templates/Completions templates/Permeability-length': Template(petrel_name="Permeability-length"), 'Templates/Geophysical templates/Oil phase thermal conductivity': Template(petrel_name="Oil phase thermal conductivity"), 'Templates/Seismic templates/Seismic - Variance': Template(petrel_name="Seismic - Variance"), 'Templates/Well log templates/Sonic': Template(petrel_name="Sonic"), 'Templates/Seismic templates/Seismic - Contrast': Template(petrel_name="Seismic - Contrast"), 'Templates/Volume templates/Recoverable gas (map)': Template(petrel_name="Recoverable gas (map)"), 'Templates/Production templates/Gas injection rate': Template(petrel_name="Gas injection rate"), 'Templates/Continuous other templates/Oil flow rate': Template(petrel_name="Oil flow rate"), 'Templates/Geophysical templates/Velocity': Template(petrel_name="Velocity"), 'Templates/Petrophysical templates/Water heat capacity': Template(petrel_name="Water heat capacity"), 'Templates/Volume templates/Vapourized oil-gas ratio': Template(petrel_name="Vapourized oil-gas ratio"), 'Templates/Geometrical templates/Dip quality': Template(petrel_name="Dip quality"), 'Templates/Geophysical templates/Lambda*Rho': Template(petrel_name="Lambda*Rho"), 'Templates/Seismic templates/Seismic - Dip error': Template(petrel_name="Seismic - Dip error"), 'Templates/Stimulation templates/Reservoir mass density': Template(petrel_name="Reservoir mass density"), 'Templates/Geophysical templates/SEI1': Template(petrel_name="SEI1"), 'Templates/Geometrical templates/Residual': Template(petrel_name="Residual"), 'Templates/Well log templates/Conductivity, shallow': Template(petrel_name="Conductivity, shallow"), 'Templates/Geophysical templates/EI3': Template(petrel_name="EI3"), 'Templates/Well log templates/Photoelectric factor': Template(petrel_name="Photoelectric factor"), 'Templates/Geophysical templates/Rock heat capacity temp. coefficient': Template(petrel_name="Rock heat capacity temp. coefficient"), 'Templates/Depth/thickness templates/Thickness time': Template(petrel_name="Thickness time")})
Using list comprehension, the templates can be viewed as a list:

templates_list= [tl for tl in petrel.templates]
templates_list
[Template(petrel_name="Seismic - Phase"),
 Template(petrel_name="Water velocity"),
 Template(petrel_name="Constant water resistivity"),
 Template(petrel_name="Solution gas-oil ratio"),
 Template(petrel_name="Reservoir production rate"),
 Template(petrel_name="Temperature"),
 Template(petrel_name="P-velocity"),
 Template(petrel_name="Density 1"),
 Template(petrel_name="Vaporization heat"),
 Template(petrel_name="Inverse temperature"),
 Template(petrel_name="Gas  mass production"),
 Template(petrel_name="Lithology fraction"),
 Template(petrel_name="Principal stress"),
 Template(petrel_name="Edge surface"),
 Template(petrel_name="Permeability X"),
 Template(petrel_name="Gas mass production rate"),
 Template(petrel_name="Fracture permeability"),
 Template(petrel_name="Sonic 1"),
 Template(petrel_name="Bulk density correction"),
 Template(petrel_name="Water cut"),
 Template(petrel_name="V0 factor"),
 Template(petrel_name="Molar density"),
 Template(petrel_name="Liquid injection rate"),
 Template(petrel_name="Gas phase thermal conductivity"),
 Template(petrel_name="Open hole"),
 Template(petrel_name="Transmissibility J direction"),
 Template(petrel_name="Oil velocity"),
 Template(petrel_name="Effective stress"),
 Template(petrel_name="Permeability Z"),
 Template(petrel_name="Heat transmissibility J"),
 Template(petrel_name="Gamma ray, thorium"),
 Template(petrel_name="Oil production rate"),
 Template(petrel_name="Gas heat capacity"),
 Template(petrel_name="Seismic - Polarity"),
 Template(petrel_name="Elevation general"),
 Template(petrel_name="Heat transfer coefficient"),
 Template(petrel_name="Fracturing job time"),
 Template(petrel_name="Cell inside out"),
 Template(petrel_name="Water injection rate"),
 Template(petrel_name="Normalised friction ratio"),
 Template(petrel_name="Acoustic impedance"),
 Template(petrel_name="Microemulsion saturation"),
 Template(petrel_name="Optical density"),
 Template(petrel_name="Summary data"),
 Template(petrel_name="Water saturation"),
 Template(petrel_name="Mass flow rate"),
 Template(petrel_name="Thickness general"),
 Template(petrel_name="Oil  mass production"),
 Template(petrel_name="Saturation hydrocarbons"),
 Template(petrel_name="General"),
 Template(petrel_name="Lambda/Mu"),
 Template(petrel_name="PI multiplier"),
 Template(petrel_name="Water compressibility"),
 Template(petrel_name="Critical oil saturation"),
 Template(petrel_name="Measured depth"),
 Template(petrel_name="Pore volume (map)"),
 Template(petrel_name="Caliper"),
 Template(petrel_name="Friction angle"),
 Template(petrel_name="Corrected friction ratio"),
 Template(petrel_name="Erosional velocity"),
 Template(petrel_name="S-velocity"),
 Template(petrel_name="P/S velocity ratio"),
 Template(petrel_name="P-impedance"),
 Template(petrel_name="Recoverable oil (map)"),
 Template(petrel_name="Displacement"),
 Template(petrel_name="Porosity"),
 Template(petrel_name="Seismic - Gradient"),
 Template(petrel_name="Completion diameter"),
 Template(petrel_name="Mass"),
 Template(petrel_name="X distance"),
 Template(petrel_name="Density"),
 Template(petrel_name="Pore pressure behind friction sleeve"),
 Template(petrel_name="Water formation volume factor"),
 Template(petrel_name="Neutron"),
 Template(petrel_name="Pore volume multiplier"),
 Template(petrel_name="Confidence"),
 Template(petrel_name="Sleeve friction resistance"),
 Template(petrel_name="Clean fluid"),
 Template(petrel_name="Completion depth"),
 Template(petrel_name="Capillary pressure"),
 Template(petrel_name="Water  mass production"),
 Template(petrel_name="Inclination"),
 Template(petrel_name="PI compressible fluid"),
 Template(petrel_name="P-sonic"),
 Template(petrel_name="Thermal conductivity matrix-fracture"),
 Template(petrel_name="Skin"),
 Template(petrel_name="Red(-) White Black(+)"),
 Template(petrel_name="Hydrogen index"),
 Template(petrel_name="Permeability matrix-fracture"),
 Template(petrel_name="Motor speed"),
 Template(petrel_name="Porosity - total"),
 Template(petrel_name="ICD strength"),
 Template(petrel_name="Reservoir energy density"),
 Template(petrel_name="Water flow rate"),
 Template(petrel_name="Simulation time"),
 Template(petrel_name="Mobility"),
 Template(petrel_name="Resistivity, medium"),
 Template(petrel_name="Young's modulus"),
 Template(petrel_name="From facies"),
 Template(petrel_name="Micro resistivity"),
 Template(petrel_name="Relative permeability"),
 Template(petrel_name="Percent"),
 Template(petrel_name="GIIP"),
 Template(petrel_name="Reservoir injection rate"),
 Template(petrel_name="Grain size diameter"),
 Template(petrel_name="Seismic - Dip (angle)"),
 Template(petrel_name="Geological time scale"),
 Template(petrel_name="Water viscosibility"),
 Template(petrel_name="Year"),
 Template(petrel_name="Net/Gross"),
 Template(petrel_name="Well datum"),
 Template(petrel_name="Seismic - Dip azimuth"),
 Template(petrel_name="Permeability XY"),
 Template(petrel_name="Second"),
 Template(petrel_name="Transmissibility K direction"),
 Template(petrel_name="Inverse oil formation volume factor, also known as InverseBoFactor"),
 Template(petrel_name="Slurry"),
 Template(petrel_name="Hook load"),
 Template(petrel_name="Interval velocity"),
 Template(petrel_name="Recovery factor"),
 Template(petrel_name="Clean fluid rate"),
 Template(petrel_name="Compressional modulus"),
 Template(petrel_name="Irr. water saturation"),
 Template(petrel_name="Molar enthalpy"),
 Template(petrel_name="Gamma ray, uranium"),
 Template(petrel_name="Bulk volume (map)"),
 Template(petrel_name="Linear fracture intensity"),
 Template(petrel_name="Bulk volume"),
 Template(petrel_name="PI liquid"),
 Template(petrel_name="Rock compressibility"),
 Template(petrel_name="Resis_NCT"),
 Template(petrel_name="GIIP (map)"),
 Template(petrel_name="Matrix-fracture coupling"),
 Template(petrel_name="Fracture pressure gradient as mud density"),
 Template(petrel_name="Inverse temperature squared"),
 Template(petrel_name="Fault displacement"),
 Template(petrel_name="Compaction"),
 Template(petrel_name="Molar rate"),
 Template(petrel_name="Rock heat capacity"),
 Template(petrel_name="PS elastic-impedance"),
 Template(petrel_name="Strain"),
 Template(petrel_name="Resistivity"),
 Template(petrel_name="Penetration rate"),
 Template(petrel_name="Elevation time"),
 Template(petrel_name="Inverse gas formation volume factor, also known as InverseBgFactor"),
 Template(petrel_name="Gas generation"),
 Template(petrel_name="Coal gas volume per mass"),
 Template(petrel_name="Amount of substance"),
 Template(petrel_name="K factor (depth)"),
 Template(petrel_name="GI"),
 Template(petrel_name="Wave period time"),
 Template(petrel_name="Density, azimuth upwards"),
 Template(petrel_name="K factor (time)"),
 Template(petrel_name="MudWeight"),
 Template(petrel_name="Gamma ray"),
 Template(petrel_name="Influential surface data"),
 Template(petrel_name="SI"),
 Template(petrel_name="Geologic sediment velocity"),
 Template(petrel_name="Normalised cone resistance"),
 Template(petrel_name="Dip angle"),
 Template(petrel_name="Mud flow rate"),
 Template(petrel_name="Conductivity"),
 Template(petrel_name="Money"),
 Template(petrel_name="Hole Size"),
 Template(petrel_name="Lambda"),
 Template(petrel_name="Gas flow rate"),
 Template(petrel_name="Pore pressure behind cone"),
 Template(petrel_name="Permeability K"),
 Template(petrel_name="Constant mud resistivity"),
 Template(petrel_name="Oil-water contact"),
 Template(petrel_name="Permeability IK"),
 Template(petrel_name="Corrosion rate"),
 Template(petrel_name="Bottom hole proppant concentration"),
 Template(petrel_name="True stratigraphic thickness"),
 Template(petrel_name="Thermal resistance"),
 Template(petrel_name="Seismic (default)"),
 Template(petrel_name="Pore volume"),
 Template(petrel_name="Oil viscosity"),
 Template(petrel_name="Conductivity, deep"),
 Template(petrel_name="Well bore radius"),
 Template(petrel_name="Irr. gas saturation"),
 Template(petrel_name="Hour"),
 Template(petrel_name="Rock volume"),
 Template(petrel_name="Bulk density of material"),
 Template(petrel_name="Seismic - Local flatness"),
 Template(petrel_name="STOIIP"),
 Template(petrel_name="Slurry rate"),
 Template(petrel_name="Area"),
 Template(petrel_name="Thermal conductivity of rock"),
 Template(petrel_name="Gas-oil ratio"),
 Template(petrel_name="Energy"),
 Template(petrel_name="Inverse penetration rate"),
 Template(petrel_name="Pres_VES"),
 Template(petrel_name="Principal component"),
 Template(petrel_name="Total depth"),
 Template(petrel_name="General integer"),
 Template(petrel_name="General derivative"),
 Template(petrel_name="Water-gas ratio"),
 Template(petrel_name="Water viscosity"),
 Template(petrel_name="Rock displacement"),
 Template(petrel_name="Mud density"),
 Template(petrel_name="Diffusivity"),
 Template(petrel_name="Vp_NCT"),
 Template(petrel_name="EI2"),
 Template(petrel_name="Corrected cone resistance"),
 Template(petrel_name="Density, azimuth downwards"),
 Template(petrel_name="Pressure gradient"),
 Template(petrel_name="Oil formation volume factor"),
 Template(petrel_name="Matrix-fracture thermal coupling"),
 Template(petrel_name="Delta time"),
 Template(petrel_name="Transmissibility I direction"),
 Template(petrel_name="Gas fluid-in-place"),
 Template(petrel_name="Transmissibility multiplier"),
 Template(petrel_name="Pore pressure on cone"),
 Template(petrel_name="Mu*Rho"),
 Template(petrel_name="Sediment diffusion"),
 Template(petrel_name="Oil injection rate"),
 Template(petrel_name="Fractional flow"),
 Template(petrel_name="Wave intensity"),
 Template(petrel_name="Thermal gradient"),
 Template(petrel_name="Shale gouge ratio"),
 Template(petrel_name="Cell angle"),
 Template(petrel_name="Bulk modulus"),
 Template(petrel_name="Oil saturation"),
 Template(petrel_name="Connection transmissibility"),
 Template(petrel_name="Saturation pressure"),
 Template(petrel_name="Seismic - Attenuation"),
 Template(petrel_name="Permeability"),
 Template(petrel_name="Stress as mud density"),
 Template(petrel_name="Soil moisture"),
 Template(petrel_name="Gas-water contact"),
 Template(petrel_name="Gel concentration"),
 Template(petrel_name="Caliper, mechanical"),
 Template(petrel_name="Reservoir production volume"),
 Template(petrel_name="Relative temperature"),
 Template(petrel_name="Permeability J"),
 Template(petrel_name="Equiv. circulating density"),
 Template(petrel_name="Stacking velocity"),
 Template(petrel_name="Seismic - Dip (ratio)"),
 Template(petrel_name="Completion area"),
 Template(petrel_name="Rock strength"),
 Template(petrel_name="Variance"),
 Template(petrel_name="Dimensionless fracture intensity"),
 Template(petrel_name="Transformation ratio"),
 Template(petrel_name="Cell top depth"),
 Template(petrel_name="Acidity"),
 Template(petrel_name="HCPV gas"),
 Template(petrel_name="Liquid production"),
 Template(petrel_name="Effective cone resistance"),
 Template(petrel_name="Density, compensated bulk"),
 Template(petrel_name="Heat flow"),
 Template(petrel_name="Compaction/dilation ratio"),
 Template(petrel_name="Caliper, acoustic stand-off"),
 Template(petrel_name="Specific heat capacity per temperature squared"),
 Template(petrel_name="Gas production rate"),
 Template(petrel_name="HCPV gas (map)"),
 Template(petrel_name="Slurry density"),
 Template(petrel_name="Drainage radius"),
 Template(petrel_name="PI gas"),
 Template(petrel_name="Average penetration rate"),
 Template(petrel_name="Cell X dimension"),
 Template(petrel_name="Corrected sleeve resistance"),
 Template(petrel_name="Seismic - Correlation coefficient"),
 Template(petrel_name="Perforation connectivity"),
 Template(petrel_name="Resistivity, deep"),
 Template(petrel_name="Energy flow rate"),
 Template(petrel_name="Cell Y dimension"),
 Template(petrel_name="Seismic - Cosine of phase"),
 Template(petrel_name="Pore pressure ratio"),
 Template(petrel_name="Roughness"),
 Template(petrel_name="One-way time"),
 Template(petrel_name="Surface attribute"),
 Template(petrel_name="Y distance"),
 Template(petrel_name="VShale"),
 Template(petrel_name="Adsorption"),
 Template(petrel_name="DExponent"),
 Template(petrel_name="Vs_NCT"),
 Template(petrel_name="Drilling azimuth"),
 Template(petrel_name="General time"),
 Template(petrel_name="Heat transmissibility"),
 Template(petrel_name="History match stepwise quantity"),
 Template(petrel_name="Nitrogen rate"),
 Template(petrel_name="History match constant quantity"),
 Template(petrel_name="Thermal conductivity of rock and fluids"),
 Template(petrel_name="In situ pore pressure"),
 Template(petrel_name="Enthalpy flow rate"),
 Template(petrel_name="Uptime fraction"),
 Template(petrel_name="Z factor"),
 Template(petrel_name="Gas-oil contact"),
 Template(petrel_name="Total stress"),
 Template(petrel_name="S-sonic"),
 Template(petrel_name="Age"),
 Template(petrel_name="Resistivity, shallow"),
 Template(petrel_name="E"),
 Template(petrel_name="Above contact"),
 Template(petrel_name="Pres_LITHO"),
 Template(petrel_name="Fault thickness"),
 Template(petrel_name="Inverse water formation volume factor, also known as InverseBwFactor"),
 Template(petrel_name="Depth-depth relationship"),
 Template(petrel_name="True vertical thickness"),
 Template(petrel_name="Probability"),
 Template(petrel_name="Annulus pressure"),
 Template(petrel_name="Elevation depth"),
 Template(petrel_name="Water saturation, residual oil"),
 Template(petrel_name="Gas production"),
 Template(petrel_name="Oil production"),
 Template(petrel_name="Geologic water velocity"),
 Template(petrel_name="Dip azimuth"),
 Template(petrel_name="Porosity - effective"),
 Template(petrel_name="T2 distribution"),
 Template(petrel_name="Permeability XZ"),
 Template(petrel_name="Vertical section"),
 Template(petrel_name="Cell height"),
 Template(petrel_name="Gas saturation, residual oil"),
 Template(petrel_name="Water production"),
 Template(petrel_name="Microemulsion viscosity"),
 Template(petrel_name="Heat transmissibility I"),
 Template(petrel_name="Thickness depth"),
 Template(petrel_name="Distribution frequency"),
 Template(petrel_name="Pore pressure gradient as mud density"),
 Template(petrel_name="Vitrinite reflectance"),
 Template(petrel_name="Seismic - Shape index"),
 Template(petrel_name="Fracture aperture"),
 Template(petrel_name="Liquid density"),
 Template(petrel_name="Net pay"),
 Template(petrel_name="Seismic - Consistent curvature"),
 Template(petrel_name="Gamma ray, potassium"),
 Template(petrel_name="Critical water saturation"),
 Template(petrel_name="Uncertainty"),
 Template(petrel_name="History match polyline quantity"),
 Template(petrel_name="Critical gas saturation"),
 Template(petrel_name="STOIIP (map)"),
 Template(petrel_name="Weight on bit"),
 Template(petrel_name="Excess pore pressure"),
 Template(petrel_name="Oil generation"),
 Template(petrel_name="Shear modulus"),
 Template(petrel_name="Acceleration"),
 Template(petrel_name="Gas saturation"),
 Template(petrel_name="Seismic - Frequency"),
 Template(petrel_name="Extended elastic impedance"),
 Template(petrel_name="Neutron, Geosteering"),
 Template(petrel_name="Water phase thermal conductivity"),
 Template(petrel_name="Gas formation volume factor"),
 Template(petrel_name="Molar mass"),
 Template(petrel_name="Water production rate"),
 Template(petrel_name="Rho_NCT"),
 Template(petrel_name="Bit depth"),
 Template(petrel_name="Net volume (map)"),
 Template(petrel_name="Torque"),
 Template(petrel_name="PP elastic-impedance"),
 Template(petrel_name="DExponent_NCT"),
 Template(petrel_name="Fraction"),
 Template(petrel_name="Water fluid-in-place"),
 Template(petrel_name="Net volume"),
 Template(petrel_name="Permeability IJ"),
 Template(petrel_name="Reflection coefficients"),
 Template(petrel_name="Liquid concentration"),
 Template(petrel_name="General production"),
 Template(petrel_name="Concentration"),
 Template(petrel_name="Surface tension"),
 Template(petrel_name="Seismic - Edge"),
 Template(petrel_name="Friction ratio"),
 Template(petrel_name="Proppant concentration"),
 Template(petrel_name="Recoverable gas"),
 Template(petrel_name="Rock density"),
 Template(petrel_name="Spontaneous potential"),
 Template(petrel_name="Constant water salinity"),
 Template(petrel_name="Angular velocity"),
 Template(petrel_name="Point density"),
 Template(petrel_name="Recoverable oil"),
 Template(petrel_name="Well Index"),
 Template(petrel_name="Conductivity, medium"),
 Template(petrel_name="Bottom hole pressure"),
 Template(petrel_name="Solid phase thermal conductivity"),
 Template(petrel_name="Plug back tot. depth"),
 Template(petrel_name="HCPV oil"),
 Template(petrel_name="Permeability I"),
 Template(petrel_name="Gas viscosity"),
 Template(petrel_name="SEI2"),
 Template(petrel_name="Permeability Y"),
 Template(petrel_name="Holdup (volume %)"),
 Template(petrel_name="Coal gas concentration"),
 Template(petrel_name="Fracture compressibility"),
 Template(petrel_name="Inside diameter"),
 Template(petrel_name="Treating pressure"),
 Template(petrel_name="Proppant"),
 Template(petrel_name="Oil-gas ratio"),
 Template(petrel_name="Permeability YZ"),
 Template(petrel_name="Depth seabed"),
 Template(petrel_name="Deepening"),
 Template(petrel_name="Oil mass production rate"),
 Template(petrel_name="Distance"),
 Template(petrel_name="Liquid production rate"),
 Template(petrel_name="Downhole torque"),
 Template(petrel_name="Gas content"),
 Template(petrel_name="Carbon dioxide rate"),
 Template(petrel_name="Erosion rate"),
 Template(petrel_name="Absolute temperature"),
 Template(petrel_name="Specific heat capacity per temperature"),
 Template(petrel_name="Happy day"),
 Template(petrel_name="Cone resistance"),
 Template(petrel_name="Water mass production rate"),
 Template(petrel_name="Permeability JK"),
 Template(petrel_name="Gas velocity"),
 Template(petrel_name="Poissons ratio"),
 Template(petrel_name="Pressure gradient as mud density"),
 Template(petrel_name="Oil heat capacity"),
 Template(petrel_name="Differential temperature"),
 Template(petrel_name="Volume Rendering"),
 Template(petrel_name="History match quantitative"),
 Template(petrel_name="Molar volume"),
 Template(petrel_name="Duration"),
 Template(petrel_name="Net cone resistance"),
 Template(petrel_name="Oil fluid-in-place"),
 Template(petrel_name="Pressure"),
 Template(petrel_name="Wavelet"),
 Template(petrel_name="S-impedance"),
 Template(petrel_name="HCPV oil (map)"),
 Template(petrel_name="Mu"),
 Template(petrel_name="Fault permeability"),
 Template(petrel_name="Standpipe pressure"),
 Template(petrel_name="Dogleg severity"),
 Template(petrel_name="Heat transmissibility K"),
 Template(petrel_name="Average velocity"),
 Template(petrel_name="Two-way time"),
 Template(petrel_name="Seismic - Ant tracking"),
 Template(petrel_name="Permeability-length"),
 Template(petrel_name="Oil phase thermal conductivity"),
 Template(petrel_name="Seismic - Variance"),
 Template(petrel_name="Sonic"),
 Template(petrel_name="Seismic - Contrast"),
 Template(petrel_name="Recoverable gas (map)"),
 Template(petrel_name="Gas injection rate"),
 Template(petrel_name="Oil flow rate"),
 Template(petrel_name="Velocity"),
 Template(petrel_name="Water heat capacity"),
 Template(petrel_name="Vapourized oil-gas ratio"),
 Template(petrel_name="Dip quality"),
 Template(petrel_name="Lambda*Rho"),
 Template(petrel_name="Seismic - Dip error"),
 Template(petrel_name="Reservoir mass density"),
 Template(petrel_name="SEI1"),
 Template(petrel_name="Residual"),
 Template(petrel_name="Conductivity, shallow"),
 Template(petrel_name="EI3"),
 Template(petrel_name="Photoelectric factor"),
 Template(petrel_name="Rock heat capacity temp. coefficient"),
 Template(petrel_name="Thickness time")]
You can now use list slicing to assign one of the templates to a variable:

selected_template = templates_list[0]
selected_template
Template(petrel_name="Seismic - Phase")
Or you can access a specific template using it’s path:

P_velocity=petrel.templates['Templates/Geophysical templates/P-velocity']
P_velocity
Template(petrel_name="P-velocity")
The path of a template can be obtain using the .path property:

selected_template.path
'Templates/Seismic templates/Seismic - Phase'
Similarly, you can retrieve its name using the .petrel_name property:

selected_template.petrel_name
'Seismic - Phase'
The .droid property will return the GUID of the template:

selected_template.droid
'000000af-0000-0000-0000-000000000000'
The .unit_symbol property the unit used by the template. In Petrel you can access this data by propping up the settings for the selected template:

unit.png
selected_template.unit_symbol
'deg'
We can use the .get_template() function to retrieve the template of differnt domain objects. In the example bellow we are retrieving the global sonic log and then return the template associated to this log:

GWL=[el for el in petrel.global_well_logs if el.petrel_name=='DT']
GWL[0]
GlobalWellLog(petrel_name="DT")
GWL[0].get_template()
Template(petrel_name="P-sonic")
You can now also pass a template when cloning an object. If a template argument is provided, the clone will get the default color table of the given template. If a template argument is not provided, the clone will have the same template and color table as the source object.

Note that providing a template when cloning is only possible if the copy_values flag is set to False.

In the example below we are cloning the P-sonic global well log and assigning it the S-Sonic template:

S_sonic_template=[tl for tl in petrel.templates if tl.petrel_name=='S-sonic']
S_sonic_template
[Template(petrel_name="S-sonic")]
GWL[0].clone('S-sonic',copy_values=False,template=S_sonic_template[0])
GlobalWellLog(petrel_name="S-sonic")
To change the template of an existing object we need to make use of a petrel workflow. The workflow is simple and has only one step: Set Template. Form more information regarding the use of workflows please see this userguide.

workflows.png
TL_workflow=petrel.workflows['Workflows/set_template']
The workflow makes use of two input variables: one for the input object (the object we’ll change the template for) and one for the template which will be assigned to it:

input.png
workflow_tl_input = TL_workflow.input['input_object']
workflow_tl_template = TL_workflow.input['New Template']
Let’s change the template of an existing seismic cube. We’ll retrieve a seismic cube and change it’s template from Seismic (default) to *Red(-) White Black(+):

SeismicCube= petrel.seismic_cubes['Input/Seismic/Seismic Data/Demo_Cube']
NewSeismicTemplate=[tl for tl in petrel.templates if tl.petrel_name=='Red(-) White Black(+)']
The next cell will execute the workflow in Petrel and change the template of the selected Seismic Cube:

change_template.png
output_dict = TL_workflow.run(args={workflow_tl_input : SeismicCube,
                                              workflow_tl_template : NewSeismicTemplate[0]})
Discrete Templates
Check out the API documentation to view a detailed description of all the functions and properties available for working with discrete templates.

Using the .discrete_templates property, we can save all the discrete templates to a dictionary where the keys represent the path of the template within the Petrel project and the value represents the name of the template .

petrel.discrete_templates
DiscreteTemplates({"Templates/Discrete property templates/Segments from 'Struct Frame 5/3D grid'": DiscreteTemplate(petrel_name="Segments from 'Struct Frame 5/3D grid'"), 'Templates/Discrete property templates/Boolean': DiscreteTemplate(petrel_name="Boolean"), 'Templates/Discrete property templates/Dip classification': DiscreteTemplate(petrel_name="Dip classification"), 'Templates/Discrete property templates/Legacy time stratigraphy': DiscreteTemplate(petrel_name="Legacy time stratigraphy"), "Templates/Discrete property templates/Zones from 'Gullfaks2004/Gullfaks Final (DC)'": DiscreteTemplate(petrel_name="Zones from 'Gullfaks2004/Gullfaks Final (DC)'"), 'Templates/Discrete property templates/Zones (hierarchy)': DiscreteTemplate(petrel_name="Zones (hierarchy)"), 'Templates/Discrete well log templates/Producer status': DiscreteTemplate(petrel_name="Producer status"), 'Templates/Discrete property templates/Depositional trend': DiscreteTemplate(petrel_name="Depositional trend"), 'Templates/Discrete property templates/System track': DiscreteTemplate(petrel_name="System track"), 'Templates/Discrete other templates/Hole classification for polygons': DiscreteTemplate(petrel_name="Hole classification for polygons"), 'Templates/Discrete property templates/Strings': DiscreteTemplate(petrel_name="Strings"), 'Templates/Discrete property templates/General discrete': DiscreteTemplate(petrel_name="General discrete"), 'Templates/Discrete fracture property templates/Fracture type': DiscreteTemplate(petrel_name="Fracture type"), 'Templates/Discrete fracture property templates/Fracture set': DiscreteTemplate(petrel_name="Fracture set"), 'Templates/Discrete property templates/Zones': DiscreteTemplate(petrel_name="Zones"), 'Templates/Discrete other templates/Activity code': DiscreteTemplate(petrel_name="Activity code"), 'Templates/Discrete well log templates/Sliding sleeve positions': DiscreteTemplate(petrel_name="Sliding sleeve positions"), "Templates/Discrete property templates/Zones from 'Gullfaks2003SE/Gullfaks (Make Horizon) (DC)'": DiscreteTemplate(petrel_name="Zones from 'Gullfaks2003SE/Gullfaks (Make Horizon) (DC)'"), 'Templates/Discrete property templates/Horizons': DiscreteTemplate(petrel_name="Horizons"), 'Templates/Discrete property templates/Well Index': DiscreteTemplate(petrel_name="Well Index"), 'Templates/Discrete property templates/Lithologies': DiscreteTemplate(petrel_name="Lithologies"), 'Templates/Discrete property templates/Faults': DiscreteTemplate(petrel_name="Faults"), 'Templates/Discrete property templates/Fluvial facies': DiscreteTemplate(petrel_name="Fluvial facies"), 'Templates/Discrete well log templates/Perforation': DiscreteTemplate(petrel_name="Perforation"), 'Templates/Discrete property templates/Connected volumes': DiscreteTemplate(petrel_name="Connected volumes"), 'Templates/Discrete property templates/Grain size trend': DiscreteTemplate(petrel_name="Grain size trend"), "Templates/Discrete property templates/Zone log from 'Reservoir Demo'": DiscreteTemplate(petrel_name="Zone log from 'Reservoir Demo'"), 'Templates/Discrete property templates/Segments': DiscreteTemplate(petrel_name="Segments"), 'Templates/Discrete property templates/Quality': DiscreteTemplate(petrel_name="Quality"), 'Templates/Discrete property templates/Region': DiscreteTemplate(petrel_name="Region"), 'Templates/Discrete property templates/Layers': DiscreteTemplate(petrel_name="Layers"), 'Templates/Discrete property templates/Time stratigraphy': DiscreteTemplate(petrel_name="Time stratigraphy"), 'Templates/Discrete property templates/IJK Segments': DiscreteTemplate(petrel_name="IJK Segments"), 'Templates/Discrete property templates/Main zones': DiscreteTemplate(petrel_name="Main zones"), 'Templates/Discrete well log templates/Completion string': DiscreteTemplate(petrel_name="Completion string"), 'Templates/Discrete well log templates/Lined': DiscreteTemplate(petrel_name="Lined"), 'Templates/Discrete property templates/Aggradation trend': DiscreteTemplate(petrel_name="Aggradation trend"), 'Templates/Discrete property templates/Bodies': DiscreteTemplate(petrel_name="Bodies"), 'Templates/Discrete property templates/Cell activity': DiscreteTemplate(petrel_name="Cell activity"), 'Templates/Discrete property templates/IJK layers': DiscreteTemplate(petrel_name="IJK layers"), 'Templates/Discrete well log templates/Cased': DiscreteTemplate(petrel_name="Cased"), 'Templates/Discrete other templates/History match qualitative fine': DiscreteTemplate(petrel_name="History match qualitative fine"), 'Templates/Discrete property templates/Facies': DiscreteTemplate(petrel_name="Facies"), "Templates/Discrete property templates/Zone log from 'Reservoir'": DiscreteTemplate(petrel_name="Zone log from 'Reservoir'"), 'Templates/Discrete property templates/Fluids': DiscreteTemplate(petrel_name="Fluids"), 'Templates/Discrete other templates/Status': DiscreteTemplate(petrel_name="Status"), 'Templates/Discrete property templates/Horizon filter attribute': DiscreteTemplate(petrel_name="Horizon filter attribute"), 'Templates/Discrete other templates/History match qualitative coarse': DiscreteTemplate(petrel_name="History match qualitative coarse")})
Using list comprehension, the discrete templates can be viewed as a list:

discrete_templates_list= [tl for tl in petrel.discrete_templates]
discrete_templates_list
[DiscreteTemplate(petrel_name="System track"),
 DiscreteTemplate(petrel_name="Depositional trend"),
 DiscreteTemplate(petrel_name="Lithologies"),
 DiscreteTemplate(petrel_name="Fluvial facies"),
 DiscreteTemplate(petrel_name="Perforation"),
 DiscreteTemplate(petrel_name="Connected volumes"),
 DiscreteTemplate(petrel_name="Segments"),
 DiscreteTemplate(petrel_name="Segments from 'Struct Frame 5/3D grid'"),
 DiscreteTemplate(petrel_name="Zones from 'Gullfaks2003SE/Gullfaks (Make Horizon) (DC)'"),
 DiscreteTemplate(petrel_name="History match qualitative fine"),
 DiscreteTemplate(petrel_name="Lined"),
 DiscreteTemplate(petrel_name="Main zones"),
 DiscreteTemplate(petrel_name="Grain size trend"),
 DiscreteTemplate(petrel_name="Status"),
 DiscreteTemplate(petrel_name="IJK layers"),
 DiscreteTemplate(petrel_name="Layers"),
 DiscreteTemplate(petrel_name="Fracture type"),
 DiscreteTemplate(petrel_name="Zones"),
 DiscreteTemplate(petrel_name="Fracture set"),
 DiscreteTemplate(petrel_name="Horizon filter attribute"),
 DiscreteTemplate(petrel_name="Faults"),
 DiscreteTemplate(petrel_name="Time stratigraphy"),
 DiscreteTemplate(petrel_name="Zones from 'Gullfaks2004/Gullfaks Final (DC)'"),
 DiscreteTemplate(petrel_name="Region"),
 DiscreteTemplate(petrel_name="Sliding sleeve positions"),
 DiscreteTemplate(petrel_name="Strings"),
 DiscreteTemplate(petrel_name="Facies"),
 DiscreteTemplate(petrel_name="Dip classification"),
 DiscreteTemplate(petrel_name="History match qualitative coarse"),
 DiscreteTemplate(petrel_name="Zones (hierarchy)"),
 DiscreteTemplate(petrel_name="Producer status"),
 DiscreteTemplate(petrel_name="Hole classification for polygons"),
 DiscreteTemplate(petrel_name="Completion string"),
 DiscreteTemplate(petrel_name="Bodies"),
 DiscreteTemplate(petrel_name="Boolean"),
 DiscreteTemplate(petrel_name="General discrete"),
 DiscreteTemplate(petrel_name="Cell activity"),
 DiscreteTemplate(petrel_name="IJK Segments"),
 DiscreteTemplate(petrel_name="Aggradation trend"),
 DiscreteTemplate(petrel_name="Zone log from 'Reservoir Demo'"),
 DiscreteTemplate(petrel_name="Quality"),
 DiscreteTemplate(petrel_name="Zone log from 'Reservoir'"),
 DiscreteTemplate(petrel_name="Cased"),
 DiscreteTemplate(petrel_name="Activity code"),
 DiscreteTemplate(petrel_name="Legacy time stratigraphy"),
 DiscreteTemplate(petrel_name="Horizons"),
 DiscreteTemplate(petrel_name="Well Index"),
 DiscreteTemplate(petrel_name="Fluids")]
Lets assign the Facies template to a variable:

Facies=petrel.discrete_templates['Templates/Discrete property templates/Facies']
Facies
DiscreteTemplate(petrel_name="Facies")
You can access the discrete codes associated to a discrete template using the .discrete_codes property:

Facies.discrete_codes
{0: 'Blocky', 1: 'Coarsening upwards', 2: 'Fining upwards'}
=====
Folders
Note: Support for working with Folders was introduced in Python Tool Pro 2.8.

This guide explains how to access, create, modify and delete Folders with Python Tool Pro. Check out the API documentation to view a detailed description of all the functions and properties available for working with folders.

foldertype.png
Connect to a Petrel project
from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()
Accessing Folders
You can access all available folders in the project using the .folders property on the Petrel connection. The keys of the dictionary represents the path to the folder in the Petrel input tree and the value represents the folder object.

petrel.folders
Folders({'Input/Objects': Folder(petrel_name="Objects"), 'Input/surfaces': Folder(petrel_name="surfaces"), 'Input/surfaces/surfaces (Depth)': Folder(petrel_name="surfaces (Depth)"), 'Input/surfaces/Surfaces (Time)': Folder(petrel_name="Surfaces (Time)"), 'Input/Boundaries': Folder(petrel_name="Boundaries"), 'Input/wavelets': Folder(petrel_name="wavelets"), 'Input/Polygons and Pointsets': Folder(petrel_name="Polygons and Pointsets")})
folderTree.png
Alternatively, you can get a list of all Folder objects using a list comprehension:

folder_list = [i for i in petrel.folders]
folder_list
[Folder(petrel_name="Objects"),
 Folder(petrel_name="surfaces"),
 Folder(petrel_name="surfaces (Depth)"),
 Folder(petrel_name="Surfaces (Time)"),
 Folder(petrel_name="Boundaries"),
 Folder(petrel_name="wavelets"),
 Folder(petrel_name="Polygons and Pointsets")]
To get a specific folder, you can either use the .folders property with the full Petrel path or use the new .get_by_name() function:

object_folder = petrel.folders['Input/Objects']
#or
object_folder = petrel.folders.get_by_name('Objects')
object_folder
Folder(petrel_name="Objects")
Folder properties
The .petrel_name property returns the name of the Folder as shown in Petrel.

object_folder.petrel_name
'Objects'
The .path property returns the path of the folder in the Petrel input tree.

object_folder.path
'Input/Objects'
The .readonly property indicates whether the folder is read-only; set it to False to enable editing.

object_folder.readonly
True
The .parent_folder property returns the parent folder of the selected folder. It returns None if the object is the Input root.

object_folder.parent_folder
The .droid property returns the Petrel Droid (unique object ID or GUID).

object_folder.droid
'709e7437-9c1f-4530-a4ab-33fecfbb980f'
The .comments property returns any comments on the Folder as a string (or an empty string if none).

object_folder.comments
''
Folder functions
The .add_comment() method adds a comment to the folders’s existing comments or replaces them. Use add_comment("Comment text", overwrite=False) to append, or set overwrite=True to replace all existing comments.

# set the readonly status to false so the folder can be edited
object_folder.readonly = False
# Add a comment
object_folder.add_comment('Comment added by Python Tool Pro',overwrite=False)
# Returns the added comment
object_folder.comments
'Comment added by Python Tool Pro'
The .set_petrel_name() method sets or changes the name of this folder in Petrel.

# set the readonly status to false so the folder can be edited
object_folder.readonly = False
# change the folder name from 'Objects' to 'Objects folder'
object_folder.set_petrel_name('Objects folder')
object_folder.petrel_name
'Objects folder'
Create a new folder
You can create a subfolder inside an existing folder using the .create_folder() function.

# set the readonly status to false so the folder can be edited
object_folder.readonly = False

# Create a subfolder within the selected folder
subfolder = object_folder.create_folder("New subfolder")

print(f"Created folder '{subfolder.petrel_name}' inside '{subfolder.parent_folder.petrel_name}'")
Created folder 'New subfolder' inside 'Objects folder'
subfolder.png
You can also create a top-level folder directly under the Input tree root using the PetrelConnection.create_folder() function.

root_level_folder = petrel.create_folder('New Root Level Folder')
root_level_folder.petrel_name
'New Root Level Folder'
rootlevel.png
The create API has been updated so you can now optionally specify a target folder when creating new domain objects. This allows you to control exactly where the new object will be placed in the Petrel Input Tree, rather than relying on the default root-level location.

petrel.create_pointset('New_PointSet', folder = subfolder)
petrel.create_polylineset('New_PolylineSet',folder = subfolder)
petrel.create_markercollection('New_WellTops',folder = subfolder)
MarkerCollection(petrel_name="New_WellTops")
new_objs.png
Retrieve objects from folders
You can retrieve all objects in a folder using the get_objects() function:

object_folder.get_objects()
[Folder(petrel_name="New subfolder"),
 PointSet(petrel_name="Points 1"),
 PolylineSet(petrel_name="Polygons"),
 Surface(petrel_name="Seabed"),
 Wavelet(petrel_name="Ricker 1")]
To retrieve all objects recursively, including those located in any subfolders, set the recursive flag to True:

object_folder.get_objects(recursive=True)
[Folder(petrel_name="New subfolder"),
 PointSet(petrel_name="Points 1"),
 PolylineSet(petrel_name="Polygons"),
 Surface(petrel_name="Seabed"),
 Wavelet(petrel_name="Ricker 1"),
 MarkerCollection(petrel_name="New_WellTops"),
 PointSet(petrel_name="New_PointSet"),
 PolylineSet(petrel_name="New_PolylineSet")]
You can also filter by specific object types using either the FolderObjectTypeEnum or string type names. For example, to retrieve only PointSet and Surface objects:

from cegalprizm.pythontool import FolderObjectTypeEnum
object_folder.get_objects(recursive=True,object_types=[FolderObjectTypeEnum.PointSet,FolderObjectTypeEnum.Surface])
[PointSet(petrel_name="Points 1"),
 Surface(petrel_name="Seabed"),
 PointSet(petrel_name="New_PointSet")]
You can achieve the same using string inputs:

object_folder.get_objects(recursive=True,object_types=['Wavelet','PolylineSet'])
[PolylineSet(petrel_name="Polygons"),
 Wavelet(petrel_name="Ricker 1"),
 PolylineSet(petrel_name="New_PolylineSet")]
Move folders
You can move a folder to a different one using the move() function. Before moving, ensure that the folder is not readonly.

# set the readonly status to false so the folder can be moved
root_level_folder.readonly = False

# Move folder
root_level_folder.move(object_folder)
moveF.png
Delete folder
You can delete a Petrel object using the delete() function. Before deleting, you must explicitly enable deletion on the PetrelConnection by setting allow_deletion=True. In addition, the folder must not be readonly.

# set allow_deletion flag to True
from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection(allow_deletion=True)

# set readonly status to False
root_level_folder.readonly=False

# delete folder
root_level_folder.delete()
A deleted object becomes a _DeletedPetrelObject proxy, and any further attempts to access its properties or methods will raise exceptions.

root_level_folder
<Deleted <class 'cegalprizm.pythontool.folder.Folder'>>
Deleting a Folder will also delete all objects contained inside it, including any subfolders and their contents.

subfolder.readonly = False
# Delete a folder with multiple objects inside
subfolder.delete()
deletedfolders.png
You can also delete multiple Petrel folders at once using the delete() function on the PetrelConnection.

petrel = PetrelConnection(allow_deletion=True)

folder1.readonly = False
folder2.readonly = False

# Delete multiple folders in one call
petrel.delete([folder1, folder2])
=====
Global Well Logs Folders
Note: Support for working with Global Well Logs Folders was introduced in Python Tool Pro 2.8.

This guide explains how to access, create, and modify Global Well Logs Folders with Python Tool Pro. Check out the API documentation to view a detailed description of all the functions and properties available for working with Global Well Logs Folders.

GWLtype.png
Connect to a Petrel project
from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()
Accessing Global Well Logs (GWL) Folders
You can access all available GWL folders in the project using the .global_well_log_folders property on the Petrel connection. The keys of the dictionary represents the path to the folder in the Petrel input tree and the value represents the GWL folder object.

petrel.global_well_log_folders
GlobalWellLogFolders({'Input/Wells/Global well logs/COMPOSITE': GlobalWellLogFolder("COMPOSITE"), 'Input/Wells/Global well logs/CPI': GlobalWellLogFolder("CPI"), 'Input/Wells/Global well logs/FACIES': GlobalWellLogFolder("FACIES"), 'Input/Wells/Global well logs/ZONELOG': GlobalWellLogFolder("ZONELOG"), 'Input/Wells/Global well logs/CORE': GlobalWellLogFolder("CORE"), 'Input/Wells/Global well logs/PRESSURE': GlobalWellLogFolder("PRESSURE"), 'Input/Wells/Global well logs': GlobalWellLogFolder("Global well logs")})
GWLlist.png
Alternatively, you can get a list of all GlobalWellLogFolder objects using a list comprehension:

GWL_folder_list = [i for i in petrel.global_well_log_folders]
GWL_folder_list
[GlobalWellLogFolder("COMPOSITE"),
 GlobalWellLogFolder("CPI"),
 GlobalWellLogFolder("FACIES"),
 GlobalWellLogFolder("ZONELOG"),
 GlobalWellLogFolder("CORE"),
 GlobalWellLogFolder("PRESSURE"),
 GlobalWellLogFolder("Global well logs")]
To get a specific folder, you can either use the .global_well_log_folders property with the full Petrel path or use the new ``.get_by_name()`` function:

composite_folder = petrel.global_well_log_folders['Input/Wells/Global well logs/COMPOSITE']
#or
composite_folder = petrel.global_well_log_folders.get_by_name('COMPOSITE')
composite_folder
GlobalWellLogFolder("COMPOSITE")
GWL Folders properties
The .petrel_name property returns the name of the GWL Folder as shown in Petrel.

composite_folder.petrel_name
'COMPOSITE'
The .path property returns the path of the GWL Folder in the Petrel input tree.

composite_folder.path
'Input/Wells/Global well logs/COMPOSITE'
The .readonly property indicates whether the GWL folder is read-only; set it to False to enable editing.

composite_folder.readonly
True
The .parent_folder property returns the parent GWL folder of the selected folder. It returns None if the object is the Input root.

composite_folder.parent_folder
GlobalWellLogFolder("Global well logs")
The .droid property returns the Petrel Droid (unique object ID or GUID).

composite_folder.droid
'5fd695f9-3b92-428f-a7b5-38930d2a77ad'
The .comments property returns any comments on the Folder as a string (or an empty string if none).

composite_folder.comments
''
GWL Folders functions
The .add_comment() method adds a comment to the GWL folders’s existing comments or replaces them. Use add_comment("Comment text", overwrite=False) to append, or set overwrite=True to replace all existing comments.

# set the readonly status to false so the GWL folder can be edited
composite_folder.readonly = False
# Add a comment
composite_folder.add_comment('Comment added by Python Tool Pro',overwrite=False)
# Returns the added comment
composite_folder.comments
'Comment added by Python Tool Pro'
The .set_petrel_name() method sets or changes the name of this folder in Petrel.

# set the readonly status to false so the GWL folder can be edited
composite_folder.readonly = False
# change the folder name from 'COMPOSITE' to 'COMPOSITE PTP'
composite_folder.set_petrel_name('COMPOSITE PTP')
composite_folder.petrel_name
'COMPOSITE PTP'
Create a new folder
You can create a subfolder inside an existing GWL folder using the .create_global_well_log_folder() function.

# set the readonly status to false so the GWL folder can be edited
composite_folder.readonly = False

# Create a subfolder within the selected GWL folder
GWL_subfolder = composite_folder.create_global_well_log_folder("New subfolder")

print(f"Created folder '{GWL_subfolder.petrel_name}' inside '{GWL_subfolder.parent_folder.petrel_name}'")
Created folder 'New subfolder' inside 'COMPOSITE'
GWLsubfolder.png
You can create a GWL log directly on a folder using the .create_global_well_log() function.

# set the readonly status to false so the GWL folder can be edited
GWL_subfolder.readonly = False

# get the porosity template
por = petrel.templates.get_by_name("Porosity")

por_GWL = GWL_subfolder.create_global_well_log('Por',template=por)
print(f"Created GWL '{por_GWL.petrel_name}' inside '{por_GWL.parent_folder.petrel_name}'")
Created GWL 'Por' inside 'New subfolder'
You can now optionally specify a target GWL folder when creating a new GWL log.

# set the readonly status to false so the GWL folder can be edited
GWL_subfolder.readonly = False

# create 2 new GWL logs in the GWL subfolder
petrel.create_global_well_log('New Log', folder=GWL_subfolder)
petrel.create_global_well_log('New Disc Log',data_type='discrete', folder=GWL_subfolder)
DiscreteGlobalWellLog(petrel_name="New Disc Log")
GWLLogs.png
Retrieve objects from folders
You can retrieve all objects in a GWL folder using the get_logs() function:

composite_folder.get_logs()
[DiscreteGlobalWellLog(petrel_name="Lithofacies"),
 GlobalWellLog(petrel_name="NPHI"),
 GlobalWellLog(petrel_name="RHOB"),
 GlobalWellLog(petrel_name="VP"),
 GlobalWellLog(petrel_name="VS"),
 GlobalWellLog(petrel_name="VSH"),
 GlobalWellLog(petrel_name="PHIE"),
 GlobalWellLog(petrel_name="Perm"),
 GlobalWellLog(petrel_name="NetGross"),
 GlobalWellLog(petrel_name="DRHO_L"),
 GlobalWellLog(petrel_name="Porosity"),
 GlobalWellLog(petrel_name="RD_L"),
 GlobalWellLog(petrel_name="RHOB_L"),
 GlobalWellLog(petrel_name="RT_L")]
To retrieve all objects recursively, including those located in any subfolders, set the recursive flag to True:

composite_folder.get_logs(recursive=True)
[DiscreteGlobalWellLog(petrel_name="Lithofacies"),
 GlobalWellLog(petrel_name="NPHI"),
 GlobalWellLog(petrel_name="RHOB"),
 GlobalWellLog(petrel_name="VP"),
 GlobalWellLog(petrel_name="VS"),
 GlobalWellLog(petrel_name="VSH"),
 GlobalWellLog(petrel_name="PHIE"),
 GlobalWellLog(petrel_name="Perm"),
 GlobalWellLog(petrel_name="NetGross"),
 GlobalWellLog(petrel_name="DRHO_L"),
 GlobalWellLog(petrel_name="Porosity"),
 GlobalWellLog(petrel_name="RD_L"),
 GlobalWellLog(petrel_name="RHOB_L"),
 GlobalWellLog(petrel_name="RT_L"),
 DiscreteGlobalWellLog(petrel_name="New Disc Log"),
 GlobalWellLog(petrel_name="New Log")]
You can also filter by specific object types using either the NumericDataTypeEnum or string type names.

from cegalprizm.pythontool import NumericDataTypeEnum
composite_folder.get_logs(recursive=True, data_type=NumericDataTypeEnum.Continuous)
[GlobalWellLog(petrel_name="NPHI"),
 GlobalWellLog(petrel_name="RHOB"),
 GlobalWellLog(petrel_name="VP"),
 GlobalWellLog(petrel_name="VS"),
 GlobalWellLog(petrel_name="VSH"),
 GlobalWellLog(petrel_name="PHIE"),
 GlobalWellLog(petrel_name="Perm"),
 GlobalWellLog(petrel_name="NetGross"),
 GlobalWellLog(petrel_name="DRHO_L"),
 GlobalWellLog(petrel_name="Porosity"),
 GlobalWellLog(petrel_name="RD_L"),
 GlobalWellLog(petrel_name="RHOB_L"),
 GlobalWellLog(petrel_name="RT_L"),
 GlobalWellLog(petrel_name="New Log")]
You can achieve the same using string inputs:

composite_folder.get_logs(recursive=True, data_type='discrete')
[DiscreteGlobalWellLog(petrel_name="Lithofacies"),
 DiscreteGlobalWellLog(petrel_name="New Disc Log")]
=========
Property Folders
Note: Support for working with Property Folders was introduced in Python Tool Pro 2.8.

This guide explains how to access, create, and modify Property Folders with Python Tool Pro. Check out the API documentation to view a detailed description of all the functions and properties available for working with Property Folders.

propf_type.png
Connect to a Petrel project
from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection()
Accessing Property Folders
You can access all available property folders in the project using the .grid_property_folders property on the Petrel connection. The keys of the dictionary represents the path to the property folder in the Petrel input tree and the value represents the property folder object.

petrel.grid_property_folders
PropertyFolders({'Models/GEO grid from SF/GEO Grid/Properties/Prop': PropertyFolder(petrel_name="Prop"), 'Models/GEO grid from SF/GEO Grid/Properties/Stochastic': PropertyFolder(petrel_name="Stochastic"), 'Models/GEO grid from SF/GEO Grid/Properties': PropertyFolder(petrel_name="Properties"), 'Models/GEO grid from SF/GEO Grid/Properties/Geometrical': PropertyFolder(petrel_name="Geometrical"), 'Models/GEO grid from SF/GEO Grid/Properties/Facies': PropertyFolder(petrel_name="Facies")})
propf_list.png
Alternatively, you can get a list of all PropertyFolder objects using a list comprehension:

property_folder_list = [i for i in petrel.grid_property_folders]
property_folder_list
[PropertyFolder(petrel_name="Prop"),
 PropertyFolder(petrel_name="Stochastic"),
 PropertyFolder(petrel_name="Properties"),
 PropertyFolder(petrel_name="Geometrical"),
 PropertyFolder(petrel_name="Facies")]
To get a specific property folder, you can either use the .grid_property_folders property with the full Petrel path or use the new ``.get_by_name()`` function:

prop_folder = petrel.grid_property_folders['Models/GEO grid from SF/GEO Grid/Properties/Prop']
#or
prop_folder = petrel.grid_property_folders.get_by_name('Prop')
prop_folder
PropertyFolder(petrel_name="Prop")
In addition to retrieving property folders from the Petrel connection, you can also access them directly from a specific Grid object.

Every grid has a root-level Properties folder, accessible through the .``property_folder`` property:

propfprop.png
grid = petrel.grids.get_by_name("GEO Grid")
properties_root = grid.property_folder
properties_root
PropertyFolder(petrel_name="Properties")
This root-level folder behaves like any other property folder and exposes its own ``property_folders`` property, which returns all child property folders inside it:

properties_root.property_folders
PropertyFolders(property folder="PropertyFolder(petrel_name="Properties")")
You can iterate over them just like any other collections:

[el for el in properties_root.property_folders]
[PropertyFolder(petrel_name="Geometrical"),
 PropertyFolder(petrel_name="Facies"),
 PropertyFolder(petrel_name="Prop"),
 PropertyFolder(petrel_name="Stochastic")]
prop_folder = properties_root.property_folders['Prop']
prop_folder
PropertyFolder(petrel_name="Prop")
Property Folders properties
The .petrel_name property returns the name of the Property Folder as shown in Petrel.

prop_folder.petrel_name
'Prop'
The .path property returns the path of the Property Folder in the Petrel input tree.

prop_folder.path
The .readonly property indicates whether the Property folder is read-only; set it to False to enable editing.

prop_folder.readonly
The .parent_folder property returns the parent Property folder of the selected folder. It returns None if the object is the Models root.

prop_folder.parent_folder
PropertyFolder(petrel_name="Properties")
The .droid property returns the Petrel Droid (unique object ID or GUID).

prop_folder.droid
The .comments property returns any comments on the Property Folder as a string (or an empty string if none).

prop_folder.comments
The .grid property returns the parent grid of the property folder.

prop_folder.grid
Grid(petrel_name="GEO Grid")
The .properties property returns a collection of all the properties in the property folder.

prop_folder.properties
GridProperties(property folder="PropertyFolder(petrel_name="Prop")")
list(prop_folder.properties)
[GridProperty(petrel_name="NetGross (fluvial)"),
 GridProperty(petrel_name="Perm"),
 GridProperty(petrel_name="Porosity"),
 GridProperty(petrel_name="Sw"),
 GridDiscreteProperty(petrel_name="Facies")]
Property Folders properties
The .add_comment() method adds a comment to the Property folders’s existing comments or replaces them. Use add_comment("Comment text", overwrite=False) to append, or set overwrite=True to replace all existing comments.

# set the readonly status to false so the Property folder can be edited
prop_folder.readonly = False
# Add a comment
prop_folder.add_comment('Comment added by Python Tool Pro',overwrite=False)
# Returns the added comment
prop_folder.comments
'Comment added by Python Tool Pro'
The .set_petrel_name() method sets or changes the name of this folder in Petrel.

# set the readonly status to false so the property folder can be edited
prop_folder.readonly = False
# change the folder name from 'Prop' to 'Modeled properties'
prop_folder.set_petrel_name('Modeled properties')
prop_folder.petrel_name
'Modeled properties'
Create a new folder
You can create a subfolder inside an existing property folder using the ``.create_property_folder()`` function.

# set the readonly status to false so the property folder can be edited
prop_folder.readonly = False

# Create a subfolder within the selected property folder
prop_subfolder = prop_folder.create_property_folder("New subfolder")

print(f"Created folder '{prop_subfolder.petrel_name}' inside '{prop_subfolder.parent_folder.petrel_name}'")
Created folder 'New subfolder' inside 'Modeled properties'
propf_subfolder.png
To create a new folder under the grid’s root Properties folder, first access the grid, retrieve its root property folder, and then call ``.create_property_folder()`` on it:

grid = petrel.grids.get_by_name("GEO Grid")
properties_root = grid.property_folder
properties_root.readonly = False

new_root_folder = properties_root.create_property_folder("New root subfolder")
new_root_folder
PropertyFolder(petrel_name="New root subfolder")
propf_subfolder.png
You can create a property directly on a folder using the .create_property() function.

# set the readonly status to false so the property folder can be edited
prop_subfolder.readonly = False

# create a new continuous property
prop_subfolder.create_property("New continuous")

# create a new discrete property
prop_subfolder.create_property("New discrete", data_type='discrete')

# create a new property with NPHI template
nphi_template = petrel.templates.get_by_name("Neutron")
prop_subfolder.create_property("New NPHI", template=nphi_template)
GridProperty(petrel_name="New NPHI")
propf_createprop.png
Retrieve properties from folders
You can retrieve all objects in a property folder using the ``.get_properties()`` function:

prop_folder.get_properties()
[GridProperty(petrel_name="NetGross (fluvial)"),
 GridProperty(petrel_name="Perm"),
 GridProperty(petrel_name="Porosity"),
 GridProperty(petrel_name="Sw"),
 GridDiscreteProperty(petrel_name="Facies")]
To retrieve all properties recursively, including those located in any subfolders, set the recursive flag to True:

prop_folder.get_properties(recursive=True)
[GridProperty(petrel_name="NetGross (fluvial)"),
 GridProperty(petrel_name="Perm"),
 GridProperty(petrel_name="Porosity"),
 GridProperty(petrel_name="Sw"),
 GridProperty(petrel_name="New continuous"),
 GridProperty(petrel_name="New NPHI"),
 GridDiscreteProperty(petrel_name="Facies"),
 GridDiscreteProperty(petrel_name="New discrete")]
You can also filter by specific properties types using either the NumericDataTypeEnum or string type names.

from cegalprizm.pythontool import NumericDataTypeEnum

prop_folder.get_properties(recursive=True, data_type=NumericDataTypeEnum.Continuous)
[GridProperty(petrel_name="NetGross (fluvial)"),
 GridProperty(petrel_name="Perm"),
 GridProperty(petrel_name="Porosity"),
 GridProperty(petrel_name="Sw"),
 GridProperty(petrel_name="New continuous"),
 GridProperty(petrel_name="New NPHI")]
You can achieve the same using string inputs:

prop_folder.get_properties(recursive=True, data_type='discrete')
[GridDiscreteProperty(petrel_name="Facies"),
 GridDiscreteProperty(petrel_name="New discrete")]
Delete folder
You can delete a Petrel object using the delete() function. Before deleting, you must explicitly enable deletion on the PetrelConnection by setting allow_deletion=True. In addition, the property folder must not be readonly.

# set allow_deletion flag to True
from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection(allow_deletion=True)

# set readonly status to False
new_root_folder.readonly=False

# delete folder
new_root_folder.delete()
A deleted object becomes a _DeletedPetrelObject proxy, and any further attempts to access its properties or methods will raise exceptions.

new_root_folder
<Deleted <class 'cegalprizm.pythontool.gridpropertycollection.PropertyFolder'>>
Deleting a Property Folder will also delete all properties contained inside it, including any subfolders and their contents.

prop_subfolder.readonly = False
# Delete a property folder with multiple properties inside
prop_subfolder.delete()
propf_delete.png
You can also delete multiple Petrel property folders at once using the delete() function on the PetrelConnection.

petrel = PetrelConnection(allow_deletion=True)

folder1.readonly = False
folder2.readonly = False

# Delete multiple property folders in one call
petrel.delete([folder1, folder2])
=====
Working with Chunks
Chunks are the only way of accessing the values of a gridded Petrel object such as a GridProperty, SurfaceAttribute etc.

Getting a chunk
Objects have methods which return different chunks of their values. For instance, the cegalprizm.pythontool.GridProperty class has the two methods cegalprizm.pythontool.GridProperty.column() and cegalprizm.pythontool.GridProperty.layer(), which retrieve a chunk for a particular column and a particular layer respectively.

Seismic objects can only generate column chunks (for efficiency); surface attributes can only generate all chunks (which are effectively the values of the single layer of the surface).

Grid property and seismic objects also allow you to retrieve a list of chunks, optionally specifying the range. This is useful when you want to work on an i-slice of a property for example, or just a set of layers. See the cegalprizm.pythontool.GridProperty.columns() method for details - this is available for layers as well in the case of grid properties.

Retrieving the values of a chunk
values as_array
There are two ways of retrieving the values of a chunk. The first and most straightforward is to use the cegalprizm.pythontool.Chunk.as_array() method. This returns a numpy.ndarray of values; if the chunk is of a continuous property they will be of type float. If discrete, they will be of type int.

The array returned will be 1-dimensional if the chunk is a column-chunk or two-dimensional if it’s a layer chunk. However, Python will allow you to iterate over the values without knowing the dimensionality:

# prints all the values in the layer
my_layer = my_prop.layer(5)
vals = my_layer.as_array()
for val in vals:
    print(val)
Enumeration
As the above example shows, although using as_array() is straightforward and the most performant option, you have to keep track of the indices of the value manually. The cegalprizm.pythontool.Chunk.enumerate() method gives values together with their indices. This example uses the Python technique called tuple-unpacking which allows you to assign multiple values in one go.

# prints all the values in the layer together with their indices
my_layer = my_prop.layer(5)
for (i, j, k, val) in my_layer.enumerate():
    print("[%d %d %d] => %f" % (i, j, k, val))
This will output something like (with made up values)

[0 0 0] => 0.001
[0 0 1] => 0.00121
...
[1 2 3] => 0.0093
[1 2 4] => 0.0033
..
This method is slower than using as_array() but can be much more convenient when developing an algorithm.

Setting the values of a chunk
When you retrieve the values from a Chunk, you are able to change them without consequence. The Petrel object’s values will not be affected until you call the cegalprizm.pythontool.Chunk.set() method of the chunk.

The set method is designed to be as convenient as possible, at the cost of some performance.

The most performant way of doing this is to pass in a System.Array (or numpy.ndarray in Python 3.6) of values, such as you might have retrieved from another chunk:

## assigns the values of layer k=1 to layers k=2 through 10
layerA = my_prop.layer(1)
layerA_values = layerA.as_array()
for layer in my_prop.layers(krange=[2, 3, 4, 5, 6, 7, 8, 9, 10]):
    layer.set(layerA_values)
As soon as you set the values for each layer, the Petrel object is updated. If the Petrel 3D window is displaying the property, you can see them update in real-time (be warned though that it is much slower when displaying the property in a 3D window as Petrel has to read and update the display for each layer). This can be very useful for debugging.

set also takes a list of values, as long as there are exactly the same number of values in the list as there needs to be in the chunk. For instance, if we wanted to clamp the values in a layer to a minimum of 0.1:

layer = my_prop.layer(1)
layer_values = layer.as_array()
# use a 'list-comprehension' to generate a Python list of values from the array
clamped = [0.1 if val < 0.1 else val for val in layer_values]
# pass the Python list to 'set'
layer.set(clamped)
(It is also valid to pass a list-of-lists, as long as the dimensions of the lists match up).

You can also set all of a chunk’s values to a single number:

# set all of a column to be 0
column = my_prop.column(2, 3)
column.set(0)
Finally, you can pass another Chunk and the values are transferred wholesale, as long as the chunks have the same size, orientation and ‘type’ (i.e., continuous or discrete):

# set layer k=1 to have the same values as a layer in another property
layer = my_prop.layer(1)
layer.set(my_other_prop.layer(10))
Chunk arithmetic
For chunks of continuous values, (i.e., not discrete properties or surface attributes) you can perform simple arithmetic using scalar values or other Chunk objects, as long as they are of compatible size and orientation. The resultant Chunk object is termed disconnected - it does not have a link to a Petrel object. You can however pass this Chunk to another connected chunk:

average_layer = (my_prop.layer(10) + my_prop.layer(11)) / 2
print(average_layer.disconnected) # outputs 'True'

my_prop.layer(12).set(average_layer)
The arithmetic operations work with Chunks both on the left-hand side or right-hand side:

layerA = my_prop.layer(10) + 2
layerB = 2 + my_prop.layer(10)
========
Wavelets , Point sets and Polylines sets
This Notebook provides examples on how to use Python Tool Pro to access Wavelets, Point sets and Polylines sets. This version includes editing of polyline sets which is only available in Cegal Prizm Python Tool Pro 2.5 or higher.

#connect to local petrel project

from cegalprizm.pythontool import PetrelConnection
ptp = PetrelConnection()
Wavelets
Check out the API documentation to view a detailed description of all the functions and properties available for working with wavelets.

Using the .wavelets property, we can save all the wavelets to a dictionary where the keys represent the path of the wavelet within the Petrel input tree (i.e, Input/Extended White 1) and the value represents the name of the wavelet (Wavelet(petrel_name=”Extended White 1”)). We can then save all the wavelet paths to a list :

#Save all the wavelets within the Petrel project in a dictionary
all_wavelets_dict = ptp.wavelets
#Save the keys(paths) of the wavelets to a dictionary
all_wavelets_paths = ptp.wavelets.keys()
#Save all the paths to a list
wav_paths = list(all_wavelets_paths)
print(wav_paths)
['Input/Gullfaks wavelets/Ricker 1', 'Input/Gullfaks wavelets/Extended White 1', 'Input/Gullfaks wavelets/ISIS (frequency) 1']
Using slicing, we can then assign the Extended White 1 wavelet to the mywavelet variable:

#Assign the first wavelet from the list to a variable and print it
mywavelet = ptp.wavelets[wav_paths[0]]
print(mywavelet)
Wavelet(petrel_name="Ricker 1")
Using the .as_dataframe() function, we can create a DataFrame that contains all the time[s] and the amplitude values:

mywaveletamplitudes=mywavelet.as_dataframe()
mywaveletamplitudes
position	amplitude
0	-0.064	0.0
1	-0.062	0.0
2	-0.060	0.0
3	-0.058	0.0
4	-0.056	0.0
...	...	...
60	0.056	0.0
61	0.058	0.0
62	0.060	0.0
63	0.062	0.0
64	0.064	0.0
65 rows × 2 columns

This DataFrame can also be visualised in Petrel by accessing the settings of the wavelet and viewing the values. Note that the .as_dataframe() function returns the time in seconds while in Petrel the time is measured in milliseconds:

wavelet_df.png
The .sample_count property retruns the number of samples (rows in the DataFrame) in the wavelet object:

mywavelet.sample_count
65
The .sampling_start property returns the first time value of the wavelet object as a float:

mywavelet.sampling_start
-0.064
The .sample_points property returns the time values of the wavelet object as a NumPy array:

mywavelet.sample_points
array([-0.064, -0.062, -0.06 , -0.058, -0.056, -0.054, -0.052, -0.05 ,
       -0.048, -0.046, -0.044, -0.042, -0.04 , -0.038, -0.036, -0.034,
       -0.032, -0.03 , -0.028, -0.026, -0.024, -0.022, -0.02 , -0.018,
       -0.016, -0.014, -0.012, -0.01 , -0.008, -0.006, -0.004, -0.002,
        0.   ,  0.002,  0.004,  0.006,  0.008,  0.01 ,  0.012,  0.014,
        0.016,  0.018,  0.02 ,  0.022,  0.024,  0.026,  0.028,  0.03 ,
        0.032,  0.034,  0.036,  0.038,  0.04 ,  0.042,  0.044,  0.046,
        0.048,  0.05 ,  0.052,  0.054,  0.056,  0.058,  0.06 ,  0.062,
        0.064])
The .amplitudes property returns the amplitudes of the wavelet object as a NumPy array:

mywavelet.amplitudes
array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
        0.        ,  0.        ,  0.        , -0.00227661, -0.00505651,
       -0.01061043, -0.02101134, -0.03921132, -0.06883918, -0.11342719,
       -0.17486049, -0.25109798, -0.33369079, -0.40619588, -0.44493452,
       -0.42327141, -0.31943996, -0.12611451,  0.1417942 ,  0.44517364,
        0.72717726,  0.9274826 ,  1.        ,  0.9274826 ,  0.72717726,
        0.44517364,  0.1417942 , -0.12611451, -0.31943996, -0.42327141,
       -0.44493452, -0.40619588, -0.33369079, -0.25109798, -0.17486049,
       -0.11342719, -0.06883918, -0.03921132, -0.02101134, -0.01061043,
       -0.00505651, -0.00227661,  0.        ,  0.        ,  0.        ,
        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])
With the release of Python Tool Pro 2.8 , a new domain property is now available for Wavelet objects and returns the domain of the object as a string (e.g., Elevation Time, Elevation Depth). If no domain is available, an empty string is returned.

mywavelet.domain
The .time_unit_symbol property returns the measurement that describes the wavelet datatype. This measurement is defined in the unit system in Petrel.

mywavelet.time_unit_symbol
'Short_Time'
In Petrel, the measurement type can be accessed and changed by navigating to the wavelet settings->global settings->Customize:

wavelet_unit.png
Working with pointsets
Check out the API documentation to view a detailed description of all the functions and properties available for working with pointsets.

The .pointsets property returns a dictionary where the keys represent the path of the pointset within the Petrel input tree and the value represents the name of the pointset.

ptp.pointsets
PointSets({'Input/Points 2': PointSet(petrel_name="Points 2"), 'Input/Points 3': PointSet(petrel_name="Points 3"), 'Input/New point set with template': PointSet(petrel_name="New point set with template"), 'Input/New point set': PointSet(petrel_name="New point set")})
We can save all the pointsets paths to a list and then use slicing to retrieve a specific pointset, which is then assigned to the mypointset variable:

all_pointsets_dict = ptp.pointsets
all_pointsets_paths = ptp.pointsets.keys()
paths = list(all_pointsets_paths)
mypointset = ptp.pointsets[paths[0]]
print(mypointset)
PointSet(petrel_name="Points 2")
The .as_dataframe() function returns a DataFrame of the selected pointset where each column of the DataFrame represents an attribute or point coordinate. The column names are the names of the attributes. If there are attributes with equal names, these attribute names are given a suffix with a number to make the column names unique.

mypointsetdf=mypointset.as_dataframe()
mypointsetdf
x	y	z	Z	xmas
0	536102.57	6793049.4	0.0	0.0	NaN
1	536103.57	6793049.4	0.0	0.0	NaN
2	536104.57	6793049.4	0.0	0.0	NaN
3	536105.57	6793049.4	0.0	0.0	NaN
4	536106.57	6793049.4	0.0	0.0	NaN
...	...	...	...	...	...
4992	536194.57	6793098.4	100.0	100.0	100.0
4993	536195.57	6793098.4	100.0	100.0	100.0
4994	536196.57	6793098.4	100.0	100.0	100.0
4995	536197.57	6793098.4	100.0	100.0	100.0
4996	536198.57	6793098.4	100.0	100.0	100.0
4997 rows × 5 columns

The .add_point() function adds a single point in displayed world coordinates to the pointset. The Point class can be imported from the cegalprizm.pythontool.primitives module. The point class parameters represent a point in space, according to the coordinate system in use. Then, we need to set the readonly status of the pointset to False so we can modify it:

from cegalprizm.pythontool import Point
mypointset.readonly=False
mypointset.add_point(Point(450000.0, 6780301.0, -1982.50))
Results are written back to Petrel in real time and can be checked by accessing the point spreadsheet for the selected pointset:

pointsetspreads.png
The .set_values() function allows us to create new attribute values which are written to Petrel. The data parameter must be a Pandas DataFrame with a format as returned by the as_dataframe() function. To create new attributes, a list of attribute names can be passed to the optional parameter create. The names listed in create must be existing columns in the input DataFrame.

mypointsetdf['z adjusted'] = 0.95 * mypointsetdf['z']
mypointset.set_values(mypointsetdf, create = ['z adjusted'])
pointset_newAtr.png
The .values() function can be used for reading and writing attribute data. In the following example, we modify the first value of the z adjusted attribute to -1000 and visualize the change in a DataFrame. At the end of the with block, the content of the DataFrame is automatically written back to Petrel.

with mypointset.values(start= 0, end= 10) as mypointsetdf:
    mypointsetdf['z adjusted'][0] = -1000
mypointsetdf['z adjusted']
0    -1000.0
1        0.0
2        0.0
3        0.0
4        0.0
5        0.0
6        0.0
7        0.0
8        0.0
9        0.0
10       0.0
Name: z adjusted, dtype: float64
Finally, using the delete_point() function, we can delete points from the point set. Using this function multiple times will be slower than manipulating a list of cegalprizm.pythontool.PointsetPoint objects and assigning it to the points() property in one go. Note that cegalprizm.pythontool.PointsetPoint objects are compared by reference, not value. In order to delete a point, you must refer to the actual PointsetPoint object you wish to delete:


#assign the first point of the pointset to a variable
points_to_delete= mypointset.points[0]
#delete the first point from the pointset
mypointset.delete_point(points_to_delete)
#check DataFrame to see if the point was deleted
mypointsetdf=mypointset.as_dataframe()
mypointsetdf
x	y	z	Z	xmas	z adjusted
0	536103.57	6793049.4	0.0	0.0	NaN	0.0
1	536104.57	6793049.4	0.0	0.0	NaN	0.0
2	536105.57	6793049.4	0.0	0.0	NaN	0.0
3	536106.57	6793049.4	0.0	0.0	NaN	0.0
4	536107.57	6793049.4	0.0	0.0	NaN	0.0
...	...	...	...	...	...	...
4993	536196.57	6793098.4	100.0	100.0	100.0	95.0
4994	536197.57	6793098.4	100.0	100.0	100.0	95.0
4995	536198.57	6793098.4	100.0	100.0	100.0	95.0
4996	450000.00	6780301.0	-1982.5	-1982.5	NaN	NaN
4997	450000.00	6780301.0	-1982.5	-1982.5	NaN	NaN
4998 rows × 6 columns

Using the function .create_pointset() it is possible to create a new empty polyline set. This functionality is only available from version 2.6 or higher.

ptp.create_pointset(name='New point set')
PointSet(petrel_name="New point set")
By default the template of the new point set object is set to ‘Elevation depth. In version 2.6 or higher you can set the template when creating a new point set object.

selected_pointset_template=[i for i in ptp.templates if i.petrel_name=='Velocity'][0]
selected_pointset_template
Template(petrel_name="Velocity")
new_point_set=ptp.create_pointset(name='New point set with template', template=selected_pointset_template)
new_point_set
PointSet(petrel_name="New point set with template")
In previous version the property .template returned a empty string for point set objects. This has been fixed in version 2.6 or higher.

new_point_set.template
'Velocity'
With the release of Python Tool Pro 2.8 , a new domain property is now available for PointSet objects and returns the domain of the object as a string (e.g., Elevation Time, Elevation Depth). If no domain is available, an empty string is returned.

mypointset.domain
Polylines sets
Check out the API documentation to view a detailed description of all the functions and properties available for working with polylines sets.

The .polylinesets property returns a dictionary where the keys represent the path of the polylineset within the Petrel input tree and the value represents the name of the polylineset.

ptp.polylinesets
PolylineSets({'Input/Boundaries/Copy of Project Boundary': PolylineSet(petrel_name="Copy of Project Boundary"), 'Input/Boundaries/Project Boundary': PolylineSet(petrel_name="Project Boundary"), 'Input/Boundaries/Boundary of Top Ness (Depth 1)': PolylineSet(petrel_name="Boundary of Top Ness (Depth 1)"), 'Input/Copy of Above Top Tabert': PolylineSet(petrel_name="Copy of Above Top Tabert"), 'Input/Boundaries/Above Top Tabert': PolylineSet(petrel_name="Above Top Tabert"), 'Input/Boundaries/Small Boundary': PolylineSet(petrel_name="Small Boundary"), 'Input/Create Pseudowells Polygon': PolylineSet(petrel_name="Create Pseudowells Polygon")})
An alternative way to retrieve polyline sets is to use list comprehensions

polyline_list=[i for i in ptp.polylinesets]
polyline_list
[PolylineSet(petrel_name="Copy of Project Boundary"),
 PolylineSet(petrel_name="Project Boundary"),
 PolylineSet(petrel_name="Boundary of Top Ness (Depth 1)"),
 PolylineSet(petrel_name="Copy of Above Top Tabert"),
 PolylineSet(petrel_name="Above Top Tabert"),
 PolylineSet(petrel_name="Small Boundary"),
 PolylineSet(petrel_name="Create Pseudowells Polygon")]
Let’s assign the first polyline set to a variable:

mypolylineset = polyline_list[2]
mypolylineset.readonly=False
print(mypolylineset)
PolylineSet(petrel_name="Boundary of Top Ness (Depth 1)")
With the release of Python Tool Pro 2.8 , a new domain property is now available for PolylineSet objects and returns the domain of the object as a string (e.g., Elevation Time, Elevation Depth). If no domain is available, an empty string is returned.

mypolylineset.domain
We can check if the polygon is closed by using the .is_close() function. The input parameter represents the index of the polygon in the polyline set. The index starts at 0 in Python but at 1 in Petrel. This method returns a boolean value, True if the polygon is closed and False otherwise:

mypolylineset.is_closed(0)
True
The .get_position() function returns a tuple containing lists for the X,Y,Z positions of the polygons in a polyline set:

mypolylineset.get_positions(0)
([459102.57,
  458219.84783203126,
  456884.55,
  455890.26,
  455099.93,
  454220.36,
  453608.49,
  452958.38,
  452703.44,
  452219.04,
  451760.14,
  451454.2,
  451122.77,
  450804.09,
  450765.85,
  450957.06,
  451556.18,
  452206.29,
  452951.75256835937,
  453482.80551269534,
  454437.07,
  456604.11,
  457980.81,
  458477.96,
  458898.62],
 [6789084.4,
  6790276.509609375,
  6790244.4,
  6789772.75,
  6789607.04,
  6789390.33,
  6789160.88,
  6788714.73,
  6787835.17,
  6786840.88,
  6785910.33,
  6785285.71,
  6784533.62,
  6783513.84,
  6782047.9,
  6781155.59,
  6780492.73,
  6780365.26,
  6780250.015136719,
  6780209.482148438,
  6780084.82,
  6780416.25,
  6782379.33,
  6784444.39,
  6786496.7],
 [0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0,
  0.0])
The image below shows how the Project boundary polygon looks like alongside with the associated spreadsheet:

beforeaddpoly.png
A polyline set can have multiple polylines. You can access a polyline from a polyline set using the index.

polyline=mypolylineset[0]
polyline
Polyline(parent_polylineset=PolylineSet(petrel_name="Project Boundary"))
Or you can use a list comprehension to get a list of polylines in a polyline set.

[i for i in mypolylineset.polylines]
[Polyline(parent_polylineset=PolylineSet(petrel_name="Project Boundary")),
 Polyline(parent_polylineset=PolylineSet(petrel_name="Project Boundary"))]
Now let’s use the .add_line() function to add a new line to the polyline set. First, we need to ensure that the polyline set readonly is set to False so we can modify it. Then we can use the point class parameter and provide four new points.

Note: The function .add_line() is a feature available in Python Tool Pro version 2.5.

You must supply at least two points, or three if the polyline is closed:

from cegalprizm.pythontool import Point
mypolylineset.readonly=False
mypolylineset.add_line(points=[Point(457102.57 ,6779084.4, 0.0 ),Point(454219.84 ,6790276.509, 0.0 ),Point(450002.57 ,6790276.509, 0.0 ),Point(452002.57 ,6776276.509, 0.0 )], closed =True )
The image below shows the added new polygon to the Project Boundary polygon set. Notice how the spreadsheet has been updated and it now contains a new polygon with the four vertices defined in the cell above:

afterAddLine.png
Note: The function .delete_line() is a feature available in Python Tool Pro version 2.5.

To delete the added polygon we can iterate through the existing polylines, assign the last polygon to a variable and then use the .delete_line function:

del_line= [i for i in mypolylineset.polylines][-1]
mypolylineset.delete_line(del_line)
It is possible to show the polyline set as a Pandas DataFrame. The DataFrame includes the polyline ID, the vertice ID (point in the polyline) and the XYZ for each point.

df=mypolylineset.points_dataframe() df

To add many lines at once it is better to use the method .add_lines() instead of .add_line() as this will be more performant. The method .add_lines() takes a PandasDataFrame as an input. In this example we will copy the dataframe from the original polyline set and change the values to create new polylines. We can then use this new DataFrame to add multiple lines at once.

df2=df.copy()
df2['Poly']=df['Poly']+3
df2['X']=df['X']+993
df2['Z']=df['Z']+400
mypolylineset.add_lines(dataframe=df2)
The property polyline_type returns the type of polyline of the polyline set. This is a property available in Python Tool Pro version 2.5 or higher.

mypolylineset.polyline_type
'Generic boundary polygon'
From Python Tool Pro version 2.6 or higher it is possible to set the ployline_type. This can be done by using the PolyLineTypeEnum or one of the accepted strings.

from cegalprizm.pythontool import PolylineTypeEnum
[i for i in PolylineTypeEnum]
[<PolylineTypeEnum.FaultSticks: 'Fault sticks'>,
 <PolylineTypeEnum.FaultLines: 'Fault lines'>,
 <PolylineTypeEnum.FaultCenterline: 'Fault centerline'>,
 <PolylineTypeEnum.FaultPolygons: 'Fault polygons'>,
 <PolylineTypeEnum.HorizonContours: 'Horizon contours'>,
 <PolylineTypeEnum.HorizonErosionLine: 'Horizon erosion line'>,
 <PolylineTypeEnum.GenericBoundaryPolygon: 'Generic boundary polygon'>,
 <PolylineTypeEnum.GenericSeismic2DLines: 'Generic seismic 2D lines'>,
 <PolylineTypeEnum.GenericSeismic3DLines: 'Generic seismic 3D lines'>,
 <PolylineTypeEnum.GenericZeroLines: 'Generic zero lines'>,
 <PolylineTypeEnum.TrendLines: 'Trend lines'>,
 <PolylineTypeEnum.FlowLines: 'Flow lines'>,
 <PolylineTypeEnum.GenericSingleLine: 'Generic single line'>,
 <PolylineTypeEnum.ManyPoints: 'Many points'>,
 <PolylineTypeEnum.FewPoints: 'Few points'>,
 <PolylineTypeEnum.MultiZHorizon: 'Multi-Z horizon'>,
 <PolylineTypeEnum.Other: 'Other'>]
# Change the type of the polyline to 'Fault polygon' using a string
mypolylineset.polyline_type = 'Fault polygons'
mypolylineset.polyline_type
'Fault polygons'
# Change the type of the polyline to 'Generic boundary polygon' using the PolylineTypeEnum
mypolylineset.polyline_type = PolylineTypeEnum.GenericBoundaryPolygon
mypolylineset.polyline_type
'Generic boundary polygon'
Using the function .create_polylineset() it is possible to create a new empty polyline set. This functionality is only available from version 2.5 or higher.

ptp.create_polylineset(name='New polyline set')
PolylineSet(petrel_name="New polyline set")
In version 2.6 or higher it is possible to set the template when creating a new polyline set. The default is ‘Elevation depth’.

selected_template=[i for i in ptp.templates if i.petrel_name=='Elevation time'][0]
selected_template
Template(petrel_name="Elevation time")
ptp.create_polylineset(name='New polyline set with template', template=selected_template)
PolylineSet(petrel_name="New polyline set with template")
Polyline attributes
Note: The ability to access polyline attributes is a feature available Python Tool Pro version 2.5.

The ployline attributes can be displayed with the method attributes_dataframe()

mypolylineset.attributes_dataframe()
Poly	Show polygon	Label X	Label Y	Label Z	Label angle	Continuous
0	1	True	NaN	NaN	NaN	0.0	NaN
1	2	True	NaN	NaN	NaN	0.0	NaN
Polyline attributes can also be retrieved as Python objects using the property .attributes.

my_attribute=[i for i in mypolylineset.attributes][-1]
my_attribute
PolylineAttribute(unique_name="Continuous")
It is possible to use the index or the name of the attribute.

print(mypolylineset.attributes[-1])
print(mypolylineset.attributes["Continuous"])
PolylineAttribute(unique_name="Continuous")
PolylineAttribute(unique_name="Continuous")
The property is_well_known_attribute shows if an attributes is a Petrel defined or user defined attribute. Well_known_attributes cannot be deleted.

my_attribute.is_well_known_attribute
False
Polyline attributes can be edited using the method set_values. The input is a Numpy array or list of equal length of the number of polylines.

my_attribute.set_values(values=[4.1,4.2,3.2,56.1,12.2,1.2])
mypolylineset.attributes_dataframe()
Poly	Show polygon	Label X	Label Y	Label Z	Label angle	Discrete	Boolean	String	Continuous	Date
0	1	True	454934.21	6785180.66	1.0	0.0	1	True	test	4.1	2024-03-13
1	2	True	453552.57	6783276.51	1.0	0.0	2	False	tes3	4.2	2024-03-10
2	3	True	453552.57	6783276.51	1.0	0.0	3	False	test32	3.2	2024-02-15
3	4	True	455927.21	6785180.66	401.0	0.0	4	True	teset21	56.1	2024-03-11
4	5	True	454545.57	6783276.51	401.0	0.0	5	False	e123	12.2	2024-03-24
5	6	True	454545.57	6783276.51	401.0	0.0	6	False	waras2	1.2	2024-02-13
Polyline attributes can be added or deleted from the polyline set.

new_attribute=mypolylineset.add_attribute(name='new_attribute',data_type='continuous')
new_attribute
PolylineAttribute(unique_name="new_attribute")
mypolylineset.delete_attribute(attribute=new_attribute)
====
Working with Petrel workflows
Accessing Petrel workflows from Python Tool Pro is one of the new experimental methods. These methods have to be explicitly enabled in the PetrelConnection to be used. Check out the API documentation to view a detailed description of all the functions and methods available for Workflows.

from cegalprizm.pythontool import PetrelConnection
petrel = PetrelConnection(allow_experimental=True)
Using the .workflow property, we can retrieve all the workflows from the the project in a dictionary where the keys represent the path of the workflow within the Petrel input tree and the values represent the name of the workflow:

petrel.workflows
Workflows({'Workflows/Unflatten cube on horizon': Workflow(petrel_name="Unflatten cube on horizon"), 'Workflows/Workflow 1': Workflow(petrel_name="Workflow 1"), 'Workflows/Flatten cube on horizon': Workflow(petrel_name="Flatten cube on horizon")})
Using the .path and .petrel_name attributes, we can also create a list of tuples that contain both the path and the name of the workflow:

listofworkflows=[(i.petrel_name,i.path) for i in petrel.workflows]
listofworkflows
[('Unflatten cube on horizon', 'Workflows/Unflatten cube on horizon'),
 ('Workflow 1', 'Workflows/Workflow 1'),
 ('Flatten cube on horizon', 'Workflows/Flatten cube on horizon')]
To assign a workflow to a variable, we can use the Petrel path of the data objects:

Flatten_workflow=petrel.workflows['Workflows/Flatten cube on horizon']
Flatten_workflow.petrel_name
'Flatten cube on horizon'
Alternatively, we can use list comprehension on the ‘listofworkflows’ variable created earlier, and assign one of workflows in the list to a variable. To do this, we select the third tuple in the list of workflows [2], and then the second value in the tuple [1], which is the path to that workflow:

Flatten_workflow=petrel.workflows[listofworkflows[2][1]]
Flatten_workflow
Workflow(petrel_name="Flatten cube on horizon")
The image below shows the Petrel Workflow tree and the Flatten cube on horizon workflow definition. In this example, the workflow is used to flatten a seismic cube using a specific horizon. The seismic cube and horizon are assigned to two reference variables. Next, the name of the seismic cube is also saved as a variable. The Flatten cube process takes the seismic_cube and seismic_horizon variables as inputs, flattens the cube, saves the output under a new name (the seismc cube name variable + “_flattened suffix”) and then assigns it to the seismic_cube_flattened variable.

workflowdef.png
The .input property returns all the input variables for the selected workflow:

Flatten_workflow.input
{'Seismic_cube': ReferenceVariable(petrel_name="Seismic_cube"),
 'Seismic_horizon': ReferenceVariable(petrel_name="Seismic_horizon")}
Similarly, the .output property returns all the output variables for the selected workflow:

Flatten_workflow.output
{'Seismic_cube_flattened': ReferenceVariable(petrel_name="Seismic_cube_flattened"),
 'Output variable': ReferenceVariable(petrel_name="Output variable")}
We can assign the workflow input variables to Python variables:

workflow_flatten_cube_input_seismic_cube = Flatten_workflow.input['Seismic_cube']
workflow_flatten_cube_input_seismic_horizon = Flatten_workflow.input['Seismic_horizon']
Next, we can assign the seismic cube we want to flatten and the seismic horizon we want to use to Python variables:

seismic_cube = petrel.seismic_cubes['Input/Seismic/2016-R3136_Depth/Tiny cropped cube']
seismic_horizon = petrel.horizon_interpretations['Input/Seismic/Interpretation folder 1/Horizon to flatten on truncated']
Using the .run() function, we can execute the workflow. The function takes in a dictionary with the workflow input variables as keys and the petrel objects as values:

output_dict = Flatten_workflow.run(args={workflow_flatten_cube_input_seismic_cube : seismic_cube,
                                              workflow_flatten_cube_input_seismic_horizon : seismic_horizon})
Running the cell above creates a flattened seismic cube in the petrel input tree. The image below shows the unflatten seismic together with the used horizon (to the left) and the flattened seismic (to the right):

seis_workflow.png
===
Remember all these guidelines!


